{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from profilescraper import query_profile\n",
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "import os\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from proxy_utils import proxy_dict, get_proxies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profiles_to_pandas(profiles):\n",
    "    userDf = pd.DataFrame(columns=['username', 'location', 'has_location', 'age', 'is_verified', 'total_tweets', 'total_following', 'total_followers', 'total_likes', 'total_moments', 'total_lists', 'has_avatar', 'has_background', 'is_protected', 'profile_modified', 'tweets'])\n",
    "    tweetDf = pd.DataFrame(columns=['User', 'ID', 'Tweet', 'Time', 'Likes', 'Replies', 'Retweet'])\n",
    "\n",
    "    for profile in profiles:   \n",
    "        for tweet in profile.tweets:\n",
    "            tweetDf = tweetDf.append({'User': profile.username, 'ID': tweet.id, 'Tweet': tweet.text, 'Time': tweet.timestamp, 'Likes': tweet.likes, 'Replies': tweet.replies, 'Retweet': tweet.retweets}, ignore_index=True)\n",
    "\n",
    "        userDf = userDf.append({'username':profile.username, 'location':profile.location, 'has_location':profile.has_location, 'age':profile.age, 'is_verified':profile.is_verified, 'total_tweets':profile.total_tweets, 'total_following':profile.total_following, 'total_followers':profile.total_followers, 'total_likes':profile.total_likes, 'total_moments':profile.total_moments, 'total_lists':profile.total_lists, 'has_avatar':profile.has_avatar, 'has_background':profile.has_background, 'is_protected':profile.is_protected, 'profile_modified':profile.profile_modified}, ignore_index=True)\n",
    "\n",
    "    tweetDf = tweetDf.to_csv('profiledata/userTweets.csv', index=None, mode='a')\n",
    "    userDf['username'].to_csv('profiledata/extractedUsers.csv', index=None, mode='a')\n",
    "    userDf.to_csv('profiledata/userData.csv', index=None, mode='a')\n",
    "    \n",
    "    print(\"Saved to userTweets.csv and extractedUsers.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_list(currList, poolsize, proxy, count):\n",
    "        \n",
    "    if (len(currList) > 0):\n",
    "        profiles = query_profile(currList, poolsize=poolsize, proxy=proxy)\n",
    "        profiles_to_pandas(profiles)\n",
    "\n",
    "        count += 1\n",
    "    \n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_extraction(coinname, poolsize=20):\n",
    "    proxies = get_proxies()\n",
    "    proxySize = len(proxies)\n",
    "    \n",
    "    users = list(set(pd.read_csv('{}/extracted/combined.csv'.format(coinname), dtype=str)['User']))\n",
    "    \n",
    "    try:\n",
    "        alreadyRead = pd.read_csv('profiledata/extractedUsers.csv', header=None)[0]\n",
    "    except FileNotFoundError:\n",
    "        logging.info(\"Already extracted users not found - Starting from a clean slate\")\n",
    "        os.mknod(\"profiledata/extractedUsers.csv\")\n",
    "        alreadyRead = pd.Series()\n",
    "        \n",
    "    \n",
    "    uniqueUsers = list(set(users) - set(alreadyRead))\n",
    "    \n",
    "    print(\"File contains {} data. Scraping for {} after cache\".format(len(users), len(uniqueUsers)))\n",
    "    \n",
    "    oldi = 0\n",
    "    count = 0\n",
    "    \n",
    "    for i in range(0, len(uniqueUsers), poolsize*5):\n",
    "        count = scrape_list(uniqueUsers[oldi:i], poolsize=poolsize, proxy=proxies[count], count=count)\n",
    "        \n",
    "        if (count >= proxySize):\n",
    "            count = 0\n",
    "        \n",
    "        logging.info(\"Done {} of {}\".format(i, len(uniqueUsers)))\n",
    "        oldi = i\n",
    "    \n",
    "    scrape_list(uniqueUsers[i:], poolsize=poolsize, proxy=None, count=count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for files in glob(os.getcwd() + \"/*\"):\n",
    "    if (os.path.exists(files + \"/extracted\")):\n",
    "        print(\"Extracting for {}\".format(files))\n",
    "        perform_extraction(files.split(\"/\")[-1], poolsize=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_details():\n",
    "    allUsers = pd.DataFrame()\n",
    "\n",
    "    for files in glob(os.getcwd() + \"/*\"):\n",
    "        if (os.path.exists(files + \"/extracted\")):\n",
    "            fname = files + \"/extracted/combined.csv\"\n",
    "            tDf = pd.read_csv(fname)\n",
    "            print(\"Reading from {}\".format(fname))\n",
    "            allUsers = pd.concat([allUsers, tDf['User']])\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_files():\n",
    "    userData = pd.read_csv(os.getcwd() + \"/profiledata/userData.csv\")\n",
    "    userTweets = pd.read_csv(os.getcwd() + \"/profiledata/userTweets.csv\")\n",
    "    \n",
    "    userData = userData.set_index('username').drop_duplicates().reset_index()\n",
    "    userTweets = userTweets.set_index(['User', 'ID']).drop_duplicates().reset_index()\n",
    "    \n",
    "    userTweets = userTweets.rename({'User': 'usernamee'})\n",
    "    \n",
    "    merged = pd.merge(userData, userTweets, how='inner', on=['username'])\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shresthanikesh23/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2903: DtypeWarning: Columns (0,1,2,3,4,5,6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'username'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-e624fa369d68>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmeged\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-2243768b179f>\u001b[0m in \u001b[0;36mclean_files\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0muserTweets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muserTweets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'User'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'usernamee'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mmerged\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muserData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserTweets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'inner'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'username'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmerged\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m     58\u001b[0m                          \u001b[0mright_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mright_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuffixes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msuffixes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                          \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindicator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindicator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m                          validate=validate)\n\u001b[0m\u001b[1;32m     61\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    548\u001b[0m         (self.left_join_keys,\n\u001b[1;32m    549\u001b[0m          \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright_join_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m          self.join_names) = self._get_merge_keys()\n\u001b[0m\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m         \u001b[0;31m# validate the merge keys dtypes. We may need to coerce\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m_get_merge_keys\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    854\u001b[0m                             right_keys.append(\n\u001b[1;32m    855\u001b[0m                                 right._get_label_or_level_values(\n\u001b[0;32m--> 856\u001b[0;31m                                     rk, stacklevel=stacklevel))\n\u001b[0m\u001b[1;32m    857\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                             \u001b[0;31m# work-around for merge_asof(right_index=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_label_or_level_values\u001b[0;34m(self, key, axis, stacklevel)\u001b[0m\n\u001b[1;32m   1377\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1378\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1379\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1381\u001b[0m         \u001b[0;31m# Check for duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'username'"
     ]
    }
   ],
   "source": [
    "meged = clean_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

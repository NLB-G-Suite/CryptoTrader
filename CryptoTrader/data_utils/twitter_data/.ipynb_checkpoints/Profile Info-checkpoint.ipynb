{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from profilescraper import query_profile\n",
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "import os\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from proxy_utils import proxy_dict, get_proxies\n",
    "\n",
    "import numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profiles_to_pandas(profiles):\n",
    "    userDf = pd.DataFrame(columns=['username', 'location', 'has_location', 'age', 'is_verified', 'total_tweets', 'total_following', 'total_followers', 'total_likes', 'total_moments', 'total_lists', 'has_avatar', 'has_background', 'is_protected', 'profile_modified', 'tweets'])\n",
    "    tweetDf = pd.DataFrame(columns=['User', 'ID', 'Tweet', 'Time', 'Likes', 'Replies', 'Retweet'])\n",
    "\n",
    "    for profile in profiles:   \n",
    "        for tweet in profile.tweets:\n",
    "            tweetDf = tweetDf.append({'User': profile.username, 'ID': tweet.id, 'Tweet': tweet.text, 'Time': tweet.timestamp, 'Likes': tweet.likes, 'Replies': tweet.replies, 'Retweet': tweet.retweets}, ignore_index=True)\n",
    "\n",
    "        userDf = userDf.append({'username':profile.username, 'location':profile.location, 'has_location':profile.has_location, 'age':profile.age, 'is_verified':profile.is_verified, 'total_tweets':profile.total_tweets, 'total_following':profile.total_following, 'total_followers':profile.total_followers, 'total_likes':profile.total_likes, 'total_moments':profile.total_moments, 'total_lists':profile.total_lists, 'has_avatar':profile.has_avatar, 'has_background':profile.has_background, 'is_protected':profile.is_protected, 'profile_modified':profile.profile_modified}, ignore_index=True)\n",
    "\n",
    "    tweetDf = tweetDf.to_csv('profiledata/userTweets.csv', index=None, mode='a')\n",
    "    userDf['username'].to_csv('profiledata/extractedUsers.csv', index=None, mode='a')\n",
    "    userDf.to_csv('profiledata/userData.csv', index=None, mode='a')\n",
    "    \n",
    "    print(\"Saved to userTweets.csv and extractedUsers.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_list(currList, poolsize, proxy, count):\n",
    "        \n",
    "    if (len(currList) > 0):\n",
    "        profiles = query_profile(currList, poolsize=poolsize, proxy=proxy)\n",
    "        profiles_to_pandas(profiles)\n",
    "\n",
    "        count += 1\n",
    "    \n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_extraction(coinname, poolsize=20):\n",
    "    proxies = get_proxies()\n",
    "    proxySize = len(proxies)\n",
    "    \n",
    "    users = list(set(pd.read_csv('{}/extracted/combined.csv'.format(coinname), dtype=str)['User']))\n",
    "    \n",
    "    try:\n",
    "        alreadyRead = pd.read_csv('profiledata/extractedUsers.csv', header=None)[0]\n",
    "    except FileNotFoundError:\n",
    "        logging.info(\"Already extracted users not found - Starting from a clean slate\")\n",
    "        os.mknod(\"profiledata/extractedUsers.csv\")\n",
    "        alreadyRead = pd.Series()\n",
    "        \n",
    "    \n",
    "    uniqueUsers = list(set(users) - set(alreadyRead))\n",
    "    \n",
    "    print(\"File contains {} data. Scraping for {} after cache\".format(len(users), len(uniqueUsers)))\n",
    "    \n",
    "    oldi = 0\n",
    "    count = 0\n",
    "    \n",
    "    for i in range(0, len(uniqueUsers), poolsize*5):\n",
    "        count = scrape_list(uniqueUsers[oldi:i], poolsize=poolsize, proxy=proxies[count], count=count)\n",
    "        \n",
    "        if (count >= proxySize):\n",
    "            count = 0\n",
    "        \n",
    "        logging.info(\"Done {} of {}\".format(i, len(uniqueUsers)))\n",
    "        oldi = i\n",
    "    \n",
    "    scrape_list(uniqueUsers[i:], poolsize=poolsize, proxy=None, count=count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for files in glob(os.getcwd() + \"/*\"):\n",
    "    if (os.path.exists(files + \"/extracted\")):\n",
    "        print(\"Extracting for {}\".format(files))\n",
    "        perform_extraction(files.split(\"/\")[-1], poolsize=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_details():\n",
    "    allUsers = pd.DataFrame()\n",
    "\n",
    "    for files in glob(os.getcwd() + \"/*\"):\n",
    "        if (os.path.exists(files + \"/extracted\")):\n",
    "            fname = files + \"/extracted/combined.csv\"\n",
    "            tDf = pd.read_csv(fname)\n",
    "            print(\"Reading from {}\".format(fname))\n",
    "            allUsers = pd.concat([allUsers, tDf['User']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.jit\n",
    "def clean_files():\n",
    "    userData = pd.read_csv(os.getcwd() + \"/profiledata/userData.csv\")\n",
    "    userTweets = pd.read_csv(os.getcwd() + \"/profiledata/userTweets.csv\")\n",
    "    \n",
    "    userTweets = userTweets.rename(columns={'User': 'username'})\n",
    "    \n",
    "    merged = pd.merge(userData, userTweets, how='inner', on=['username'])    \n",
    "    newuserData = merged[userData.columns]\n",
    "    newuserData = newuserData.set_index('username').drop_duplicates().reset_index()\n",
    "    \n",
    "    newuserTweets = merged[userTweets.columns]\n",
    "    newuserTweets = newuserTweets.rename(columns={'username': 'User'})\n",
    "    \n",
    "    newuserTweets = newuserTweets.set_index(['User', 'ID']).drop_duplicates().reset_index()\n",
    "    \n",
    "    return userData, userTweets, newuserData, newuserTweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shresthanikesh23/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (0,1,2,3,4,5,6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "userData, userTweets, newuserData, newuserTweets = clean_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "289816"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(userData['username']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(userTweets['username']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "277024"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(newuserData['username']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "277023"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(newuserTweets['User']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

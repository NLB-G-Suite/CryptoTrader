{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from twitterscraper import query_tweets\n",
    "\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from dateutil.rrule import rrule, MONTHLY\n",
    "from datetime import datetime, date, timedelta\n",
    "\n",
    "from proxy_utils import proxy_dict, get_proxies\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "import os\n",
    "\n",
    "import requests\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "proxies=get_proxies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Querying Bitcoin since:2018-02-15 until:2018-02-16\n",
      "INFO:root:Querying Bitcoin since:2018-02-16 until:2018-02-17\n",
      "INFO:root:Querying Bitcoin since:2018-02-14 until:2018-02-15\n",
      "INFO:root:Querying Bitcoin since:2018-02-17 until:2018-02-18\n",
      "ERROR:root:Failed to parse JSON \"Expecting value: line 1 column 1 (char 0)\" while requesting \"https://twitter.com/i/search/timeline?vertical=default&include_available_features=1&include_entities=1&reset_error_state=false&src=typd&max_position=TWEET-965007878158462976-&q=Bitcoin%20since%3A2018-02-17%20until%3A2018-02-18&l=\".\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/shresthanikesh23/jupyter/CryptoTraderRemote/CryptoTrader/data_utils/twitter_data/twitterscraper/query.py\", line 50, in query_single_page\n",
      "    json_resp = json.loads(response.text)\n",
      "  File \"/usr/lib/python3.5/json/__init__.py\", line 319, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/usr/lib/python3.5/json/decoder.py\", line 339, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/usr/lib/python3.5/json/decoder.py\", line 357, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "INFO:root:Retrying... (Attempts left: 10)\n",
      "ERROR:root:Failed to parse JSON \"Expecting value: line 1 column 1 (char 0)\" while requesting \"https://twitter.com/i/search/timeline?vertical=default&include_available_features=1&include_entities=1&reset_error_state=false&src=typd&max_position=TWEET-964979791903342592-965007367426502656-BD1UO2FFu9QAAAAAAAAVfAAAAAcAAABWAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA==-T-0-2&q=Bitcoin%20since%3A2018-02-17%20until%3A2018-02-18&l=\".\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/shresthanikesh23/jupyter/CryptoTraderRemote/CryptoTrader/data_utils/twitter_data/twitterscraper/query.py\", line 50, in query_single_page\n",
      "    json_resp = json.loads(response.text)\n",
      "  File \"/usr/lib/python3.5/json/__init__.py\", line 319, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/usr/lib/python3.5/json/decoder.py\", line 339, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/usr/lib/python3.5/json/decoder.py\", line 357, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "INFO:root:Retrying... (Attempts left: 10)\n",
      "INFO:root:Got 836 tweets for Bitcoin%20since%3A2018-02-17%20until%3A2018-02-18.\n",
      "INFO:root:Got 836 tweets (836 new).\n",
      "ERROR:root:Failed to parse JSON \"Expecting value: line 1 column 1 (char 0)\" while requesting \"https://twitter.com/i/search/timeline?vertical=default&include_available_features=1&include_entities=1&reset_error_state=false&src=typd&max_position=TWEET-963583298634166272-963920249069305856-BD1UO2FFu9QAAAAAAAAVfAAAAAcAAABWAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA==-T-0-48&q=Bitcoin%20since%3A2018-02-14%20until%3A2018-02-15&l=\".\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/shresthanikesh23/jupyter/CryptoTraderRemote/CryptoTrader/data_utils/twitter_data/twitterscraper/query.py\", line 50, in query_single_page\n",
      "    json_resp = json.loads(response.text)\n",
      "  File \"/usr/lib/python3.5/json/__init__.py\", line 319, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/usr/lib/python3.5/json/decoder.py\", line 339, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/usr/lib/python3.5/json/decoder.py\", line 357, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "INFO:root:Retrying... (Attempts left: 10)\n",
      "ERROR:root:Failed to parse JSON \"Expecting value: line 1 column 1 (char 0)\" while requesting \"https://twitter.com/i/search/timeline?vertical=default&include_available_features=1&include_entities=1&reset_error_state=false&src=typd&max_position=TWEET-963577468631310336-963920249069305856-BD1UO2FFu9QAAAAAAAAVfAAAAAcAAABWAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA==-T-0-49&q=Bitcoin%20since%3A2018-02-14%20until%3A2018-02-15&l=\".\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/shresthanikesh23/jupyter/CryptoTraderRemote/CryptoTrader/data_utils/twitter_data/twitterscraper/query.py\", line 50, in query_single_page\n",
      "    json_resp = json.loads(response.text)\n",
      "  File \"/usr/lib/python3.5/json/__init__.py\", line 319, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/usr/lib/python3.5/json/decoder.py\", line 339, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/usr/lib/python3.5/json/decoder.py\", line 357, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "INFO:root:Retrying... (Attempts left: 10)\n",
      "INFO:root:Got 1064 tweets for Bitcoin%20since%3A2018-02-16%20until%3A2018-02-17.\n",
      "INFO:root:Got 1900 tweets (1064 new).\n",
      "Process ForkPoolWorker-12:\n",
      "Process ForkPoolWorker-11:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 343, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "ERROR:root:An unknown error occurred! Returning tweets gathered so far.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/shresthanikesh23/jupyter/CryptoTraderRemote/CryptoTrader/data_utils/twitter_data/twitterscraper/query.py\", line 112, in query_tweets_once\n",
      "    pos is None, proxies=proxies\n",
      "  File \"/home/shresthanikesh23/jupyter/CryptoTraderRemote/CryptoTrader/data_utils/twitter_data/twitterscraper/query.py\", line 53, in query_single_page\n",
      "    tweets = list(Tweet.from_html(html))\n",
      "  File \"/home/shresthanikesh23/jupyter/CryptoTraderRemote/CryptoTrader/data_utils/twitter_data/twitterscraper/tweet.py\", line 133, in from_html\n",
      "    soup = BeautifulSoup(html, \"lxml\")\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/bs4/__init__.py\", line 228, in __init__\n",
      "    self._feed()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/bs4/__init__.py\", line 289, in _feed\n",
      "    self.builder.feed(self.markup)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/bs4/builder/_lxml.py\", line 251, in feed\n",
      "    self.parser.close()\n",
      "  File \"src/lxml/parser.pxi\", line 1367, in lxml.etree._FeedParser.close\n",
      "  File \"src/lxml/parser.pxi\", line 1398, in lxml.etree._FeedParser.close\n",
      "  File \"src/lxml/parsertarget.pxi\", line 147, in lxml.etree._TargetParserContext._handleParseResult\n",
      "  File \"src/lxml/parsertarget.pxi\", line 135, in lxml.etree._TargetParserContext._handleParseResult\n",
      "  File \"src/lxml/etree.pyx\", line 316, in lxml.etree._ExceptionContext._raise_if_stored\n",
      "  File \"src/lxml/saxparser.pxi\", line 388, in lxml.etree._handleSaxTargetStartNoNs\n",
      "  File \"src/lxml/saxparser.pxi\", line 403, in lxml.etree._callTargetSaxStart\n",
      "  File \"src/lxml/parsertarget.pxi\", line 80, in lxml.etree._PythonSaxParserTarget._handleSaxStart\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/bs4/builder/_lxml.py\", line 183, in start\n",
      "    self.soup.handle_starttag(name, namespace, nsprefix, attrs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/bs4/__init__.py\", line 465, in handle_starttag\n",
      "    self.currentTag, self._most_recent_element)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/bs4/element.py\", line 842, in __init__\n",
      "    self.name, attrs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/bs4/builder/__init__.py\", line 163, in _replace_cdata_list_attribute_values\n",
      "    for attr in list(attrs.keys()):\n",
      "KeyboardInterrupt\n",
      "INFO:root:Got 1054 tweets for Bitcoin%20since%3A2018-02-15%20until%3A2018-02-16.\n",
      "INFO:root:Got 1067 tweets for Bitcoin%20since%3A2018-02-14%20until%3A2018-02-15.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/usr/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    679\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 680\u001b[0;31m                 \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_items\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: pop from an empty deque",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-e8550430a14f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtweets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery_tweets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Bitcoin\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbegindate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2018\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menddate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2018\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m18\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproxies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproxies\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/jupyter/CryptoTraderRemote/CryptoTrader/data_utils/twitter_data/twitterscraper/query.py\u001b[0m in \u001b[0;36mquery_tweets\u001b[0;34m(query, limit, begindate, enddate, poolsize, lang, proxies, tweettype)\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0mpool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoolsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mnew_tweets\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimap_unordered\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_tweets_once\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproxies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproxies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit_per_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqueries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m             \u001b[0mall_tweets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_tweets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m             logging.info(\"Got {} tweets ({} new).\".format(\n",
      "\u001b[0;32m/usr/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    682\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_length\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 684\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    685\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m                     \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_items\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tweets = query_tweets(\"Bitcoin\", limit=10000, begindate=date(2018,2,14), enddate=date(2018, 2, 18), proxies=proxies[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cum on my tits\n",
      "964265275175653376\n",
      "I HAD HALF A TIT OUT ALL OF MY STATS LECTURE AND NO1 TOLD ME... IT REALLY BE YA OWN CLASSMATES....\n",
      "964249816145555456\n",
      "ISSUN SHE'S FUCKING DEAD YOU CAN'T KEEP MAKING TIT JOKES pic.twitter.com/ENBqIKcx7e\n",
      "964262451033399297\n",
      "Who wants to clean @masked_maya's spunked tits? pic.twitter.com/9PEXTOcpna\n",
      "964282806963666944\n",
      "$120 in 35 minutes? Why go to work when you can do the same thing in 35 minutes at home in your underwear and say words like shit fuck tits balls anytime. Focus on my lessons, my tutorials, my TA. pic.twitter.com/JIDDacg2xK\n",
      "964268664680742912\n",
      "\n",
      "\n",
      "Jokes on you , tit  https://twitter.com/knighthawk1970/status/964238698274611200 … <quoted_status> Who’s watching the Celtic game purely for the comedy value lol </quoted_status>\n",
      "964270404834676737\n",
      "*looks at tits*\n",
      "mawww I want a party tit too! C’mon gals, one of you snort a line of cocaine or something! https://twitter.com/piddle_fart/status/960261301028220929 … <quoted_status> I'll calm my tits all day long. 'Cept my left one. That's my party tit</quoted_status>\n",
      "964248815191711745\n",
      "Plus anal and tit fucks are better for men. You get off, it's painful/humiliating for the woman, and there's no chance of knocking her up and dealing with all that legal trouble.\n",
      "964281585498509312\n",
      "Tit fucks and anal are much better than vaginal sex for Hana.\n",
      "\n",
      "She has to remain pure and chaste till marriage.\n",
      "964281288399183872\n",
      "There’s just nothing more comforting than holding ur own tits a wee bit\n",
      "964262877074018304\n",
      "This new Snapchat is really getting on ma tits now \n",
      "964268675455909888\n",
      "This weather is THE TITS. Makes my soul so happy ♡\n",
      "964258997728575493\n",
      "having big tits suckkk and it’s a shame\n",
      "964287509428498432\n",
      "I hate how flat chested I am mannn lol I'm getting a boob job when I'm 25! Mark my words! So if in two years you guys see me w a killer rack & ur like \"did jac get a tit job?\" Yes, yes I did & I look like a shniiickkky shnackkkkkkkk\n",
      "964260104848728064\n",
      "Small world. I’ve just written one. If you’d clicked on the link you could have read it before making a tit of yourself. https://twitter.com/rizahu/status/964285648164270084 … <quoted_status> Currently writing an essay on child obesity, I can cut the long story short. The NCMP (2016/17) found that 20% of children aged 10-11 are obese, if you include overweight children this totals up to 34.3 percent. https://twitter.com/cjsnowdon/status/964281098267082753 …</quoted_status>\n",
      "964287795345969152\n",
      "Who else is ready to sweat their tits off in summer \n",
      "964287152816361472\n",
      "Awh my snapchats doing me fucking tits in sending things to the wrong people inall\n",
      "964285036034973701\n",
      "A text between two writers:\n",
      "@sne_k : \"What do we have to do next?\"\n",
      "Me: \"I think tits done.\"\n",
      "...\n",
      "Me: \"IT'S DONE. IT. NOT TITS.\"\n",
      "The end.\n",
      "964278866352119809\n",
      "funk is stored in the ball of tits from outer space pic.twitter.com/iQO1g9ciAO\n",
      "964267328832659456\n",
      "Why’s there all these girls slagging the under boob lighten up and get ur tits out o wait maybe it’s cos U HAVE NONE jealous cows\n",
      "964260291105112064\n",
      "Trump signals tit-for-tat duties to punish PM Modi's move https://www.ndtv.com/india-news/prime-minister-narendra-modi-sets-stage-for-trade-war-with-import-duties-foreign-media-1812964 … pic.twitter.com/bWb7KUX8gC\n",
      "964252981246902272\n",
      "Flashing her melons outside! #boobs #tits @Intimate_Diary https://twitter.com/Intimate_Diary/status/963946429684338689/photo/1pic.twitter.com/Vlo9zgDdZP \n",
      "964250885139333122\n",
      "RT @johncaswell7: Long Tailed Tit @WorcsWT @WoodlandTrust @jessops @wildlife_uk pic.twitter.com/GTbhjicvT7\n",
      "964244747152969728\n",
      "College is literally the best/worst time of your life. One minute you’re on Spring Break in Padre raging tits, the next you're broke and hungover and have 3 exams in a day.\n",
      "964244718401015808\n",
      "My timeline is nothing but gun control & tits fil a...\n",
      "964244434941554688\n",
      "Another day without nature, thank God for my garden visitors who are just about keeping me sane.Coal tit is adorable. pic.twitter.com/IxgWNK7kms\n",
      "964243524383277056\n",
      "Whose breasts would you rather oil up and tit fuck?\n",
      "\n",
      "RT for Demi Lovato \n",
      "LIKE for Selena Gomez pic.twitter.com/G67GUG6gvS\n",
      "964243230748536832\n",
      "keepy-puppies: n. Tits so droopy they could be used for football practice.\n",
      "964243055451824133\n",
      "Bro I was running for the train and my tit popped out I’m tighttttt\n",
      "964236505567891456\n",
      "Whilst waiting for the bramblings to show themselves this blue tit came quite close. It's easy to forget sometimes what a beautiful little bird it is pic.twitter.com/BE9SHGSr4D\n",
      "964232756917129217\n",
      "Unleashing her big titty! @sabinadulcecb #boobs #tits https://twitter.com/sabinadulcecb/status/964168747773759488/video/1 …\n",
      "964232639157764098\n",
      "Yano it gets on my TITS when I speak to girls who’ve just split from their loser boyfriends and feel so insecure because of them!GIRLS you are fucking queens, don’t let a stupid boy make you feel ugly! Watch in a few months you’ll be laughing at how minging he’s got \n",
      "964217738410553344\n",
      "Don’t you just hate those girls who you added on Snapchat because they’re hoes but now they’ve changed the way they live and they document every part of their life with their boyfriend. You n ur boyfs matching chicken chow main pot noodles are not cute Louise get your tits out.\n",
      "964215668437585921\n",
      "I Suddenly Ended Up With 3 Big Titty Sisters! I Was An Only Child, But When My Dad Got Remarried To A Lady With 3 Daughters, We Were Now One Big Family Living Under One Roof... I Knew Nothing About Women, But These Big Tits Slutty Sisters Gave Me A Great Sex Education\n",
      "964215364648361985\n",
      "It's always great to see a Crested Tit. #birds pic.twitter.com/tSbTY41uPS\n",
      "964213063808356352\n",
      "me: smells like up dog\n",
      "girl: whats up dog \n",
      "me: big tits\n",
      "964213011132149760\n",
      "It's like mama always said \"get them tits out, baby girl.. God gave them to you for a reason\"\n",
      "964208859421306880\n",
      "@laurasboutique_ has a shirt that says “I have no tits” I NEED THAT\n",
      "964206574863437824\n",
      "Tit Stante's \"#FreeMeekMill\" message and more have made the 2018 Winter Olympics dank af http://bit.ly/2stuuSI \n",
      "964197885784018945\n",
      "i really wish i was mysterious and lowkey but i will literally show u my tit and tell u my life story within the first 5 minutes of meeting\n",
      "964192942780018689\n",
      "What a non story. Some tit added some MPs to a silly Facebook group. https://twitter.com/owenjones84/status/964185221670342656 … <quoted_status> Oh look, Dominic Raab, frothing-at-the-mouth rightwing Tory housing minister, belonged to a secret Facebook group in favour of privatising all council housing and reintroducing workhouses for debtors https://www.buzzfeed.com/alexspence/the-tory-housing-minister-was-in-a-private-facebook-group?utm_term=.ncjv8nN5aV#.fcenGJAd7Q …</quoted_status>\n",
      "964186159738949637\n",
      "There's really not much of a Genesis Coupe scene in AZ. But I'm trynna look tits next year pic.twitter.com/xHmLLJiNev\n",
      "964185325357613056\n",
      "Officially endorsed by fromage “Le P’tit Québec” now y’all better watch yo mouths now\n",
      "964183877790167042\n",
      "If THAT is what you got from my tweet, you are a complete fucking moron. I didn't refer to guns in any way...but if you MUST know. 1. The \"Dems\" have not paid me. 2. I don't want your stupid guns. I have my own (not a tit joke) Thanks. https://twitter.com/ShellyM98283122/status/964180918641610752 …\n",
      "964182644002041858\n",
      "How much longer till I get to be a cyborg with hot swappable body parts? I wanna be able to swap back and forth between being flat chested and having the hugest fakest tits at a moment's notice.\n",
      "964181092566740994\n",
      "you were born in 1997 or 98. when Paolo Maldini was in his prime you were sucking your mom's tits. https://twitter.com/ZCalcio/status/963995782289461248 … <quoted_status> Don't let nostalgia fool you. I'm Italian and I hate Madrid, but c'mon. As good as Maldini was, he wasn't anywhere near as effective or talented as Marcelo. https://twitter.com/BTLComps/status/963923275440148485 …</quoted_status>\n",
      "964180837825617920\n",
      "ma tits https://twitter.com/tinyitems/status/960656888806305792 …\n",
      "964177989746520064\n",
      "I’m not a jealous person at all but if u go near what’s mine you’ll lose your left tit x\n",
      "964175590013140992\n",
      "Sexy Cock Sucking & Tit Fucking http://c4s.com/108594/19153397  #BBW #Clips4Sale pic.twitter.com/tqim8gQCn4\n",
      "964170852303589376\n",
      "learning juuust enough about tits to draw one \"aesthetically pleasing\" shape and just moving on with your life?? like your job is done??? completely inadequate. tits are PERSONAL. tits tell you so much about a body, what its seen, where its from, what its doing in the moment\n",
      "964165611570962432\n",
      "seriously though if theres only one thing about drawing you learn from me, its that you should absolutely never neglect the character and atmospheric importance of Tits. the tits are the eyes of the torso\n",
      "964165038213758976\n",
      "Long Tailed Tit @WorcsWT @WoodlandTrust @jessops @wildlife_uk pic.twitter.com/fvQuAV4pKc\n",
      "964160008471613441\n",
      "Since I started feeding the squirrels I just have to open my blinds in the morning now and at least one of them runs up within five to check the situation, they're no daft lol. I'm also getting robins and blue tits now, coming for the seeds. #LoveABitOfWildlife\n",
      "964155913044144130\n",
      "Plumber came over and took a look under the sink... He forgot to turn off his phone so I'm staring down at this large phone w/ big tits in a text message. XD\n",
      "964154147934277632\n",
      "I know the right is going to drag me to come out in favor of tits, but I have principles. I stand firmly in favor of tits being perfect and if that makes me a \"soyboy\" then so be it.\n",
      "964153224247828481\n",
      "niall hasnt yet tweeted about on the loose lyric videos been taken down i salute his unproblematic tits\n",
      "964151042534289408\n",
      "About two minutes after taking this pic I stacked it arse over tit and plunged face first into the snow in front of about 50 kids on a skiing lesson - Impossible to style out, just had to 'take the L' as the kids say nowadays as they all laughed and pointed.\n",
      "964147917455060992\n",
      "There's no such thing as \"bad tits.\" All tits are perfect.\n",
      "964146492540964864\n",
      "Garden Tits.\n",
      "Long tailed, Great and Marsh, Blue and Coal tits pic.twitter.com/nWZOMHY5y0\n",
      "964146254333833217\n",
      "“Following in the footsteps of Queens, Hoboken, and Jersey Ci—“\n",
      "\n",
      "Nah, this ain’t it. When have you know the Bronx to follow anybody? What in fifty tits is a Jersey City???? https://twitter.com/wsj/status/963749730558889985 … <quoted_status> The Bronx is the new Brooklyn. Sort of. http://on.wsj.com/2o6KxjB </quoted_status>\n",
      "964145355574202370\n",
      "Blue Tit ,Blackbird,Robin and Bullfinch @DerbysWildlife Avenue Washlands #365DaysWild #LoveWildlife pic.twitter.com/Q2sBVS0EYV\n",
      "964137703112630272\n",
      "Let me tell you a story. Yesterday, the gardener at @QueensCollegeOx installed bird feeders in the gardens. Today, I saw pair of coal tits using them. I've never once seen coal tits here before, in 3 years. 1 day. 1 day and some fatballs is all it took to attract a new species. pic.twitter.com/BtW6ppnHG4\n",
      "964134608781574144\n",
      "In February Blue Tits will start looking for safe nesting sites. Females usually lay 8–10 eggs in April/May, and once hatched each of the chicks can eat up to 100 caterpillars in a day! http://bit.ly/2s9XydH  #NationalNestBoxWeek pic.twitter.com/4PylulgImZ\n",
      "964122290379280385\n",
      "so my 21st birthday celebrations included me straddling a sexy spanish man on the back of a jet ski whilst trying not to die, paragliding, snorkelling, banana boating, getting off my tits at a drag show with my fabulous family and new friends and going on the pull with my mam \n",
      "964121440479047684\n",
      "Interested in how to help the nationally declining Willow Tit in the Dearne Valley? If yes join the DVLP with @NatureBftB & @YorksWildlife at @Worsbrough_Mill for a day of conservation & survey. pic.twitter.com/Zn3Dqyc5ii\n",
      "964121091449999360\n",
      "Prayers and condolences won’t stop this happening again it’s about time to change your laws! Easy for you to tweet about feeling safe when you travel with an armed security. You DT are a first class Tit. #FloridaShootinghttps://twitter.com/realdonaldtrump/status/963878055969198080 … <quoted_status> My prayers and condolences to the families of the victims of the terrible Florida shooting. No child, teacher or anyone else should ever feel unsafe in an American school.</quoted_status>\n",
      "964116955589435393\n",
      "why is it that when girls get their tits out on Twitter they get like 200k likes and guys drooling over them but when I post a pic of me looking cute asf in my boyfriend jeans, my mate messages me saying she mistook me for a guy....\n",
      "964110953079099392\n",
      "big tits webcam http://bigtitsmilf.co.uk/webcam/   ***NO WEB CAM NEEDED*** + sexy FREE chat pic.twitter.com/FERm5iA5F6\n",
      "964107523476172800\n",
      "6/ That I would never be my words or my art or my music to these men. That my enthusiasm and my talent would always be second to my sex appeal. I was, first & always, as my step father put it when I was 13, just blonde hair & a big pair of tits #timesup #metoo\n",
      "964104691960266752\n",
      "Big perky knockers! #boobs #tits @Intimate_Diary https://twitter.com/Intimate_Diary/status/963946614145593345/photo/1pic.twitter.com/eYOarzGVnR \n",
      "964103864923361280\n",
      "We have a regular long-tailed tit on our garden feeders now, and a tiny goldcrest - we're slowly building our nature-friendly garden. https://twitter.com/paulhayes55/status/964087837825159168 … <quoted_status> Long tail tit high five @OldeEire @Loverandomleigh @CeciliaEgan1 @BirdWatchIE @BirdWatchingMag @NikonProEurope @nikonownermag @Irishwildlife @RareBirdAlertUK @plantmad #naturelovers #birding pic.twitter.com/N1re9d4qbF</quoted_status>\n",
      "964100277711376385\n",
      "I react so strongly to caffeine that earl grey is like hard drugs to me. had one cup of tea and now I’m sitting at my desk off my tits\n",
      "964095474230800384\n",
      "Get your plask on\n",
      "\n",
      "Get your frees worth\n",
      "\n",
      "Get your rig out \n",
      "\n",
      "Get your perk on don’t trip \n",
      "\n",
      "Get your napkins ready  \n",
      "\n",
      "Get your poop in a group \n",
      "\n",
      "Get your tits in a line \n",
      "\n",
      "Get your schwerve on\n",
      "\n",
      "Get crack-a-lackin\n",
      "\n",
      "Get yourself a man from Boston \n",
      "\n",
      "https://shoreditchtownhall.com/whats-on/party-skills-for-the-end-of-the-world-2 …\n",
      "964083517423521794\n",
      "Just booked New Zealand to do the lord of the rings tour, buzzin oot Ma tits #runyoufools\n",
      "964082006324781056\n",
      "U.K 40F Ball shrinkage start for most, with jizzy penguins patches in the north. Giants cocks wafting with wintry showers of ice cold spunk later. \n",
      "Ohio 13c Chance of frog spit \n",
      "Florida 22c Murky as an elephants ass \n",
      "New Orleans 23c Dull as a person named Sharon with tiny tits pic.twitter.com/cduGi2fED7\n",
      "964058224994541569\n",
      "Okay Eleanor is kinda embarrassing idk if she still thinks that fans are 12 and wanna marry any of the boys but bitch no we want them to marry each other calm your tits down\n",
      "964057115513024513\n",
      "Trump is a freeloader, sucking at the tit of Lady Liberty, allowing her no sustenance from his abundance. He and his minions will suck her dry.  Dems must throw them out, balance the scales, and feed Lady Liberty for the benefit of all. #VoteThemOut #VoteBlue2018 #GetOutTheVote pic.twitter.com/LmpdJbymNx\n",
      "964056698368372738\n",
      "The birds seem to think its spring this morning - strutting mallards, drumming woodpecker, a song thrush in fine voice and great tits playing kiss-chase by the river!\n",
      "964047420681342978\n",
      "I wonder if your selfies would get as many likes if your tits weren't in them??\n",
      "964046839606599681\n",
      "ok i wish minors couldn’t have twitters bc i’m tired of seeing 15 year olds cry over boys and havin their tits out. go back to ur coloring book\n",
      "964041012627701760\n",
      "Jana for the first time nime sliciwa dame not by a man but by another woman.\n",
      "I wanna Know where this foking country is headed @UKenyatta\n",
      " \n",
      "It certainly wouldn't have happened during Kibaki's time. \n",
      "\n",
      "Country has gone tits Up.\n",
      "964038453737545733\n",
      "Every time I draw Quiet metalgear I consider giving her more sensible clothing because she deserves it but then as you may know I also love drawing tits and that's the side of me which usually wins the debate. The folly of man\n",
      "964038016951046144\n",
      "Trump Signals Tit-For-Tat Duties To Punish PM Modi's Move https://www.ndtv.com/india-news/prime-minister-narendra-modi-sets-stage-for-trade-war-with-import-duties-foreign-media-1812964 … #NDTVNewsBeeps pic.twitter.com/SoV35ePEDd\n",
      "964038007920758784\n",
      "I mean what better way to cut labor costs than to basically force your employees to give you back their wages if they want to eat. They're not gonna stop sucking that particular tit any time soon.\n",
      "964037820095651840\n",
      "Blue Tit yesterday, Mid-Wales @ruthwignall @Natures_Voice @wildlife_uk @NatureUK @Britnatureguide @BTO_GBW #wildlifephotography pic.twitter.com/14lYIqa0t1\n",
      "964035426783760384\n",
      "Not to suck my own tit or anything but my pancakes and brownies came out bomb today\n",
      "964034493848764416\n",
      "Happy slap day\n",
      "Tit for tat  jor se maar pic.twitter.com/hQfkEYs6z0\n",
      "964027116533686272\n",
      "Blue Tit Bird Painting  Blue Yellow White http://dld.bz/fj5W5  #birds #wildlife #painting pic.twitter.com/ApWjhRNzIA\n",
      "964022809306517505\n",
      "My glossy tits need your fingers\n",
      "964019257184006146\n",
      "Before and After Feminism pic.twitter.com/SQZMyhBUMm\n",
      "964011093239705600\n",
      "once i asked an artist what he thought of male tits with no nipples drawn and he said “it’s like a beef bowl without the rice”\n",
      "964006790630334465\n",
      "Happy (slightly late) Valentine's Day to my boo Hungarian Falls, made this vid just 4 u (also because I can't leave my bed and am bored as tits)\n",
      "\n",
      "(Also I expect @NickWeingartz to make fun of this within five minutes of when it is posted don't let me down) pic.twitter.com/umJwgzraiF\n",
      "964005178813841408\n",
      "Big tits British milf live web cam sex show http://bigtitsmilf.co.uk/webcam/  FREE chat #webcam #UK pic.twitter.com/BmLAfBrOGs\n",
      "964002581692510208\n",
      "Just sold! Get yours! squishing my huge tits so hard for you. Get yours here https://www.manyvids.com/Video/604570/squishing-my-huge-tits-so-hard-for-you/ … @manyvids #MVSales pic.twitter.com/S0DuDrfy7C\n",
      "963997210835865600\n",
      "if only I had tits like these https://twitter.com/mottsforthots/status/963615945775345664 …\n",
      "963997086919245825\n",
      "Xtina and her FAT TITS ruining her top pic.twitter.com/Crh7Gxri8e\n",
      "963987676507660288\n",
      "Fun with titties! #boobs #tits @BabesButtBoobs https://twitter.com/BabesButtBoobs/status/963946957441044480/photo/1pic.twitter.com/eVoqGuzzUL \n",
      "963986570134085632\n",
      "i want “you should’ve never called me a fatass kelly price” tattooed across my tits\n",
      "963983044360134656\n",
      "Happy the day of valentine-ing\n",
      "I don't much participate in it myself because uh\n",
      "I haven't had the time, energy or self-worth to have a relationship\n",
      "\n",
      "BUT IT SURE IS A GOOD EXCUSE TO SKETCH OUT TITS REAL QUICK\n",
      "Pointing at @RainBlackKat for the smallest push to actually draw a thing pic.twitter.com/Wb4xq6yEZO\n",
      "963981807896137729\n",
      "The real heroes are the touch starved single women here that haven’t posted a tit pic today for attention. \n",
      "\n",
      "I ain’t no hero. pic.twitter.com/6s9VMBh5RL\n",
      "963980576913936384\n",
      "You’re… you’re kidding, right? Like, this isn’t remarkable in anyway. We have tits, we can just do this. https://twitter.com/TransEquality/status/963962320933326848 … <quoted_status> #Transgender woman becomes the first in the world to breastfeed https://buff.ly/2F4JGbA  via @PinkNews pic.twitter.com/nEBNl6HUXt</quoted_status>\n",
      "963976983339126785\n",
      "Bob had bitch tits.\n",
      "963976131568381952\n",
      "Roses are red,\n",
      "Pogbas got nits,\n",
      "We are Man City, \n",
      "We're all off our tits  https://twitter.com/mancity/status/963744786543988737 … <quoted_status> Let's see who's got the best #ValentinesDay rhymes \n",
      "\n",
      "Roses are red,\n",
      "Manchester is blue,\n",
      "__________\n",
      "__________ pic.twitter.com/W3GxxUkwbM</quoted_status>\n",
      "963961498400849921\n",
      "Show me more! #boobs #tits @BabesButtBoobs https://twitter.com/BabesButtBoobs/status/963948606163243008/photo/1pic.twitter.com/iBxJNcqQvX \n",
      "963956179973165056\n",
      "8 #ValentinesDay tips to improve your relationship, courtesy of international relations:\n",
      "-Say what you mean\n",
      "-Make public promises\n",
      "-“Tit-for-tat”\n",
      "-Forgive\n",
      "-Calling \"stalemate\" isn't a thing\n",
      "-Be rational\n",
      "-An arbiter can help\n",
      "-Sometimes symbolism is important\n",
      "http://53eig.ht/2BY74c2 \n",
      "963956034225233920\n",
      "always tell a sista when her tits look good\n",
      "963955109842620417\n",
      "You can use the IR Camera to upload things into ToyCon Racing...\n",
      "People are going to scan tits and stuff the instant this comes out. pic.twitter.com/0gxv0TlVXb\n",
      "963955041957801984\n",
      "i dyed my hair pink, got “idfc” tatted, and my tits r pierced this is officially my mid life crisis.. lol\n",
      "963944978513907712\n",
      "tits are a great valentine's day present, right? https://marketplace.secondlife.com/p/eL-Big-Tit-Kit-for-Avatar-20/13992960 … #NSFW #SecondLife pic.twitter.com/yYV5I04lOf\n",
      "963941442790944770\n",
      "【NEW】 BIG TITS\n",
      "@ALICEJAPAN @webhakusui  \n",
      "http://ad.dmm.com/ad/p/r?_site=8547&_article=11911&_link=306791&_image=306884&_lurl=http://www.r18.com/special/bigtitssp/%3futm_source=social%26utm_medium=Twitter%26utm_campaign=Bigtits_en …\n",
      "#sex #porn #fuck #tits #boobs #asian #booty pic.twitter.com/K1MX41yzqd\n",
      "963940927650791426\n",
      "http://bigtitsmilf.co.uk  #milf #tits #boobs #bigtits Big tits milf pic.twitter.com/8uXv80pxRS\n",
      "963939666817728513\n",
      "Swiped left on accident showing my manager a pic of some cheese I ate but instead.. swiped to a tit pic in bondage. So happy valentines I guess\n",
      "963936593076801536\n",
      "Want #dm \n",
      "#Rt if your dick is bigger than 5 inc \n",
      "#penis #tits #ass #horny #kik #nudes #dm #snapchat #cumtribute #nsfw #nude #porn #pussy #boobs #cocktribute #booty #ass #xxx #hot #bj #wet #milf #amateur #panties #bra  #lingerie #camgirl #webcam #sexy #dm #dating #kikme pic.twitter.com/hlh8nMFige\n",
      "963934796740218881\n",
      "RT pinupglam: Tessa Fowler is back with another astoundingly gorgeous new video teaser at her site, right now! :)  #boobs #tits\n",
      "http://TessaFowler.Com  pic.twitter.com/VKCEzPhfk7\n",
      "963934743338373121\n",
      "Mommy is online! #sex #tradenudes #pussy #cumtribute #ass #bigass #milfs #milf #bigboobs #boobs #tits #dmme #nudes #horny #fuckme #rp #sexy #butt #booty #porn #cumforme #fuckme #milf #bigtits #hornygirl\n",
      "963934100750036997\n",
      "I hate when people are sad about Valentine's Day like pull your tits out have a vodka soda and be a hoe like any other day\n",
      "963932265796554757\n",
      "Accidentally hit a professor in the boob...felt awkward and said “tit you’re it”....felt more awkward...lil panicky...then she turned to me...laughed and said “good one!” I feel blessed.\n",
      "963929074669416448\n",
      "Gotta have my Titty Mini's with Tit Fil A sauce.\n",
      "963928091730038785\n",
      "Flop your tits one day ash your forehead the next #Louisiana #Mardigras\n",
      "963926421952389120\n",
      "do my tits bother you? they’re covered in Swarovski crystals girl! pic.twitter.com/Ifm8FWRcfC\n",
      "963926260014559232\n",
      "Tits pic.twitter.com/ZhVHc7YX8r\n",
      "963926233221337088\n",
      "A pair of solid tits and good ass is all fun and dandy BUT how’s that personality?\n",
      "963926179454570496\n",
      "gallery hot teen, big boobs, big tits, sexy, blonde, nude, amateur, topless #boobs http://boobsexploit.tumblr.com \n",
      "963926166083026944\n",
      "Joyeuse St-Valentin mes p'tits chats! pic.twitter.com/hFLVojA34g\n",
      "963926148903292932\n",
      "You gonna tell them they’re tits are out in their profile pic ?\n",
      "963926144834854917\n",
      "Make a patreon loads wanna see that pink pussy and tits for some $$$$\n",
      "963926136613933056\n",
      "Best tits on twitter https://twitter.com/nextdoornurs3/status/945035584078217219 …\n",
      "963926133694783488\n",
      "Oh man. Tit face blocked me.\n",
      "963926128749621250\n",
      "Omg I love it and you what a beautiful man inside and out you are\n",
      "963926081131745280\n",
      "free porn group videos porn big tits and ass https://twitter.com/Sophiawwood/status/872461684501360642/video/1 …\n",
      "963926052136542209\n",
      "Is that what's his tits? Seriously?\n",
      "963925992870940672\n",
      "Omg yummy\n",
      "963925956212621312\n",
      "Wanna Play?? >> http://bigtitslive.com  #bigtitslive\n",
      "#teen #milf #babe #tits #pussy\n",
      "963925827229536256\n",
      "\n",
      "\n",
      "Don’t jizz me in the eye? \n",
      "Lol, you old guys won’t even make it to my tits. \n",
      "964625556158509056\n",
      "Tits, glasses and a bear filter = standard Shelbs selfie pic.twitter.com/t8KvNCLNMW\n",
      "964620505411149826\n",
      "Listen I show my boobs cause they look great! I don’t judge anyone who love an asset of theirs and likes to show them off. Plus they’re titties, why you mad at tits bro\n",
      "964644431595884544\n",
      "Toss Samus around by her massive fuck-pillow tits :3\n",
      "964630042247561223\n",
      "u tit \n",
      "964640327515672576\n",
      "Trans has eyebrows that are bigger than her tits. pic.twitter.com/myz5mIMU38\n",
      "964642901228687360\n",
      "Garden tits of the day. pic.twitter.com/mItn7gtl9d\n",
      "964628681955176451\n",
      "really feeling this whole tits out with a feather cape and leather pants look my hunter has going on rn pic.twitter.com/MVcYZDxHtG\n",
      "964632626844831744\n",
      "\n",
      "964634296509255680\n",
      "#RT this and DM me after for more nudes  #snapchatnudes #nudes #snapchatme #tradenudes #nude #tits #boobs #hornyrn #horny #tits #vagina #sex #porno #XXX #anal #ass #BBW #teennudes #bathroomnudes #showernudes pic.twitter.com/GNLMAQ0LgE\n",
      "964605683227398144\n",
      "RT pinupglam: Another jaw-dropper from Tessa Fowler in her new video teaser :) #boobs #tits\n",
      "http://TessaFowler.Com  pic.twitter.com/vCsTxGrbRg\n",
      "964650386983391233\n",
      "Saw #BlackPanther today in a packed theater in Lexington, Ky in the middle of the day. The tits.\n",
      "964647087878131712\n",
      "RT pinupglam: IN-credible Leanne Crow, back with her all-natural L-cup big boobs, with another stunning video at her site. #boobs #tits\n",
      "http://LeanneCrow.Com  pic.twitter.com/HtFZA4gHeC\n",
      "964644120810672129\n",
      "Hearing reports a young Hufflepuff fan was force-fed Polyjuice Potion containing the hair of his own dead Gran so he had to walk about as her for 2 hours while the Slytherin fans sang \"Get your tits out for the lads\" at the poor young lad. Probably won't be back to the quidditch\n",
      "964638074562019329\n",
      "I’m cute and I have amazing tits and I’m never wasting my time on fuckboys again\n",
      "964636892187697153\n",
      "Titty flash in bed! #boobs #tits @BabesButtBoobs https://twitter.com/BabesButtBoobs/status/964414360545247233/photo/1pic.twitter.com/NcG3epJ0fm \n",
      "964636341098205186\n",
      "Ladies, don't be jealous if my tits are bigger than yours  pic.twitter.com/vkBK7wxPy1\n",
      "964634869186822145\n",
      "Establishment Criminal Robert #Mueller's spurious allegations against Russians is bound to be used for tit-for-tat retaliation.\n",
      "The major CIA op to meddle in Russia's upcoming elections will be shut down, US gov funded \"NGOs\" & FB kicked out.\n",
      "Putin's approval rating will go up. pic.twitter.com/CpCOPvsDcT\n",
      "964631258679693333\n",
      "#FriskyFriday ! Today’s rise and ride lol  have a great weekend luvs! #hotwife #Amateur #tits #boobs #Fuckmefriday #hornywife #milf @amateurissimo @flashingwives #MILFMafia pic.twitter.com/YcyNkn69K2\n",
      "964629896415752192\n",
      "@DianeBusty\n",
      "Huge titscaptivating smileDiane is elegant and classy lady sign up and join her show\n",
      "https://imlive.com/referred/BustyDiane …\n",
      "@timjack2017\n",
      "@carlosbb588_bb\n",
      "@STFPromo\n",
      "@PromoteModel\n",
      "@CMP_4U\n",
      "@hungchimichanga\n",
      "@Ipertrofia300\n",
      "@Jaknez\n",
      "@Rtthishotstuff\n",
      "@iKaylaSky\n",
      "@DamasHermosas pic.twitter.com/QHFGM3osNs\n",
      "964626904538951680\n",
      "Don’t jizz me in the eye? \n",
      "Lol, you old guys won’t even make it to my tits. \n",
      "964625556158509056\n",
      "if i breastfeed any longer my tits are going to fall off \n",
      "964621853623926784\n",
      "Tits, glasses and a bear filter = standard Shelbs selfie pic.twitter.com/t8KvNCLNMW\n",
      "964620505411149826\n",
      "Is Satan's cock as cold as a witch's tit. \n",
      "964618989749047303\n",
      "Titty out! #boobs #tits @BabesButtBoobs https://twitter.com/BabesButtBoobs/status/964414947458297857/photo/1pic.twitter.com/YnnP4MPlx5 \n",
      "964616941980839937\n",
      "I have so much dirt in my bra right now I’m thinking about starting an organic tits farm.\n",
      "964611862045245440\n",
      "Just dug out one of my most prized possessions, my parents bought this for me not knowing it had tits AND bush, very formative pic.twitter.com/0nzfmjsByO\n",
      "964609773474844678\n",
      "Check out her big curves! #boobs #tits @mostlyboobz pic.twitter.com/jzl24pjBVv\n",
      "964605918309732352\n",
      "Big Tits Titten Tetas\n",
      "Find me on Facebook\n",
      "https://www.facebook.com/boobyfairy/  pic.twitter.com/Kr0xnYORkL\n",
      "964599875336916992\n",
      "Love Big Tits? \n",
      "Big Tits Titten Tetas\n",
      "FREE!!! PORN!!!!!! \n",
      "http://BOOBYFAIRY.com  pic.twitter.com/JozFWWxRa2\n",
      "964596835485667328\n",
      "Your tits are as hypno as a skull\n",
      "964593035244863495\n",
      "Blue Tit @WhisbyNatureRes late afternoon. pic.twitter.com/cRm5nYddHb\n",
      "964587582783938561\n",
      "You grab a basket and wander around the fruit section. You can't shake the feeling you forgot why you're here - @GuacaMochni\n",
      "\n",
      "< Is that a pear? An avocado? \n",
      "< Tits at a grocery store? \n",
      "< Seriously what is that? Is it a fruit? pic.twitter.com/j3j3tKcqpA\n",
      "964583636229115909\n",
      "black hair, tits out and diamond choker? beyoncé could NEVER #iHeartAwards #BestFanArmy #EXOL @weareoneEXO pic.twitter.com/uHtWEWFiy5\n",
      "964583415046688768\n",
      "Harry/Bill fake: Tits \n",
      "Everyone on fl: Omg so true fuck me\n",
      "964581976949735425\n",
      "This is a mukbang right? Tits out, mouth stuffed  pic.twitter.com/vNdQTExtrX\n",
      "964578749000880128\n",
      "Don't you just love a Blue tit on a sunny day @NTCalkeAbbey  ? pic.twitter.com/00G27kpI3p\n",
      "964572254796484608\n",
      "This site is tits. \n",
      "THE DRONE INVASION – 30,000 Drones Approved for US Skies, Drone High-Tech Psychotronic, (Psychological Electronic) Mind Invasive​ Technology, and Official Beamed ADS Torture Subjugation\n",
      "https://youarenotmybigbrother.blog/2017/08/09/the-drone-invasion/ … pic.twitter.com/6Vm9FYq3QX\n",
      "964568314080096258\n",
      "Fluked 2 Long-eared Owl while looking for Willow Tit...a return visit today & found a least 4 in a roost...3 well hidden in ivy with another out in the sun @LongearedOwlne1 pic.twitter.com/m32UXrAXGu\n",
      "964567323653926912\n",
      "I've just hired a nineteen year-old Swedish girl with massive tits to babysit my kids.\n",
      "Now, where the fuck am I going to get some kids from?..\n",
      "964564153326292992\n",
      "Start the weekend with Katy's tits.  pic.twitter.com/WMBcIj8pW3\n",
      "964564066957234177\n",
      "What a waste of space. 3rd Lady Melania Trump using her valuable platform to buy shoes & get massages. #embarrassment. Your \"heart is heavy\"? That's because your $20,000 tits are dragging it down. By the way, who wrote that line for you? U call urself a mother. Yeah..\n",
      "964563419969064961\n",
      "BOYS: talk about a womans tits and ass behind her back\n",
      "\n",
      "MEN: talk about a womans birthing hips and her future softball playing abilities right to her face\n",
      "964562353923743745\n",
      "Lives were changed as a result of that video... with money that would’ve been spent on car rentals and girls with fake bums & tits. Just shut up man\n",
      "964557812394352640\n",
      "I’m so over seeing all the nonsense about guns. ITS THE FREAKING PERSON FOR GOD SAKE. Guns save peoples lives every single day just like they are used to killed people. Literally tit for tat  plz stfuuuuuuuuuuuu.\n",
      "964557298520739841\n",
      "Is that a Blue Tits tongue I see?! pic.twitter.com/PbeHMcpnv8\n",
      "964556044100952066\n",
      "(wearing a sweater with no bra to friday night services) tits out for shabbat\n",
      "964555584514215936\n",
      "This bearded tit kept us company today whilst working on the Freshmarsh #rspbtitchwell #digibinned @RSPBintheEast @Natures_Voice @BBCSpringwatch pic.twitter.com/htbGhCZ3WZ\n",
      "964553910672293889\n",
      "someone please tit fuck meeee\n",
      "964553849523654658\n",
      "My tits are ready for it #cumtribute pic.twitter.com/zjCfqWIopQ\n",
      "964553330562396160\n",
      "she sed do u luv me i only tel her partly i only luv ur ass and ur tits ya im sorry\n",
      "964551738274566145\n",
      "Long-tailed Tits -pm- Bowesfield Marsh, Stockton\r",
      "Nikon P900\r",
      "@clevelandbirds pic.twitter.com/XDzFv5wQqR\n",
      "964551715717599234\n",
      "Whyyyyyy do women still have to pay for bras/birth control/pads/tampons? We didn't ask for periods, or tits, or a god damn womb. These things aren't treats, they are necessities. \n",
      "SORTITOUT\n",
      "964550775740469253\n",
      "50 shades of Sugar Tits and you can’t have any of them.\n",
      "964543980389191682\n",
      "Titty slapping fun! #boobs #tits @mostlyboobz pic.twitter.com/DUr2K5w6NQ\n",
      "964540703819911168\n",
      "Kate Garraway those big gorgeous tits of yours  pic.twitter.com/uHVS3FzeUE\n",
      "964539564688924672\n",
      "Saw my first Willow tits for many years at #PenningtonFlash this week, such cute little birds which proved very difficult to photograph as they never kept still. pic.twitter.com/RHoZEOuhh5\n",
      "964535029304045569\n",
      "Well that’s what he gets for showing his tits https://twitter.com/thewrap/status/964526880643727360 … <quoted_status> Elton John Gets Struck in the Face by Mardi Gras Beads During Vegas Performance (Video) https://goo.gl/oqd6Df  pic.twitter.com/IKva0dl86T</quoted_status>\n",
      "964527227303063556\n",
      "Sucking my nipples is cool and all but I'm going to need you to put the whole tit in your mouth\n",
      "964516332598382592\n",
      "See my tits for the same price as a small coffee\n",
      "964512401231171584\n",
      "Check out ALL my gifs of this amateur with huge tits!\n",
      " \n",
      "  http://bit.ly/HugeTitAmateur   pic.twitter.com/X9fsiESYqp\n",
      "964504846454984704\n",
      "There’s nothing more attractive than a girl who can completely school me in something I think I know about, and also big tits\n",
      "964503571629682689\n",
      "Libra: Today you will experience a great malaise and ennui. I mean, as malaises and ennuis go, this one's the tits. Some people say that the Pickering, Ohio malaise and ennui of 2014 was the best. But compared to this one that shit's amateur hour.\n",
      "964501169568497665\n",
      "Today in #FunnyNature: ornithological #DRAMAS\n",
      "Why Do #Birds Get #Divorced?\n",
      "For blue tits, timing can be a factor in whether they remain together or part ways\n",
      "Credit: F. Moglia @sciam\n",
      "@CornellBirds @_BTO @AmOrnith @FieldOrnith @WilsonOrnithSoc @Birds_UK\n",
      "http://mf.tt/cQqrDr  pic.twitter.com/TPd9cowCFz\n",
      "964499649313853441\n",
      "Grab life by the tits and French kiss the shit out of her\n",
      "964492468195557376\n",
      "As it's #NationalNestBoxWeek how about this: A graphically discerning blue tit family... (we put one of these on every Green Roof Shelter) @GreenRoofShelt pic.twitter.com/63PZwAyV0c\n",
      "964488517094137856\n",
      "japanese jin stans wondering why bh covered jin's tits but not tae's torso shdvs\n",
      "964485583576936449\n",
      "Im gonna be drawing up some NSFW stuff for my patreon soon, prepare for tit pic.twitter.com/DuwF8APOdF\n",
      "964483383840698368\n",
      "G.Riesel and his string of Radio Taxis Mercedes cars remember this business went tits up,If Gett drivers are happy having there work taken away by PH Porsche drivers then you need to sell your cab or return to your renter and ge t a Prius and go work with Uber\n",
      "964482279702659073\n",
      "RT. If you'd #cum hard on my face or huge in my mouth after a perfect #blowbang, or #cumtribute my #sexy ass too. ;)\n",
      "\n",
      "#cuminmouth #blowjob #slut #hoe #jizz #gangbang #cumshot #milf #whore #sexy #hot #cumdumpster #cleavage #tits #cumslut #brunette #doggystyle #creampie #anal pic.twitter.com/NFgclyfuvH\n",
      "964481530872594433\n",
      "60+ Bewick’s swans over UEA this morning. Also re-trapped a blue tit I ringed on my first outing as a C permit holder. The bird was ringed as a fledged chick in 2015 making it almost 3 years old, nice to see it doing well at the @UEARG feeders! \n",
      "964464296729116674\n",
      "The Alliance party have made right tits of themselves this morning pulling out of committee because of Jamie Bryson???? The cheer leaders for tolerance and democracy?? Dear o dear.\n",
      "964460538540494848\n",
      "\"I'm yaojou, AKA the best jou!\"\n",
      "\n",
      "• Lewd jou \n",
      "• Can hypnotise\n",
      "• Queen of sweaters\n",
      "• Twitch streamer\n",
      "• Mains widowmaker \n",
      "• Tits and ass for days\n",
      "• Bi switch (slight dom lean)\n",
      "• Lookig for the rest of the Jous\n",
      "\"Retweet this and you MAY get lucky~\" pic.twitter.com/x3KxBi5CyV\n",
      "964460102274166784\n",
      "Tuneage! I can't wait to go to this event! Who's going? I want to meet you all, learn stuff, geek out, drink too much, and dance like a tit! @esa @spacerockslive #SpaceRockshttps://twitter.com/spacerockslive/status/964453186416365568 … <quoted_status> Check out the video for Sigma by our session three headliners, @LordConnaught project Lonely Robot! Concept album about a lone astronaut waking up from cryogenic sleep anyone? #spacerocks https://www.youtube.com/watch?v=usJwSq9Gudk …</quoted_status>\n",
      "964454539490455553\n",
      "Ok, on fait un constat, mais d’abord un p’tit selfie! pic.twitter.com/pa5W6akfPR\n",
      "964453230347472898\n",
      "My wife asked me to pour her a bath of milk for her complection.\n",
      "\n",
      "Pasteurised?\n",
      "\n",
      "No.....just up to my tits will do.\n",
      "964446672402173952\n",
      "Shit like this does my tits in. Cost of players has risen 40 fold from 30 years ago. https://twitter.com/FootyAccums/status/964431510043377664 … <quoted_status> Pep Guardiola is only around £100m off outspending Fergie's entire 26 year reign at Utd!\n",
      "\n",
      "He's been at City 18 months...  pic.twitter.com/sd7gRNScYb</quoted_status>\n",
      "964443280732753920\n",
      "NewNeneYoshitaka\n",
      "The Gravure Idol Sticky Tongue Kissing Excited Deep Kiss Sex - Nene Yoshitaka\n",
      "@S1_No1_Style\n",
      "http://ad.dmm.com/ad/p/r?_site=8547&_article=11911&_link=306791&_image=306884 …\n",
      "&_lurl=http://www.r18.com/videos/vod/movies/detail/-/id=ssni00115/%3futm_source=Social%26utm_medium=Twitter%26utm_campaign=Kissing_NeneYoshitaka …\n",
      "#sex #porn #fuck #tits #boobs #asian #booty #adult #creampie #JAV pic.twitter.com/FpgxdgoUuF\n",
      "964439225084002304\n",
      "TANA JUST ACCIDENTALLY FLASHED HER TITS TO COPS\n",
      "964427538528313344\n",
      "Nothing better than a chilled Margarita, Steak and a Good hump in the afternoon\n",
      "\n",
      " #sexy #sex #tits #cleavagefordays #milfs #milf #babes #lesbo #boobs #horny #hot #ass #butt #sultry #baby #hotness #sluts #slut #slutty #bitch #cunt #cock #porn #hot #sexydweepa4U #bangmebaby pic.twitter.com/xcVDdbdMte\n",
      "964426345601122304\n",
      "I know you like the bird watching Field Marshall but that weird cackling noise you are making is \n",
      "getting on my tits. pic.twitter.com/mqxplsDEnw\n",
      "964417411746115584\n",
      "Another vid sold! Tits bouncing on top (toy. Get yours here https://www.manyvids.com/Video/618349/Tits-bouncing-on-top-toy/ … @manyvids #MVSales pic.twitter.com/HlPL3Sx103\n",
      "964414966332731392\n",
      "Topless hippie chick! #boobs #tits @TheBustyweb pic.twitter.com/jWI1T2R7qf\n",
      "964414098225094656\n",
      "Blue tit. @BBCSpringwatch @WildlifeMag @Team4Nature300 @NatureUK @Natures_Voice @NaturalEngland @britwildlife @Britnatureguide @BritishNature @britishbirds @BritBirdLovers @KentWildlife @WildlifeTrusts @wildlife_uk @Birds_UK @WoodlandTrust @BTO_GBW pic.twitter.com/Qx8Gdb31qL\n",
      "964413161766965248\n",
      "It’s really not rocket science @marcorubio. You received $3.3M from the @NRA and you have to think about and discuss more? We dramatically affected these problems in our country. Do the right thing. Get off the @NRA tit and take a stand. #timetoacthttps://twitter.com/ditzy_horse/status/964208753032683522 … <quoted_status> People said we couldn’t stop car crashes. We improved the drivers licensing program, put in speed limits and all of a sudden crashes fell 90%. \n",
      "\n",
      "They said we couldn’t stop airplane hijackings. We improved security measures at airports and they fell 99%.\n",
      "\n",
      "We can stop shootings too</quoted_status>\n",
      "964408643641683969\n",
      "I've just been watching a pair of blue tits flitting around on the pruned roses out front at home. What a delightful way to start the day.\n",
      "964406606225002497\n",
      "I can’t wait to spend time outdoors and not be freezing my tits off\n",
      "964406570468519938\n",
      "Big boobs are CUTE\n",
      "Little tits are CUTE\n",
      "Big buts are CUTE\n",
      "Small buts are CUTE\n",
      "Tiny bellies are CUTE \n",
      "Big tummies are CUTE\n",
      "\n",
      "WHAT ISN'T CUTE IS SHAMING SOMEONE ELSE'S BODY JUST BECAUSE IT'S DIFFERENT THAN YOURS!\n",
      "THERE'S NO RIGHT OR WRONG WAY TO HAVE A BODY!\n",
      "964405734585675776\n",
      "‘oh I’m gonna put tits on asimo and make him a citizen of Saudi Arabia’\n",
      "have fun I’m gonna get rawed by the one that can sprint across ten miles of uneven ground to step on my neck\n",
      "964405604453302272\n",
      "not to suck my own tit or anything but i’m wayyyy too nice to ppl who don’t even deserve my time\n",
      "964404317066215424\n",
      "she better not be using an emoji cause robin from htbs is gonna come tit punch her if she is pic.twitter.com/iOgn62cn2V\n",
      "964403425008996353\n",
      "Shes scary and i hate when she calls me Idiot\n",
      "964402543953567744\n",
      "Are you a boob guy?\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "@BritishBabesInc @babesofbrit @bringbackpage3 @CMP_4U @AdultWorkCam @LondonSapphires\n",
      "#tits #bigtits #bigtitties #camgirl #webcamgirl #glamour #slut #adultwork pic.twitter.com/0uSehtI8g2\n",
      "964395384381480966\n",
      "Some birds struggle to find a suitable places to nest, so a nest box in your garden will really help our feathered friends. Nuthatches  and blue tits use a small nest box with a small hole, whereas starlings & woodpeckers need something a little more roomy.  #NationalNestBoxWeek pic.twitter.com/UwBmJl8dU5\n",
      "964395206341619712\n",
      "bish ill be seeing fifth harmony in weeks, how to calm my tits\n",
      "964386137216188419\n",
      "PENDULINE TIT - Better light yesterday in Gloucester @RareBirdAlertUK @Southglosbirds pic.twitter.com/5SD4gehizj\n",
      "964384656534614016\n",
      "#FriskyFriday\n",
      "The gorgeous @KimberleyJxxx  \n",
      "Looking as sexy as ever\n",
      "She is a beautiful hot    babe \n",
      "#sexy #amazing #Gorgeous #UKno1babe #juiceymelons #Tits #boobs pic.twitter.com/2zO4l97HyJ\n",
      "964382473252581376\n",
      "Impressive knockers! #boobs #tits @TheBustyweb pic.twitter.com/87B2m4JhON\n",
      "964377594337505281\n",
      "“With my tits and your ass, were unstoppable”\n",
      "964375535282405376\n",
      "Yeah getting $1000 to show your wet tits to a whole bar is cool and all, but someone accidentally left $20 in the ATM for me last night and that’s what I call winning \n",
      "964372241491230720\n",
      "holy tits pic.twitter.com/YfM9fK5SIC\n",
      "964371145192386560\n",
      "Fareeha: send a tit pic \n",
      "Angela: here  pic.twitter.com/hIdOyr9iRb\n",
      "964362902151950337\n",
      "Bonjour Twitter #libertine #coquine #hotwife #exhibition #ngot #bigboobs #tits #GoodMorningWorld pic.twitter.com/K6dEPikIMk\n",
      "964356199100526592\n",
      "any size tit is lit https://twitter.com/itslenhoe/status/964349779642793984 …\n",
      "964350987250135040\n",
      "I was dumping downstairs at Sluggers while you were still suckin' on your mama's tit. https://twitter.com/DaWolfOfStateSt/status/964347127773237248 …\n",
      "964349183023988738\n",
      "It aggravates me how some men have such a small concept about females. Men who think the only things a female can offer are pussy, head, tits and ass says a lot about their intelligence and respect they have for any female figure in their lives.\n",
      "964347547765493761\n",
      "Stella and her big tits omg pic.twitter.com/9vNj9zrl43\n",
      "964346754350002176\n",
      "today kaitlyn sent me a picture of her hands covering her tits as a joke but she didn’t know it was a live picture and at the very end she took her hands away and both nips were out. do you call that a date?\n",
      "964343943252119557\n",
      "my tits are shaking from sudden anxiety\n",
      "964343912130326529\n",
      "If you touch my tattoos, im touching your tittays...tit for tat..\n",
      "\n",
      "-dems the rules\n",
      "964342606909071360\n",
      "Boom! #tits #boobs @mostlyboobz pic.twitter.com/10IcCMkhJp\n",
      "964342454559363073\n",
      "Little Valentine shoot  like/Rt for nude version #tits #cock #bbc #cumtribute #nude #tradenudes #dm #horny #ebony #nike #cumslut #cock #cum pic.twitter.com/CXLIIV1agN\n",
      "964340681526390784\n",
      "i’ll DM a special pic to whoever #likes and #retweets my pinned post\n",
      "#tits #ass #sex #cumslut #cockslut #cocktribute #slut #cumwhore #horny #nudes #cumslut #cocktribute #dm #gay #lesbian #blowjob #wetpussy #fuckme #whore #pussy #cum #dating #boobs #bikini #milf #dating\n",
      "964338692373401600\n",
      "All this could add up to bad news for India at the World Trade Organisation.\n",
      "\"Trump Signals Tit-For-Tat Duties To Punish PM Modi's Move\" - NDTV https://www.ndtv.com/india-news/prime-minister-narendra-modi-sets-stage-for-trade-war-with-import-duties-foreign-media-1812964 …\n",
      "964334229344718849\n",
      " Being  a  creative  streamer  is  the  hardest\n",
      "\n",
      "\"draw tits\"\n",
      "\n",
      "\"draw naruto\"\n",
      "\n",
      "\"your art sucks\"\n",
      "\n",
      "\"PLAY FORNITE\"\n",
      "\n",
      "         \n",
      "964323972048306176\n",
      "We tits AF and Cheers to peeps,\n",
      "The hashtag man cave be rolling deep. \n",
      "\n",
      " #MyTwoLineRap\n",
      "964320788408098818\n",
      "RT pinupglam: It's finally up!  It may be a day late, but super sexy and supremely busty Samanta has a brand new big tits Valentine at PinupFiles just for you! #boobs #tits\n",
      "http://PinupFiles.Com  pic.twitter.com/FVgpYwm8O9\n",
      "964320728651911168\n",
      "I saw my life flash before my eyes and had an implosive mental episode in those 30 seconds between shangela talking and pulling the lipstick out of her tit\n",
      "964319066990182400\n",
      "Today I threw on my Shinpads shirt and rewatched seasons 1 & 2 of Holliston. It was tits. Season 3 needs to happen. #HollistonNation #SidewaysBigMac #IMissOderus @Adam_Fn_Green @clenglish @TheJoeLynch @LauraTiz @deesnider pic.twitter.com/6E1ISMzk47\n",
      "964310834112548864\n",
      "Scouts from ARI/BUF/MTL/OTT/CRO/HTY/FRH/TIT/LBR/GCJ/LQE/FRT/SMF/BLA/J/BTT and CÄ€ are at games tonight\n",
      "964309358661136384\n",
      "Cleavage for days! #boobs #tits @TheBustyweb pic.twitter.com/UWSRacz19A\n",
      "964308919244984320\n",
      "Daily Ranking\n",
      "http://ad.dmm.com/ad/p/r?_site=8547&_article=11911&_link=306791&_image=306884&_lurl=http://www.r18.com/videos/rankings/movies/type=daily/?%3futm_source=social%26utm_medium=Twitter%26utm_campaign=Daily#sex … #porn #fuck #tits #boobs #asian #booty #adult #creampie #JAV pic.twitter.com/QNqAby5GCJ\n",
      "964307679471583232\n",
      "When !!! Will !!! Ma !!! Tits !!! Grow ?!????\n",
      "964306737045131264\n",
      "Of course I'm a nut case\n",
      "\n",
      "I have tits and a vagina\n",
      "964306181501128704\n",
      "Instagram: Picture of a girl clearly showing off her cleavage. \n",
      "\n",
      "Her friends comment \"Tits, boobs\".\n",
      "964304244387057666\n",
      "【NEW】 BIG TITS\n",
      "@honnaka_nama @Fitch_official  @Mio_Kimijima @wakana_nao_all\n",
      "http://ad.dmm.com/ad/p/r?_site=8547&_article=11911&_link=306791&_image=306884&_lurl=http://www.r18.com/special/bigtitssp/%3futm_source=social%26utm_medium=Twitter%26utm_campaign=Bigtits_en …\n",
      "#sex #porn #fuck #tits #boobs #asian #booty pic.twitter.com/2mzCSsHHdt\n",
      "964303317592629249\n",
      "Not to suck my own tit or anything but damn I’m fucking funny and cool af\n",
      "964298761605451776\n",
      "Some millennial just said I’m 678 years old and he hasn’t even seen my tits or my bhole yet.\n",
      "964298152714035200\n",
      "Giant pointy hooters! #boobs #tits @mostlyboobz pic.twitter.com/TOZyU5IXnT\n",
      "964294698566410240\n",
      "#Tits all out for tonight, let us smother them in your face!! @CindyStarfall #asianinvasion pic.twitter.com/6UxBxk3dSI\n",
      "964289645818281984\n",
      "@JemimaNash happy birthday my princess  see you saturday big tits x ly xxxxx pic.twitter.com/qrvzWWTZbs\n",
      "964289540440674304\n",
      "He’s got the whole wide TIT in his hands  #SorryJesus\n",
      "964289515388129280\n",
      "Right, love those tits\n",
      "964289467153559552\n",
      "So u got milk in them tits yet? — no https://curiouscat.me/jjdollasiign/post/321789469?1518739405 …\n",
      "964289416805175296\n",
      "http://ow.ly/4n9AjP  <-Hot German Milf Fucked Young Boy #porn #xxx #adult #naked #nude #teen #nsfw #bath #bubble #tits #boob\n",
      "964289259715743745\n",
      "VIDEO: My amazing tits in my soft white rope  https://iwantfanclub.com/timeline/the_danish_goddess … #Subscribe #Fans #FanClub #iWantFanClub\n",
      "964289155856347136\n",
      "Sold my vid! Rough Face And Tit Slapping Fuck Session. Get yours here https://www.manyvids.com/Video/611820/Rough-Face-And-Tit-Slapping-Fuck-Session/ … @manyvids #MVSales pic.twitter.com/x33qiEnNS6\n",
      "964289058183794688\n",
      "Calling the store is probably your best bet. I called mine but they said they get two shipments a week, and I didn’t feel like asking anymore questions cause they probably could tell that I’m not an adult and I hate talking on the phone\n",
      "964288812196290566\n",
      "getting rid of negative energy is the tits\n",
      "964288577877303297\n",
      "It looks so good dude. Even better in person!!!\n",
      "964288528409612288\n",
      "THIS is your idea of honoring these young children who were senselessly gunned down?Flying a flag at half mast?You & all these @GOP need to stop sucking at the NRA tit and do your job!There is no reason why anyone needs to own an AR-15, especially someone with a mental illness\n",
      "964288229464616960\n",
      "My life is just a constant cycle of  using girlo phrases ironically, then getting genuinely addicted and making them part of my everyday vocabulary, finally resulting in sounding like a massive tit on a regular basis\n",
      "964995598918279168\n",
      "Prince Naseem off is tits right now! Eyes are fucked and can’t shut up \n",
      "965005953799217152\n",
      "All these girls coming at me sideways because of the two pictures I posted yes I have tits and you clearly don’t. Jealousy gets you nowhere you just look jealous but thank you for taking the time to look at my cleavage like everyone else \n",
      "965006888193622016\n",
      "pity party: over \n",
      "\n",
      "tits: out \n",
      "\n",
      "potential break up song by aly & aj: on\n",
      "965002341677260807\n",
      "the only reason i get to meet celebrities is because i have big tits? thats not true. i meet famous people the same way everyone else meets famous people...... i sleep with their manager\n",
      "965006361565294593\n",
      "\n",
      "\n",
      "Prince Naseem definitely sniffed off his tits\n",
      "965007403187097601\n",
      "Wish I could say this top lasted. One hug and that my tits out in middle of Shanghai. Happy bday 2 me  pic.twitter.com/ikYeTzj5jF\n",
      "965007765579223040\n",
      "Well i am #TumshieInTransit #TiT again after a few beers and a massive amount of deep fried shit from the blue lagoon\n",
      "964984857955913728\n",
      "Dear the BBC\n",
      "\n",
      "Can we have Gabby Logan presenting Match of the Day every week instead of that tit Lineker please? #MOTD\n",
      "964991633447182337\n",
      "Can this gorgeous son of a tit STOP WORRYING ABOUT THAT FOOKING PIMPLE HE LOOKS FLAWLESS pic.twitter.com/3PyLOz3jfP\n",
      "965005997575213056\n",
      "Eubank celebrating like hes won the fight just proves what a fucking tit he is, him and his dad pair of inbreds\n",
      "965001579731521536\n",
      "hi i'm at the beach and i have sandy tits pic.twitter.com/z6V7j6wu4L\n",
      "965008671422914560\n",
      "Emma flashed her tits in the SF Dave and Buster’s and got us kicked out. How’s your Saturday\n",
      "965005235784581122\n",
      "i was actually protecting my self........fro\n",
      "m ermmm.....sarah lau.....she kept hitting my tits when she was pissed at me.....lol\n",
      "964985114533990401\n",
      "Boobs out the window! #tits #boobs @TheBustyweb pic.twitter.com/IXRRlF3RwT\n",
      "965009904590311425\n",
      "The Trumps went to a \"Studio 54\" party that night.\n",
      "\n",
      "Melania wore her halter disco dress -  tits out -  to meet First Responders. Nice touch.\n",
      "\n",
      "#TrumpTramp\n",
      "\n",
      "(The Trumps cowardly avoided the affected families)\n",
      "965008288776470528\n",
      "Various Tits on feeders at RSPB Sherwood.  @RSPBSherwood @NottsBirders @Britnatureguide @NatureUK @wildlife_uk pic.twitter.com/nagSGcgRpU\n",
      "965007357754462208\n",
      "Why do they call it the wonder bra? \n",
      "\n",
      "When you take it off you wonder where her tits went \n",
      "965006962265083906\n",
      "Meek Mill \"has support from the whole world,' Olympic snowboarder Tit Stante says   http://blbrd.cm/BxFaDn  pic.twitter.com/LCtlIKn8UF\n",
      "965002859690561537\n",
      "Dude!!!! The other night a girl was staring at my tits and she literally went into my shirt and started grabbing my tits. I said fuck that and lost my shit. And she was like ‘we are both women it’s fine’ \n",
      "NO it’s fucking NOT. I’m tired https://twitter.com/waviestbaby/status/964831029159710720 … <quoted_status> Some girl groped me last night, when I turned around to confront her, she said \"It was me, not him, don't worry\" (she was with a friend).\n",
      "\n",
      "I don't care who the fuck you are, I don't care if you're a man or a woman. You do not touch another person without their consent.</quoted_status>\n",
      "965001191649198080\n",
      "Hashtag Back A Tit? #Storyofmylifehttps://twitter.com/gabbyv1003/status/964995138522173442 … <quoted_status> @chrisrankin I see you with that wild hair!!!! Watching Harry Potter on our new 55\" led TV!!!!!#backattheweasleys #backatit pic.twitter.com/CAbUIqCPEr</quoted_status>\n",
      "964998833108344832\n",
      "My life is just a constant cycle of  using girlo phrases ironically, then getting genuinely addicted and making them part of my everyday vocabulary, finally resulting in sounding like a massive tit on a regular basis\n",
      "964995598918279168\n",
      "Tit Stante speaks out about why he wants to #FreeMeekMill. http://www.thefader.com/2018/02/17/tit-stante-on-free-meek-mill?utm_source=tftw … pic.twitter.com/skBipCqwBo\n",
      "964992028860874757\n",
      "Whos ready?!! Big game at #allenfieldhouse tonight! Lets get that \"W\" #KUbball !!  #kuboobs #kufan #KUCMB #GameDay #rockchalk #Jayhawk #rcjh #kansasmodel @KUboobs @BestOfBurnsDay @TugTuesdayTop10 @TIT_Lovin_Libra @HornDawg70 pic.twitter.com/4ETJwSdr6o\n",
      "964985369723883522\n",
      "i was actually protecting my self........fro\n",
      "m ermmm.....sarah lau.....she kept hitting my tits when she was pissed at me.....lol\n",
      "964985114533990401\n",
      "My tits were covered today. \n",
      "\n",
      "One memorial down, one more to go. pic.twitter.com/BXaKD8VR5E\n",
      "964977310238691329\n",
      "stage 1: seeing lewd art of a favorite character and liking it in your head\n",
      "\n",
      "stage 2: seeing lewd art of a favorite character and liking the tweet despite the odds of it popping up as \"________ liked\" reminder tweet to one of your followers\n",
      "\n",
      "stage 3: fuck it, just retweet the tit\n",
      "964975251800182796\n",
      "Woke up in @tylergrosso bed last night shorty was showing us a beautiful Tit very therapeutic vibes\n",
      "964975061395324928\n",
      "Never thought I’d get tired of seeing tits, but 9 episodes of Altered Carbon has given me my fill\n",
      "964972100967649280\n",
      "Suck on her tits & tell her she's awesome\n",
      "964968829238603776\n",
      "got ditched by a grungy ass dude for a girl w saggy ass tits last night so\n",
      "964966120749846528\n",
      "Huge heavenly hooters! #boobs #tits @TheBustyweb pic.twitter.com/ReA4abnz7o\n",
      "964963496214622209\n",
      "Long tailed Tits at Old Bewick, Northumbs today. pic.twitter.com/EoTxVW7B1d\n",
      "964960169598898176\n",
      "Feeling naughty, rt for a dm #horny #dm #dick #tits #nudes #teengirl #snapnudes #teens #nsfw #bored #porn pic.twitter.com/udSb4VClOE\n",
      "964959706182770693\n",
      "European Stonechat (ssp. hibernans) from Plock Court, Gloucester this AM; no show of Eurasian Penduline Tit following a 6hr wait with H. King & D. Owen - @vikingoptical pic.twitter.com/GaLvHbbrJa\n",
      "964959527736094721\n",
      "Like and RT to get me to 700 followers!!  @BestOfBurnsDay @TugTuesdayTop10 @TIT_Lovin_Libra #boobs #milf #thanksforfollowingme pic.twitter.com/uFR16j5zoM\n",
      "964958783129751552\n",
      "A nice walk around @RSPBLangford shame no bearded Tits but 8 male bullfinch in 1 tree and loads of goldfinch @RSPBMidlands @NatureUK pic.twitter.com/6yKfMDmAEN\n",
      "964958687365337089\n",
      "Check out ALL my gifs of this amateur with huge tits!\n",
      " \n",
      "  http://bit.ly/HugeTitAmateur   pic.twitter.com/CcQ0cOuejD\n",
      "964957518186283009\n",
      "I have this theory that traps are the boobs of CrossFit. So I guess this is me showing off my tits. https://instagram.com/p/BfT38-yhwWR/  pic.twitter.com/P2WTne2tFQ\n",
      "964953788598513664\n",
      "My tits are a gateway drug\n",
      "964953292634820608\n",
      "Drascus has tits rt\n",
      "964951516925825024\n",
      "Bitch im celibate\n",
      "Put away your dicks\n",
      "Put away your tits\n",
      "Put away your clits pic.twitter.com/eG2jWkepIy\n",
      "964947729330950145\n",
      "19-year-old Slovenian snowboarder Tit Stante: “I wanted to point out that the U.S. justice system has a lot of flaws” http://p4k.in/9EoR7Rx \n",
      "964945558581465089\n",
      "QUALITY: We pay two writers to copy some clearly made up bullshit from The Sun because there’s the chance to print some tit shots for free. pic.twitter.com/wXGvKUpVyQ\n",
      "964945372039741440\n",
      "You know what they say about Hell Hath No Fury… Tit 4 Tat is #FreeonKU http://getBook.at/Tit4Tat  #RomHero #lprtg #gr8books4u #erotictalesselect pic.twitter.com/XlXA5CAEFE\n",
      "964938766858244097\n",
      "oh gosh holding hands is better than holding tits\n",
      "964932683594981377\n",
      "Fuck knows who you are but you're off your tits love.\n",
      "964931789344182274\n",
      "I'm still here and writing music by the way lads \n",
      "\n",
      "I ain't gone away \n",
      "\n",
      "I'm buzzing off my tits for you to see my new shit \n",
      "\n",
      "I've completely changed my genre and on-stage set up \n",
      "\n",
      "It's awesome \n",
      "\n",
      "You'll love it \n",
      "\n",
      "Because you're all awesome \n",
      "\n",
      "Who's buzzed?\n",
      "964929621820141570\n",
      "you’re givin me hella 2000’s vibes w that fit mmm girl if anyone can really rock low rise jeans it’s you!!! also tits on mf point!!! bangs are bangin!!!! i love u!!!!! https://twitter.com/alythuh/status/964927148963188737 …\n",
      "964929002119950336\n",
      "If the Cold War in the Third World did matter to the outcome of the cold war in some way, it was by inducing the USSR to allocate more of its resources to silly adventurism. It was expensive for the USA, but military tit-for-tat was relatively even more expensive for the USSR\n",
      "964928698284638208\n",
      "I do love seeing the #birds in my #garden\n",
      "Today it’s a great tit and a sparrow\n",
      "\n",
      "#LEGO #AFOL #greattit #tits #sparrow #birdwatching pic.twitter.com/9kJgwAoIg5\n",
      "964921279064215553\n",
      "if he’s busy but has the time to like other girls tit pics i’m sure he has more than enough time for you he’s just trash\n",
      "964921263641767936\n",
      "A few from Shilito Wood @DerbysWildlife Chaffinch,Reed Bunting , ,Blue Tit and  Yellowhammer pic.twitter.com/u1y47NB6jO\n",
      "964917459835932673\n",
      "left one is old but i wanted to draw a similar one with the roles reversed, so now we have victor's tits not fitting inside yuuri's jacket smh  http://privatter.net/i/2463568  pic.twitter.com/SAjdLmYjkr\n",
      "964916830358958081\n",
      "Because we don't give them stress like their girlfriends we are just mandem with tits  https://twitter.com/Mvnaaa___/status/964054290082955264 … <quoted_status> Some of you guys are way nicer to your female friends than to your girlfriends.</quoted_status>\n",
      "964911549373706245\n",
      "“Why do tits look so much better when you’re cold? Next time I have sex I’m putting the air conditioning on”\n",
      "964909449973522433\n",
      "We saw Goldcrest, blue tits, great tits, chaffinches and a big cat in a cemetery. Lady Penelope regretted not going with them. Her maid is having headaches, again. Man servant is still off colour. Her Ladyship wonders who is going to prepare her dinner. #whippet pic.twitter.com/XceGx81Jhl\n",
      "964905087410851840\n",
      "[Noah taking ark inventory]\n",
      "\n",
      "Bob: next: 2 luscious Tits!\n",
      "Noah: language, Bob\n",
      "B: and a sweet pair of Boobies!\n",
      "N: knock it off Bob\n",
      "B: these 2 chicks are popular; \n",
      "       the Swallows!\n",
      "N:  Bob be professional pls!\n",
      "Bob: [stroking Woodcocks] what?\n",
      "       I didn't name these peckers!\n",
      "964900781735497729\n",
      "Robin, Fieldfare and Blue tit at Lower Woods this morning @bristolbirding pic.twitter.com/to2w448iNZ\n",
      "964893090850000902\n",
      "if you got small tits you lucky as hell. y’all have wear cute rave clothes. shuffle and jump on end. my ass over here struggling and shit UGH \n",
      "964892765598330880\n",
      "Sweet long tailed tit Photo by Yasmin #NaturePhotography #wildlifephotography #birds pic.twitter.com/pQOZmKd34q\n",
      "964891397089263622\n",
      "On/under our #bird feeders (and in the tree they hang from) right now: 2 robins, 4 bullfinch, 2 gold crest(!), FIVE greenfinch, 2 long-tailed tits, 2 blackbird, chaffinch, wren, 3 blue tit, 2 great tit, coal tit, 3 house sparrows & a dunnock. I LOVE our bird feeders! :-)\n",
      "964891332450881538\n",
      "I just want my tits to be sucked tbh\n",
      "964885129389858817\n",
      "Long Tailed Tit today, Mid-Wales @ruthwignall @Natures_Voice @wildlife_uk @NatureUK @Britnatureguide @BTO_GBW #wildlifephotography pic.twitter.com/UooIeivE4L\n",
      "964882497476743169\n",
      "Wish it was big garden birdwatch this morning... long tailed tits, great tits, blue tits, robins, chaffinch, jays, goldfinches, firecrest AND goldcrests. @Natures_Voice #lovemygarden #feelslikespring \n",
      "964877692960215040\n",
      "Head, shoulders, amazing tits, fat ass, knees and toes... knees and toes...\n",
      "964872225953378305\n",
      "I am off my tits from that tremor fucking exciting\n",
      "964870594046103552\n",
      "well it does involve a couple of tits #OiOiLadsBanterChat\n",
      "964868258192154625\n",
      "Sorry Not Sorrythat my tits make me money  and it’s legit such a turn on that they do! Muahhahahaha My Tits have Power #belietofied @Richard10575850 @boobszone @TH_Connoisseur @Redhat_Babes @stu007gots @Booby_Brigade @ pic.twitter.com/W2LuC3mbRr\n",
      "964866243953119232\n",
      "Still need to pick a winner for my weekly banner contest #cocktribute me! #cumtribute me!! Best one in the next hour wins and gets a nude \n",
      "#cumslut #latina #tits #ass #retweet pic.twitter.com/ydC8f56Pju\n",
      "964858330379374592\n",
      "just drawing a little T&A (Tits and A dick)\n",
      "964857694371721216\n",
      "What the fuck went on in Leicester last night man keep seeing an old bird with her tits out \n",
      "964856733666566144\n",
      "Hot pointy nips! #boobs #tits @TheBustyweb pic.twitter.com/g1EkrY0iAO\n",
      "964856290387333125\n",
      "yo almost everything about winter kinda sucks... flu season, cold as tits, bulky clothes, having to start your car 3 hours before you leave like idk man, not a fan\n",
      "964854300815052800\n",
      "I love browsing through old volumes of Tit Bits magazine. Every page has something peculiar on it...\n",
      "\n",
      "“HOW IT FEELS TO BE EATEN”\n",
      "- 20 April 1889. pic.twitter.com/HNt4yPc1vG\n",
      "964846615906447360\n",
      "you ever look at taeyong and you just think... damn such a fine mf really exists huh bonne apple tit to me\n",
      "964839581777620994\n",
      "Can’t believe I got an offer for my first choice with a masters degree I am buzzing off my TITS \n",
      "964818216726953985\n",
      "Check out ALL my gifs of this amateur with huge tits!\n",
      " \n",
      "  http://bit.ly/HugeTitAmateur   pic.twitter.com/4O1uxpFTxG\n",
      "964814131604938752\n",
      "Good luck mes p'tits fdp  @DeexLz @Thxmqs_w @TayzaH_ @Eklipse_SnaKe @HopaaaK \n",
      "964813187811037184\n",
      "do NOT understand the underboob tops/dresses how do you throw shapes without your whole tit falling out\n",
      "964812322979176448\n",
      "I’ll never show understand the women who call the ladies on the show names\n",
      " “ whore, cheap, easy, bitch” etc. Internal misogyny has yals by the tits. Disgusting . #BBNaija\n",
      "964806060635770881\n",
      "i think your having some kind of mental breakdown, a medical intervention is needed for you. please stop making a tit of yourself by constantly attacking @afneil and the BBC\n",
      "964805937398722560\n",
      "Beautiful @Holkham @parkrunUK this morning: singing chaffinches, song thrushes, coal & great tits and my first singing goldcrest of 2018 pic.twitter.com/ivlK4QytUl\n",
      "964804411888369664\n",
      "That beat fucking triggers me to being 14 in a forest freezing my tits off drinking frosty Jack's trying to impress some edge lords https://twitter.com/zachey_pauley/status/964269173567381504 … <quoted_status> Yonkers is 7 years old this month but I still remember every bit like it was yesterday pic.twitter.com/XQhsSYwmIk</quoted_status>\n",
      "964795417094483968\n",
      "Canny believe Mel got her tits out in the photo booth and winched the bouncer :)))) shes fuckin aff it\n",
      "964792142542573569\n",
      "Three of the birds I see most often near our cottage:\n",
      "goldcrest (now finished), long-tailed tit, redwing pic.twitter.com/Hm3vX7W8mz\n",
      "964784770654855168\n",
      "This wonderful bird has been seen around High Elms Country Park recently. A priority species in decline. The marsh tit. Our parks are critical habitat for many species  in urban areas such as #London. Working with @natures_voice https://buff.ly/2GVkLYt  @urbanbirder\n",
      "964782721389223938\n",
      "Dangerous browsing Twitter on a bus when @TOAOMD has been tanning the retweet button. Tits everywhere \n",
      "964779437953871872\n",
      "When you’re rolling tits and trying to see what you’re typing https://twitter.com/astateofhalil/status/964639050459172864 … <quoted_status> I wonder what he saw pic.twitter.com/Y4Uo1neCQ9</quoted_status>\n",
      "964774255110995968\n",
      "Back when I was 16.\n",
      "\n",
      "Decent tits. Terrible wings. pic.twitter.com/yOISBlO4ll\n",
      "964770312435875840\n",
      "Egypt is bangin'\n",
      "- Australia <3\n",
      "964769012772085761\n",
      "Imagine a world:\n",
      "Guns: controlled\n",
      "Racists: gone\n",
      "Gays: in power\n",
      "Straight men: eradicated\n",
      "Tits: out\n",
      "964764814995349505\n",
      "I really think bigger tits would make me more responsible\n",
      "964763049759354880\n",
      "I can wrap a pizza around my schlong it don’t make it a Stromboli, sugar tits.\n",
      "\n",
      "My mom: that’s very nice sweetie\n",
      "964760507579330560\n",
      "Some girl actually refused to punch me in the face and decided to punch me straight in the tit, how lovely\n",
      "964760401996107777\n",
      "Im about to ge lit as tits\n",
      "964748469293363200\n",
      "#UnusualDollarStoreItems Cheese tits pic.twitter.com/NfGtdvCqF7\n",
      "964743180376780800\n",
      "I need my tits sucked\n",
      "964742194056892416\n",
      "Who wants to see cum on my tits? \n",
      "Dm for details \n",
      "\n",
      "@BrokeRTPig\n",
      "@rtsucker @RTPork @find0m @slavetodoms @rtswine @RTP1G @f00t_slave @RTfeet @PiggyLoyal @find0m  @RTpanties @mike_mashall @robsub24 @Tom1tommo @DairtyPanty  #dirtypanties  #usedpanties pic.twitter.com/U0YP83EQMw\n",
      "964739830306484224\n",
      "Morning @SoMilfySquad @MilfieClub @FredFlnt @VxArc @ukgirlsxxx @BritishBabesInc @Yazeedxxx1 @84Magazine @ASRBABES @HotGirlFan_Pics @PurelySexual @Luv_Curvs @milfs_only @HottestMILFs @Kimmie3235 @TheMelissaMilf @NakedHotGirlcom @janklaar2 @BoobsPics… by #HotGirlFan_Pics pic.twitter.com/u04hjzSndy\n",
      "964739764195876864\n",
      "wake up dad            th\n",
      "f*****k u and earth im goin surfing in big tits hawaii!!!!\n",
      "                              love\n",
      "964735052243394561\n",
      "When did Billie Kay get such big tits? pic.twitter.com/24CT6RI0XF\n",
      "964734812631261184\n",
      "Shower time melons! #boobs #tits @mostlyboobz pic.twitter.com/LhVKbojxZ7\n",
      "964727184614199297\n",
      "I would give both of my tits away to see Red Hot Chili Peppers live \n",
      "964726204799639557\n",
      "i dont think you guys understand how horny i am i could cry thinking about a pair of tits\n",
      "964719078609797120\n",
      "I will tag suck my left tit if i want! Back tf up #DreamGH pic.twitter.com/Xj9E8N5yU4\n",
      "964713044457803776\n",
      "\"I see three ring girls with sashes. I can’t read what's on there without starting at their tits.\" -- @BarstoolBigCat #RnR2\n",
      "964712167474958337\n",
      "Naked and alone! \n",
      "\n",
      "#MyGirlfund #fantasygirl #onlinegirlfriend #adultmodel #girlnextdoor #ass #milf #Boobs #tits pic.twitter.com/h8k9L3HHOV\n",
      "964708212393078787\n",
      "I remember when we were the same but then her tits came between us and changed everything\n",
      "\n",
      "- a soliloquy\n",
      "964702977989775361\n",
      "I saw you posted something on IG without your tits hanging out are you ok?\n",
      "964702602960297984\n",
      "Busty & naked! @AmberLynneGirl #boobs #tits pic.twitter.com/coXl0DhW2Z\n",
      "964701842499305473\n",
      "I don't get how theirs a debate over ass or tits when feet exist\n",
      "964690437129801728\n",
      "Joey Smothers has bigger tits than me #sick\n",
      "964687250582835201\n",
      "you know when people are like “ass or tits?” \n",
      "I’m like\n",
      "have you ever seen a woman’s THIGH\n",
      "or TUMMY\n",
      "or A R M\n",
      "or LEGS\n",
      "or nECK \n",
      "or HAaAANDS FOR GOODNESS SAKE\n",
      "964686971112185856\n",
      "2/2 all the men come to attention. She walks in strutting her ass from side to side. None of the men had seen a woman for about 6 months now and here she was naked and bending over inspecting beds and trucks and giving the men full views of her ass, tits and pussy. ((Reply in Dms\n",
      "964686706434891777\n",
      "Tits are fake bae ,  & so are my nails lmao https://twitter.com/brahey93/status/964684210605879298 … <quoted_status> Booty real, nails real, hair real, TITS too. Ain’t nothing fake about Ms. Lira https://twitter.com/_liragalore/status/964681430960955392 …</quoted_status>\n",
      "964685407660249088\n",
      "I take myself down back roads to watch my own tits bounce.\n",
      "964681831277772802\n",
      "Suck on my tits.... as a friend.\n",
      "964681075749474304\n",
      "NewRION\n",
      "Shaved Pussy Naked Colossal Tits Female Teacher Rape RION\n",
      "@S1_No1_Style\n",
      "http://ad.dmm.com/ad/p/r?_site=8547&_article=11911&_link=306791&_image=306884 …\n",
      "&_lurl=http://www.r18.com/videos/vod/movies/detail/-/id=ssni00126/%3futm_source=Social%26utm_medium=Twitter%26utm_campaign=Shaved_RION …\n",
      "#sex #porn #fuck #tits #boobs #asian #booty #adult #creampie #JAV pic.twitter.com/NQjWkQ6jGB\n",
      "964680823705190400\n",
      "New #clip sale! Locked and Ruled by My Tits #Chastity Get yours on #iWantClips! https://iwe.one/RlGB  pic.twitter.com/i1OFJqNmp3\n",
      "964675794470502400\n",
      "If you can sit and target a “friend”, belittle them in front of they’re friends to make yourself look and feel better you are the absolute scum of the earth with such little respect, n here’s a few words for u.. take u anchor tits and fuck off. How embarrassing\n",
      "964669656345776131\n",
      "It’s cold as tits outside  pic.twitter.com/07PChFFBvM\n",
      "964668736371269632\n",
      "he painted some nice shit, but man, bless his heart, he painted tits the way medieval monks painted elephants\n",
      "964665750299361280\n",
      "true but what about all the people who were fucking but gay. because michelangelo definitely never saw a tit even with the lights on\n",
      "964665230931394560\n",
      "jesus. calm your tits navy.\n",
      "964662908968845312\n",
      "Tits should never be close to your chin, honey.\n",
      "964661851421401088\n",
      "Just outta the shower! #boobs #tits @mostlyboobz pic.twitter.com/KmDbsKOy8I\n",
      "964659944543924225\n",
      "Might be a good time to remind about that KT McFarland email:   “If there is a tit-for-tat escalation, Trump will have difficulty improving relations with Russia which has just thrown U.S.A. election to him.”\n",
      "964656083863142400\n",
      "I just accidentally sent the Luigi with tits meme to a contractor at a job site. FML. pic.twitter.com/4uIc4FRQ3R\n",
      "964651839751839744\n",
      "2 Horny English Sluts Finger Each Other & Suck Tits!! https://onlyfans.com/tiffanysnowxxx \n",
      "964651036546945025\n",
      "Tits?\n",
      "964650940769894401\n",
      "Your tits are amazing everyone you post a picture it always makes my trousers bulge\n",
      "964650862059708416\n",
      "Anyone got good workout plans/routines/exercises they could share with me? I've starting going to be gym but so stuck and look like a tit not knowing what to do\n",
      "964650779398299648\n",
      "spot the biggest tit\n",
      "964650733525139458\n",
      "i hate when people remind me how skinny i am like i get it i’m a pancake ass with not tits \n",
      "964650667276042240\n",
      "That's a Belgian gun, you fucking  tit. https://twitter.com/jebbush/status/699706718419345408 … <quoted_status> America. pic.twitter.com/TeduJkwQF3</quoted_status>\n",
      "964650612368396288\n",
      "Blue Tit by TomMelton pic.twitter.com/0xFoP3UiwQ\n",
      "963910733070327820\n",
      "Tits are art.\n",
      "963896542095650817\n",
      "2018 is the year of tit fil a memes.\n",
      "963906874738429952\n",
      "At Whole Foods. I found what Kim Kardashian’s tits will look like 100 years after she is dead. pic.twitter.com/QOg5P5a5TJ\n",
      "963896957742800898\n",
      "The school shooter in Florida last name is Cruz I will bet my left tit the Donald Trump will use this to  pushes illegal immigrant agenda this orange bloated sleazebag will do anything to push his sleazy agenda.\n",
      "963908662065442816\n",
      "\n",
      "\n",
      "Happy Valentines Day boys heres the Valentines lingerie I promised to show you I want so much cum in my inbox(2 bonus pics of me posing)\n",
      " #cumtribute #cocktribute #cumslut #latina #ass #tits #ValentineDay #lingerie pic.twitter.com/AsR6x3qe9i\n",
      "963923295438598146\n",
      "#LIKE if you would let me try lingerie for you #like #retweet #horny #snap #kik #snapchat #cumtribute #nsfw #nude #porn #pussy #tits #boobs #cocktribute #booty #ass #xxx #hot #bj #wet #milf #amateur #panties #bra  #snapchat #sexy #nudes #dm #dating #kikme pic.twitter.com/JtpyTk5Xok\n",
      "963916010070843392\n",
      "Is tits fil a gonna be a thing now\n",
      "963894816961593344\n",
      "I bet Karen is 8 or 10 dicks in to her annual valentines gangbang her face and tits covered in cum and gagging for more pic.twitter.com/JsCxCNHg8f\n",
      "963924663582756870\n",
      "I’m going to say all this lame stuff to every female follower I have till one of them finally sends me a tit pic\n",
      "\n",
      "~ guys\n",
      "963923180879536128\n",
      "PENDULINE TIT - More of the  Plock  Court bird from yesterday @RareBirdAlertUK @Southglosbirds pic.twitter.com/5pW4VDCGkd\n",
      "963901880614248450\n",
      "Listening to couples that can laugh together while seeing who has the balls to yell “tits” the loudest on the quiet floor of the library is what gives me hope that there is someone out there for me. That’s the love I want.\n",
      "963921382282350593\n",
      "my valentine pulls tits like no other pic.twitter.com/OomxTnZdGK\n",
      "963912685539622912\n",
      "This Valentine’s Day, give your sweetheart what they really want......\n",
      "Tits Fil A pic.twitter.com/zWOzJlmvBr\n",
      "963903907427647490\n",
      "Jay you massive stud , please please spaff on my tits from ur valentines bitch p.s and on my face\n",
      "963905747267485698\n",
      "“The first shag I ever had, she had massive tits, I didn’t know what to do” (C. Ferns, 2018) he’s telling stories tonight\n",
      "963925686938406912\n",
      "stop looking at my tits\n",
      "oh & happy valentine's day \n",
      "https://instagram.com/p/BfMi6FBgJNJ/  pic.twitter.com/4HbqFxem3r\n",
      "963922408200548352\n",
      "why buy followers when you can just pay for plastic surgery and get tits\n",
      "963914878955081731\n",
      "she’ll follow you soon ok i feel it in my left tit https://twitter.com/downtownregui/status/963910862254768129 … <quoted_status> at least she’s your mutual</quoted_status>\n",
      "963914153298710536\n",
      "Bad date: at some lad’s house, while we were neckin he burst into tears and began calling me boring (has he seen my tits? Grow up). He started playing Pink Moon on a fucking mandolin (lmao ) to calm down, telling me in graphic detail how he used to finish on his ex’s gooch ...ok!\n",
      "963913939057889282\n",
      "Blue Tit by TomMelton pic.twitter.com/0xFoP3UiwQ\n",
      "963910733070327820\n",
      "& can we all agree the best part of the movie is when Jaz pulls out Lindsey's fake tits and throws them into the crowd https://twitter.com/annamcbrideox/status/963842820246261761 … <quoted_status> Angus thongs & perfect snogging honestly never gets old</quoted_status>\n",
      "963910046655696902\n",
      "Snapchat is like one of those birds that is naturally stunning, then puts on 4 inches of makeup and get's unnaturally round fake tits and goes from a 9/10 to a 4/10. If it aint broke don't fix it. Its unusable now basically...\n",
      "963908703459082240\n",
      "Miss smiley tits! #boobs #tits @mostlyboobz pic.twitter.com/ZKyxUri1jX\n",
      "963904431304724480\n",
      "Roses are red\n",
      "Elephants are gray\n",
      "All I want right now\n",
      "Are some Big Tits Fil A\n",
      "963904420697333763\n",
      "PENDULINE TIT - More of the  Plock  Court bird from yesterday @RareBirdAlertUK @Southglosbirds pic.twitter.com/5pW4VDCGkd\n",
      "963901880614248450\n",
      "This is james, James is english, james plays for rangers, james is a tit, dont be like james. https://twitter.com/talkingbaws/status/963897426435366913 …\n",
      "963898079098351617\n",
      "TONIGHT I play \"Tit Woman With Lizard Tattoo\" on Comedy Central's new hit show @corporate...watch................https://twitter.com/terribletown/status/963854532085084160 … <quoted_status> New episode of @Corporate tonight that denies the existence of God! \n",
      "\n",
      "Featuring an incredible cast including @katewalsh @BrentWeinbach @rossbryant @AnnaAkana @ryanoflan @BabsGray @babysfirstgun @paigeweldon @SaraJBenincasa and @curtneill #CorporateShow pic.twitter.com/jsMGPCjbN7</quoted_status>\n",
      "963892745629728769\n",
      "Wish I could wear they pretty lace bodysuits but I actual have nae tits it's heartbreaking\n",
      "963892052726566912\n",
      "RT pinupglam: Another winner from Tessa Fowler's new diary photo set. :) #boobs #tits\n",
      "http://TessaFowler.Com  pic.twitter.com/lbV1qAcGuY\n",
      "963886883632803845\n",
      "Boys say “nice tits” and “great ass”\n",
      "\n",
      "Men say “you’re smart” and “you’re funny”\n",
      "963883509600354305\n",
      "Ok I am DEAD at this dance routine I made up to the Buffy theme when I was 9/10 - Camp. As. Tits. pic.twitter.com/1oq3DawNZ9\n",
      "963881505457164296\n",
      "Hi welcome to Tits-Fil-A where our pleasure is YOUR pleasure pic.twitter.com/Mc6EVx0oEc\n",
      "963878688923234307\n",
      "*Valentine's Day Tit Ripoff* is available on @iWantClips https://iwe.one/k6DY  pic.twitter.com/hTjRfMgNTp\n",
      "963878038961242112\n",
      "I’m gonna be on that “Tits-Fil-A” line forever, dog \n",
      "963877044810600449\n",
      "RONALDO SCORES!\n",
      "Made Areola look a right tit... pic.twitter.com/JrZD1Ck6mY\n",
      "963876098198163458\n",
      "Finally home from work! \n",
      "Hanging out in my panties and hoody!\n",
      "\n",
      "#panties #mygirlfund #horny #ass #Spanking #onlinegirlfriend #fantasygirl #tits #ass #milf pic.twitter.com/sI9o2hQZwG\n",
      "963873345849700353\n",
      "anyone got any more pics of Kate Garraway from this morning? her tits looked amazing. pic.twitter.com/75vyW9JUPi\n",
      "963869033463459840\n",
      "Crested Tit - having a Trump-hair-day. #Highlands #LoveScotland #EarthCapture #WinterWatch @BBCEarth @BBCSpringwatch @ScotsMagazine @Natures_Voice @_BTO @wildscotland pic.twitter.com/is8sOu3by5\n",
      "963866982381752320\n",
      "Curvy milf with massive honkers! #boobs #tits @TheBustyweb pic.twitter.com/5xOrQBdOZS\n",
      "963866769009061888\n",
      "Talia storm does my tits in\n",
      "963865114666561536\n",
      "Jay, you massive stud, please, please spaff on my tits. From your valentines bitch. P.S, and on my face\n",
      "963864247469006848\n",
      "Lovely to have these Long-tailed tits visiting the #WKSnackBarCam! @CJWildlife pic.twitter.com/R4tmVZdgOZ\n",
      "963863812905619456\n",
      "That girl priya was flat af but now she got tits bigger than mia cause ham nay uthaye hi itny us kay :))\n",
      "963860080193167361\n",
      "Y’all gotta keep strip club food under wraps before Buzzfeed does a “Chicken Strips and Big Ol’ Tits” listicle about it.\n",
      "963857988929966081\n",
      "Roses are red, violets are blue. I'm off my tits on ecstasy. I fucking love you. What's your name?\n",
      "963856529324756992\n",
      "I can’t stop imagining what a logo for tits fil a would look like\n",
      "963855058269073408\n",
      "I can’t get over ‘tits fil a’ like...why..who......\n",
      "963853687394316288\n",
      "Happy Valentines Day, Pussiez!!! Not sure how y’all typically spend holidays, but over here in Club Pussy we’re sipping sparkling rosé, covering ourselves in rose pedals and showing off our ‘GREATEST TITS’... pic.twitter.com/q1c7k3dgRv\n",
      "963852223083003905\n",
      "On my way to the NME’s. Fighting with the tit tape. Wish me luck.\n",
      "963851579865649153\n",
      "https://xpornxporn.com/video/beautiful-big-tit-blonde-milf-fucked-by-huge-bbc-while-cuckold-watches-56936.html … Beautiful Big Tit Blonde Milf Fucked By Huge BBC While Cuckold Watches\n",
      "963844186939080704\n",
      "Swear I used to live in crop tops n now my belly sticks out further than my tits. Getting in a relationship makes you fat\n",
      "963843257053712386\n",
      "Happy Valentine’s Day to my left tit\n",
      "963841759683006464\n",
      "Mammoth mammaries! #boobs #tits @TheBustyweb pic.twitter.com/PEzzxl9fCU\n",
      "963840845265952768\n",
      "‘You massive stud, please, please spaff on my tits, from your valentines bitch. P.S and on my face’  if u kno u kno\n",
      "963840273892696064\n",
      "If you complain about the BBC, I’m 99.9% certain you’re a massive tit. Thank you.\n",
      "963839301564993536\n",
      "wake up dad            th\n",
      "f*****k u and earth im goin surfing in big tits hawaii!!!!\n",
      "                              love\n",
      "963829079634882561\n",
      "Happy birthday suga tits mwah \n",
      "@JetOutlaw pic.twitter.com/ly6uCFNbR3\n",
      "963827220421795847\n",
      "I’d flip a fuckin tit if they redo this when they get to Wano pic.twitter.com/udOrHGpRvl\n",
      "963827218672734208\n",
      "Never date a guy who's more interested in his tits than yours. pic.twitter.com/HGeDEFKSXH\n",
      "963825945542053894\n",
      "Thank you, Denver!!! I don't remember anything but my whole torso feels like a horse had a party on my tits.   @ekohmusic pic.twitter.com/7K0hF3b8l4\n",
      "963825928978677760\n",
      "Cutie flashing her knockers! #boobs #tits @TheBustyweb pic.twitter.com/XFfE6M2Ybm\n",
      "963825771960815617\n",
      "When people say “ninja represents LuckyGirl in a negative way in his thumbnails” I can’t help but want to slap them. I’m an honest, loud, straight up, swearing, half naked, tits or gtfo kinda chick. I am pretty sure my cleavage in his thumbnail isn’t hurting my “representation.”\n",
      "963825143154987009\n",
      "MILF with big boobs http://bigtitsmilf.co.uk/webcam/  ***NO WEBCAM NEEDED*** + FREE chat #tits #webcam pic.twitter.com/uvd0Yv65Di\n",
      "963821389873537026\n",
      "#JustWatched #CardBoardGangsters Thanks @NetflixUK ,Wasn't aware of this EstateGangster flick set in God's Own http://Country.Smart  RealAF dialogue @TheNotoriousMMA would be proud of tit for tat madness with some nice dark humour as new kids try to top the block,loved 4/5 pic.twitter.com/7BioZeBUr2\n",
      "963814903348940802\n",
      "fuck a beat i was trynna succ a tit\n",
      "963814782339084288\n",
      "Tit for tat  pic.twitter.com/RP7h5NNET4\n",
      "963808194849050624\n",
      "A pair of tits and a dick are hot.\n",
      "963807865017421824\n",
      "Roses are Red\n",
      "Temeria is Blue\n",
      "Ves' got great tits\n",
      "and so do you pic.twitter.com/upIgmUtHXz\n",
      "963805846483415040\n",
      "To celebrate #NationalNestBoxWeek, our project officer Sophie Pinder has written a beautiful #blog all about the Willow Tit project and the work they'll be doing throughout the week, with the help of #volunteers- to ensure a better future for this species: http://bit.ly/2BqQTTv  pic.twitter.com/PDpS049sPL\n",
      "963805125944008704\n",
      "Taking off her bra! #boobs #tits @BabesButtBoobs https://twitter.com/BabesButtBoobs/status/963584217199333377/photo/1pic.twitter.com/uj6LxtcpKb \n",
      "963804076302655493\n",
      "Progesterone is red\n",
      "Estrogen is blue\n",
      "Take some with me\n",
      "You'll grow tits too\n",
      "963800637275176960\n",
      "This time a Great Tit falls under the close-up spotlight in the garden. pic.twitter.com/lGnjczouH9\n",
      "963799654956765184\n",
      "8 #ValentinesDay tips to improve your relationship, courtesy of international relations:\n",
      "-Say what you mean\n",
      "-Make public promises\n",
      "-“Tit-for-tat”\n",
      "-Forgive\n",
      "-Calling \"stalemate\" isn't a thing\n",
      "-Be rational\n",
      "-An arbiter can help\n",
      "-Sometimes symbolism is important\n",
      "http://53eig.ht/2BY74c2 \n",
      "963790917827166208\n",
      "On the plus side, when this all goes tits up, at least Boris will be able to talk endlessly about how he made speeches calling for conciliation, and if it wasn't for those \"stubborn Remainers\" ignoring him, things would be fine.\n",
      "\n",
      "So, I'm looking forward to that...\n",
      "963787939024171008\n",
      "#WCW and Happy Valentine's to these great tits (tarts in training)\n",
      "@ShootyDoody\n",
      "@Pirate_Twinkie\n",
      "@funflaps\n",
      "@hamersauce\n",
      "@averagegrades\n",
      "@heapsOhate\n",
      "@praisecheese\n",
      "@candidqueso\n",
      "@ficklenuts\n",
      "@smart_alyx\n",
      "@FirecrackerKatt\n",
      "@KissabiX\n",
      "@Ms_G_Renee\n",
      "@YupKirsten\n",
      "@NotOnTheMoors\n",
      "@ArtIsMyPorn\n",
      "963782604221685760\n",
      "First time visit today - Long-Tailed Tits #daventry #longtailedtit #RSPB @Natures_Voice #britishbirds @britishbirds #Northantsbirds @RSPBMidlands @iNatureUK @NatureUK @NorthantsBTO pic.twitter.com/VNdT6m7L8A\n",
      "963778951234641920\n",
      "Kate Garraway  those tits look amazing today   pic.twitter.com/xH4oj01pRr\n",
      "963777110010683392\n",
      "Brand New Valentine’s Day video!  It involves TITS  RT this tweet if you’re single or if you’re in a relationship and cheating on your partner. \n",
      "\n",
      "http://youtu.be/KiwzTkQihYs  pic.twitter.com/IZtnGiz73n\n",
      "963775636727767041\n",
      "Slovenian snowboarder Tit Stante shows support for Meek Mill at Winter Olympics https://goo.gl/jj5JFh  pic.twitter.com/Ta3mnIsijG\n",
      "963774842762805248\n",
      "tits and pussy http://bigtitsmilf.co.uk   ----> pic.twitter.com/0sc8R0uBgi\n",
      "963773824100528129\n",
      "Wife: Today is Valentine’s Day, sooo...\n",
      "\n",
      "Me: Yeah, well, it’s also the first day of lent, sooo...\n",
      "\n",
      "Wife: The only thing you better be giving up today is dat ass, sugar tits!\n",
      "963769754262568961\n",
      "an important message from Olympian Tit Stante: pic.twitter.com/DeicayAnEI\n",
      "963768036787339264\n",
      "calm down your titsIT'S A VALENTINE PRANK LMFAO\n",
      "963767343443668992\n",
      "Comrade Corbyn gives sexual harrasment in the workplace his full support.\n",
      "(I bet he felt a right tit) pic.twitter.com/XUUjZijNp6\n",
      "963764982352629761\n",
      "Yes I've got small tits but on pancake day I don't tell everyone the day is dedicated to me for my \"pancake tits\" infact id rather call them cone tits\n",
      "963758467994521600\n",
      "Don't hesitate to rape my pussy and grope my tits\n",
      "#Cumslut #CumWhore #Slut #Whore #cumtribute #cocktribute pic.twitter.com/P64OUo2Fbg\n",
      "963757414586732545\n",
      "I wanna go for a Pap smear but gwababa has me by my tits. Ladies is it painful/ uncomfortable while doing it? #GirlTalkZA\n",
      "963755475538972672\n",
      "Do you know how I want you to spend the rest of your Valentine's day? I want your cock trapped between my massive tits and I want to beat you off over and over again, endless tit wanks till my breasts become all sticky with all your cum and your big dick is left completely dry pic.twitter.com/KUQBaqpBi6\n",
      "963754835110711296\n",
      "A slightly different take on #NationalNestboxWeek in this picture - strapping dead wood to live trees to allow Willow Tits to excavate their own nest holes. pic.twitter.com/0XEDXBjVny\n",
      "963754224273297408\n",
      "Dear jay , you massive stud please please spaff on my tits from your valentines bitch P.S and on my face\n",
      "963750565472849920\n",
      "In this iterated prisoner’s dilemma, I would gladly play tit for tat with you.  #polscivalentines\n",
      "963750351764631552\n",
      "You have a fiancé and 2 children and you are arguing with a stranger on twitter over a pair or tits. Enjoy your missionary sex with a top on and the lights off x https://twitter.com/leachysmissus/status/963740958415310849 …\n",
      "963749350064128000\n",
      "Witch's tits are probably quite warm if they're standing over cauldrons for long periods at a time.\n",
      "963749190273851392\n",
      "Do people ever consider their employer could find their tit/dick pictures they post on social media?\n",
      "963747134280433665\n",
      " Willow Tit Dating Profile \n",
      "Will Wallis find love this #Valentines @Lancswildlife pic.twitter.com/1gkz3McTiT\n",
      "963744633716174848\n",
      "Aaron, you massive stud, please, please spaff on my tits, from your valentines bitch.\n",
      "\n",
      "P.S And on my face\n",
      "963742371988066304\n",
      "Sky sports always get women presenters with big tits. Caring for the viewers .\n",
      "963734996497391616\n",
      "Rate rate rate funny seeing some lads Valentine’s posts about their birds when everytime one of my mates have got their tits out on my story they ask me for their snapchat looool\n",
      "963724905010343936\n",
      "It only shows how weak somebody's argument is when they resort to personal attacks during an argument like 'your tit is hanging out of your shirt'\n",
      "963719053037596674\n",
      "every time i see these pair of tits on my timeline i get closer n closer to gouging my fucking eyes out https://twitter.com/khantwinz/status/963300320213336065 … <quoted_status> Genes pic.twitter.com/dY7Igm2gWc</quoted_status>\n",
      "963716654684352512\n",
      "why tf are feelings even a thing?? like one minute I'm absolutely raGING, the next I'm pure buzzing out my tits and then I'm sobbing my wee heart out. what is going on\n",
      "963715571157209088\n",
      "Blue Tit just about to land. 11/2/18. 2,000th of a second not enough to freeze this little chaps wings :) pic.twitter.com/daimUJSjyr\n",
      "963708828775796736\n",
      "Old joke alert, before anyone else cracks it today:\n",
      "PSG’s goalie is a bit of a tit.\n",
      "Taxi, etc and so on.\n",
      "963701324272623616\n",
      "Great tits are true romantics! Even their winter social networks are structured by pair bonds. Whether they celebrate Valentine’s Day remains, of course, one of our primary research questions @WythamTits\n",
      "Heart colour=bird's bond strength, red line=pair bond, pink line=non-pair pic.twitter.com/53yQN23ARL\n",
      "963699884258938880\n",
      "Busty UK wife http://bigtitsmilf.co.uk  big tits milf in stockings pic.twitter.com/FtEvi8v9ba\n",
      "963698075813359616\n",
      "follow >> RT@english_milf big tits selfie x pic.twitter.com/x6DaQnkLHT\n",
      "963696817966862337\n",
      "Imagine all the titties in the world that need sucking. Save lives n suck a tit on Valentine’s Day\n",
      "963695560195788800\n",
      "“Bill, Bill you massive stud, please, plesse spaff on my tits”\n",
      "963692935572283392\n",
      "Jay you massive stud please please spaff on my tits from your valentines bitch p.s. And on my face\n",
      "963690352719880194\n",
      "Blue tit (Cyanistes caeruleus) New Forest \n",
      "@Natures_Voice @BBCSpringwatch @WildlifeMag @NewForestNPA @BritBirdLovers @BBCEarth pic.twitter.com/vMoQz2aVue\n",
      "963684359361454081\n",
      "Today marks the start of #NationalNestBoxWeek. Please pop a nest box up for your local 'love birds' \n",
      "Soon you could have a family just like our Springwatch blue tits! \n",
      "#NNBW http://bit.ly/2jeESrj  pic.twitter.com/rTM1vLKVKG\n",
      "963684256537919488\n",
      "Blue Tit yesterday, Mid-Wales @ruthwignall @Natures_Voice @wildlife_uk @NatureUK @Britnatureguide @BTO_GBW #wildlifephotography pic.twitter.com/splUOespk3\n",
      "963683321380208641\n",
      "Just received a card that reads, “harry, you massive stud please please spaff on my tits. Ps and on my face”\n",
      "963677025683767297\n",
      "Shaky titty! #boobs #tits @BabesButtBoobs https://twitter.com/BabesButtBoobs/status/963583709889945605/photo/1pic.twitter.com/q2k4zHpIsp \n",
      "963676657902084101\n",
      "Low quality pic but high quality tits pic.twitter.com/FD0HCZm1ro\n",
      "963658732772167681\n",
      "One time Kara’s Mom told me that if I fell in a barrel of tits I’d come out sucking my thumb\n",
      "963657611647291392\n",
      "Battle Rapper: Yo, and your nuts hang low, like I nevah seen befo'.\n",
      "Careful with them shits, put em on your chest, they'd be tits.\n",
      "\n",
      "Bruce Banner: ...\n",
      "\n",
      "BR: And your momma so dumb she bathed in dayglo, make you so\n",
      "\n",
      "*HULK just smashes the heck out of him*\n",
      "963648547156570113\n",
      "Ash Wednesday: a time when all the girls post forehead cross pics on vsco, showing they love Jesus, then 3 days later, posting that bra pic where yo tits look good \n",
      "963637026250780672\n",
      "Someone called me Disney world with tits one time and I've never felt more understood.\n",
      "963636355501821952\n",
      "Blondie big tits! #boobs #tits @mostlyboobz pic.twitter.com/OykXlwAbC4\n",
      "963632490169733120\n",
      ".@XHarmonyReignsX is Flashing Her Tits & lucky @jordiporn gets the best view! #DPFlixxx pic.twitter.com/GOu7NPqXb7\n",
      "963627511031783425\n",
      "I'll never get tired of Leanne Crow's tits pic.twitter.com/6vzPTSpodh\n",
      "963626701283524609\n",
      "Tits\n",
      "963622451430281216\n",
      "Happy #ValentinesDay \n",
      " \n",
      "Go to  http://OnlyFans.com/DjTaniaAmazon  for ur Valentine's gift... \n",
      "\n",
      "#TaniaAmazon\n",
      "#DJ #Producer #Model\n",
      "#Boobs #BoobsForDays #cleavagefordays #cleavage #l #titsfordays #tits #HugeTits #titsandas #GirlsWhoLift #StrongGirls #Gym #Fitness #Fitchicks #WomenWhoLift pic.twitter.com/xYPFuaitRI\n",
      "963616695091949569\n",
      "Slovenian snowboarder Tit Stante takes #FreeMeekMill to Olympic halfpipe.  https://trib.al/pAwIsOV  pic.twitter.com/pUUqmTVNER\n",
      "963613294677446656\n",
      "“I can balance a cup on my tits”\n",
      "\n",
      "Me, flirting.\n",
      "963605091914788865\n",
      "finally i have seen a tit haha hell yea let’s go\n",
      "963598535701815296\n",
      "this dudes name is tit https://twitter.com/Deadspin/status/963299276360179712 … <quoted_status> Slovenian Tit Stante has a message for the world: pic.twitter.com/5fs8UC5RxO</quoted_status>\n",
      "963598143722934273\n",
      "this bc its so upsetting to me. He was your stereotypical sexist internet kid that spammed tit streamer, whore, anything he could to degrade me. Thought it was funny to threaten me with physical harm and rape simply bc its something we let them do bc its easier to mute, ignore\n",
      "963597653857759232\n",
      "Hey dumbass...brains are the new tits.\n",
      "963597586354536449\n",
      "i like anime a lot but it really is hard to get over the fact that anime fandom so often feels like a brain genious attempt at using irony to make talking about the tits of fourteen year old sisters acceptable\n",
      "963596626991476736\n",
      "Slovenian snowboarder Tit Štante didn’t qualify for the halfpipe final but he took advantage of his moment in the spotlight yesterday http://on.si.com/2nXKZBD \n",
      "963594651000299522\n",
      "Nigga ya tits the same size as hers. Sit on down. https://twitter.com/notsam13/status/963350118484279297 …\n",
      "963594294392250369\n",
      "RT if you want to put your cock in those nice tits  pic.twitter.com/UOg3K3DoVH\n",
      "963593676252499970\n",
      "Check out her massive tits! #boobs #tittytuesday @mostlyboobz pic.twitter.com/W60syzfHRc\n",
      "963593397675200512\n",
      "shit fuck tits balls fuck me in the face. how's that for an image? https://twitter.com/Criptoboy1210/status/963582310208729088 … <quoted_status> Phil, I think you harm your image by answering all those hater messages and noobs thinking they know more than you. I personally love your TA and funny stuff, and ignoring them will work better. Not telling you what to do, just humble advice.</quoted_status>\n",
      "963582601880637440\n",
      "Of course I am difficult. It comes with the tits.\n",
      "963580042361147392\n",
      "【NEW】 BIG TITS\n",
      "http://ad.dmm.com/ad/p/r?_site=8547&_article=11911&_link=306791&_image=306884&_lurl=http://www.r18.com/special/bigtitssp/%3futm_source=social%26utm_medium=Twitter%26utm_campaign=Bigtits_en …\n",
      "#sex #porn #fuck #tits #boobs #asian #booty pic.twitter.com/cHmx1dCkJh\n",
      "963578543392378881\n",
      "I can pass the metal detector at work. My tits have never been so happy!\n",
      "963577621094322178\n",
      "Yup! She pays all the fees that Ed owes Brandi... so LeAnn is basically just giving money to Brandi, every month, year after year, while Eddie sits back without a care in the world. That's GOTTA burn her tits. And it obviously adds continual fuel to her unending hatred of Brandi.\n",
      "963571407933378561\n",
      "Ladies please can i suggest a tits out for Bibi campaign please he needs encouragement in this dark time.\n",
      "963569157965934593\n",
      "No tits #NewProfilePic pic.twitter.com/vPGsKfv3fU\n",
      "963569138433187840\n",
      "I love girls that go I only like tall guys. Well, girlfriend. I only like girls with huge tits. Only problem, I can't have stilt implants but they can get silicone. \n",
      "963568803882954752\n",
      "HIM: I'm not used to seeing u with clothes on. All u post on Instagram is tits.\n",
      "\n",
      "ME: Could it be u choose to see only tits? pic.twitter.com/yrrr3Y6JnM\n",
      "963566980224638977\n",
      "big tits MILF >>> http://bigtitsmilf.co.uk/webcam/  NO webcam needed and FREE chat pic.twitter.com/NezVhJryJX\n",
      "963563941531136000\n",
      "His gay tranny lover, Michelle. That message is from Joan Rivers from beyond the grave.\n",
      "963563901747998720\n",
      "what the fucking shitting tit nipples is THIS !?!?! https://twitter.com/nctsmtown/status/963429287255621632 … <quoted_status> NCT U ‘BOSS’ MV Teaser\n",
      "\n",
      "#NCT_U_BOSS\n",
      "#NCT_U #BOSS\n",
      "#NCT2018 pic.twitter.com/qQ0ruUbPKw</quoted_status>\n",
      "963563893439303680\n",
      "Most iconic moment in super bowl history debate ur ancestors sorry Janet ur tit wasn’t worth 13 mil like Maya’s finger pic.twitter.com/e0MPqHxuu8\n",
      "963563891509768192\n",
      "Even tho me and you have had a bad past. I’m glad you’re on my side and it’s means a lot. Thank you john.\n",
      "963563873445048320\n",
      "That's the word my mum used when I was a kid and my whole family use it now. On the (rare) occasions I need to say something about an individual sheep I have to make a conscious effort not to use the word and make myself look like a tit.\n",
      "963563860467871744\n",
      "Sexy Asian Girls With Beautiful Tits & Amazing Ass !!! - http://hotchicksvideos.com/music/sexy-asian-girls-with-beautiful-tits-amazing-ass-2/ …\n",
      "#babes #teen #bigtits #video #lingerie #bikini #sexybabes #sexyladys #sexychicks #asian #bikini #ass #bigtits #busty #booty pic.twitter.com/FBzGeU3y4D\n",
      "963563690682470402\n",
      "chill them tits or non existent tits https://twitter.com/smilingyeol/status/963562512007532545 … <quoted_status> The kpop fandom needs to fucking chill sometimes I swear</quoted_status>\n",
      "963563680465063936\n",
      "I'm at my son's basketball game and I'm in a hoodie 64° out and sunny with a breeze freezing my tits off...\n",
      "963563607349850112\n",
      "@SophieHartxxx Not only do you such a beautiful smile and great tits but your ass is perfect x\n",
      "963563508372856833\n",
      "id::944381285576851456:http://goo.gl/ujKH0l  &lt;-Chinese Couple Leaked #tits #boob #memek #bispak\n",
      "963563448062758912\n",
      "That would be mine\n",
      "963563446477340672\n"
     ]
    }
   ],
   "source": [
    "for tweet in tweets:\n",
    "    print(tweet.text)\n",
    "    print(tweet.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape(start_date, end_date, proxy, keyword=\"Bitcoin\"):\n",
    "    \n",
    "    \n",
    "    \n",
    "    for dt in rrule(MONTHLY, dtstart=start_date, until=end_date):\n",
    "        \n",
    "        fname = \"{}/extracted/{}.csv\".format(keyword.lower(), dt.strftime('%Y-%m-%d'))\n",
    "        current_directory = os.getcwd()\n",
    "        final_directory = os.path.join(current_directory, fname)                                     \n",
    "        \n",
    "        #do if file dosen't exisst\n",
    "        if not os.path.exists(final_directory):           \n",
    "            df = pd.DataFrame(columns=['ID', 'Tweet', 'Time', 'User', 'Likes', 'Replies', 'Retweet', 'in_response_to', 'response_type'])\n",
    "\n",
    "            begin = dt.date() - relativedelta(months=1) - relativedelta(days=1)\n",
    "            end = dt.date()\n",
    "\n",
    "            print(\"{} {}\".format(begin, end))\n",
    "\n",
    "            selectedDays = (end - begin).days\n",
    "\n",
    "            list_of_tweets = query_tweets(keyword, 10000 * selectedDays, begindate=begin, enddate=end, poolsize=selectedDays, proxies=proxy)\n",
    "\n",
    "            for tweet in list_of_tweets:\n",
    "                res_type = tweet.response_type\n",
    "                \n",
    "                if (tweet.reply_to_id == '0'):\n",
    "                    res_type='tweet'\n",
    "                    \n",
    "                df = df.append({'ID': tweet.id, 'Tweet': tweet.text, 'Time': tweet.timestamp, 'User': tweet.user, 'Likes': tweet.likes, 'Replies': tweet.replies, 'Retweet': tweet.retweets, 'in_response_to': tweet.reply_to_id, 'response_type': tweet.response_type}, ignore_index=True)\n",
    "\n",
    "            df.to_csv(fname, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "detailsList = []\n",
    "\n",
    "today = date(datetime.now().year, datetime.now().month, datetime.now().day)\n",
    "\n",
    "coinDetails = {}\n",
    "coinDetails['name'] = 'Bitcoin'\n",
    "coinDetails['start'] = date(2015, 1, 1)\n",
    "coinDetails['end'] = today\n",
    "detailsList.append(coinDetails)\n",
    "\n",
    "coinDetails = {}\n",
    "coinDetails['name'] = 'Dash'\n",
    "coinDetails['start'] = date(2015, 5, 1)\n",
    "coinDetails['end'] = today\n",
    "detailsList.append(coinDetails)\n",
    "\n",
    "coinDetails = {}\n",
    "coinDetails['name'] = 'Dogecoin'\n",
    "coinDetails['start'] = date(2015, 1, 1)\n",
    "coinDetails['end'] = today\n",
    "detailsList.append(coinDetails)\n",
    "\n",
    "coinDetails = {}\n",
    "coinDetails['name'] = 'Ethereum'\n",
    "coinDetails['start'] = date(2015, 12, 1)\n",
    "coinDetails['end'] = today\n",
    "detailsList.append(coinDetails)\n",
    "\n",
    "coinDetails = {}\n",
    "coinDetails['name'] = 'Litecoin'\n",
    "coinDetails['start'] = date(2015, 1, 1)\n",
    "coinDetails['end'] = today\n",
    "detailsList.append(coinDetails)\n",
    "\n",
    "coinDetails = {}\n",
    "coinDetails['name'] = 'Monero'\n",
    "coinDetails['start'] = date(2015, 1, 1)\n",
    "coinDetails['end'] = today\n",
    "detailsList.append(coinDetails)\n",
    "\n",
    "coinDetails = {}\n",
    "coinDetails['name'] = 'Ripple'\n",
    "coinDetails['start'] = date(2015, 1, 1)\n",
    "coinDetails['end'] = today\n",
    "detailsList.append(coinDetails)\n",
    "\n",
    "coinDetails = {}\n",
    "coinDetails['name'] = 'Stellar'\n",
    "coinDetails['start'] = date(2015, 1, 1)\n",
    "coinDetails['end'] = today\n",
    "detailsList.append(coinDetails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_paths():\n",
    "    for coinDetail in detailsList:\n",
    "\n",
    "        current_directory = os.getcwd()\n",
    "        final_directory = os.path.join(current_directory, coinDetail['name'].lower())\n",
    "\n",
    "        if not os.path.exists(final_directory):\n",
    "            os.makedirs(final_directory)\n",
    "\n",
    "        if not os.path.exists(final_directory + \"/extracted\"):\n",
    "            os.makedirs(final_directory + \"/extracted\")\n",
    "            \n",
    "#fix_paths()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_files():\n",
    "    for coinDetail in detailsList:\n",
    "        current_directory = os.getcwd()\n",
    "        final_directory = os.path.join(current_directory, coinDetail['name'].lower()) + \"/extracted/*\"\n",
    "        \n",
    "        for f in glob(final_directory):\n",
    "            print(\"Deleting {}\".format(f))\n",
    "            os.remove(f)\n",
    "            \n",
    "            \n",
    "#delete_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proxies = get_proxies()\n",
    "proxySize = len(proxies)\n",
    "\n",
    "for coinDetail in detailsList:\n",
    "    print(\"Scraping {} Data\".format(coinDetail['name']))\n",
    "    print(\"Starting Year: {} Ending Year: {}\".format(coinDetail['start'].year, coinDetail['end'].year))\n",
    "    count = 0\n",
    "    \n",
    "    proxy = proxies[count]\n",
    "    \n",
    "    for d in range(coinDetail['start'].year, coinDetail['end'].year + 1):\n",
    "        \n",
    "        if d == 2018:\n",
    "            scrape(date(d, 1, 1), coinDetail['end'], proxy=proxy, keyword=coinDetail['name'])\n",
    "        else:\n",
    "            if count == 0:\n",
    "                scrape(coinDetail['start'], date(d, 12, 31), proxy=proxy, keyword=coinDetail['name'])\n",
    "            else:\n",
    "                scrape(date(d, 1, 1), date(d, 12, 31), proxy=proxy, keyword=coinDetail['name'])\n",
    "            \n",
    "        count +=1\n",
    "        \n",
    "        if (count >= proxySize):\n",
    "            count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_paths():\n",
    "    dirs = glob(\"{}/*/\".format(os.getcwd()))\n",
    "    validPath = []\n",
    "\n",
    "    for directory in dirs:\n",
    "        fullPath = directory + \"extracted\"\n",
    "\n",
    "        if (os.path.exists(fullPath)):\n",
    "            validPath.append(fullPath)\n",
    "            \n",
    "    return validPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(fullDf):\n",
    "    fullDf = fullDf.reset_index(drop=True)\n",
    "    fullDf = fullDf.replace(np.inf, np.nan)\n",
    "    fullDf = fullDf.fillna(method='ffill')\n",
    "\n",
    "    fullDf['Time'] = pd.to_datetime(fullDf['Time'], errors='coerce')\n",
    "    fullDf = fullDf.dropna(subset=['Time'])\n",
    "    fullDf = fullDf.sort_values(by='Time')\n",
    "    fullDf = fullDf.drop_duplicates()\n",
    "    \n",
    "    return fullDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_data():\n",
    "    for fullPath in get_paths():\n",
    "        coinName = fullPath.split(\"/\")[-2]\n",
    "        print(coinName)\n",
    "\n",
    "        fullDf = pd.DataFrame(columns=['ID', 'Tweet', 'Time', 'User', 'Likes', 'Replies', 'Retweet', 'in_response_to', 'response_type'])\n",
    "        writeFile = fullPath + \"/\" + \"combined.csv\"\n",
    "\n",
    "        if (os.path.isfile(writeFile)):\n",
    "            os.remove(writeFile)\n",
    "\n",
    "        for file in os.listdir(fullPath):\n",
    "            csv = fullPath + \"/\" + file\n",
    "\n",
    "            if (\".csv\" in csv):\n",
    "                df = pd.read_csv(csv, engine='python')\n",
    "                print(file)\n",
    "                fullDf = pd.concat([fullDf, df[['ID', 'Tweet', 'Time', 'User', 'Likes', 'Replies', 'Retweet', 'in_response_to', 'response_type']]])\n",
    "        \n",
    "        fullDf = clean_data(fullDf)\n",
    "        fullDf.to_csv(writeFile, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ripple\n",
      "2017-11-01.csv\n",
      "2015-09-01.csv\n",
      "2016-03-01.csv\n",
      "2015-11-01.csv\n",
      "2016-02-01.csv\n",
      "2016-05-01.csv\n",
      "2016-09-01.csv\n",
      "2016-04-01.csv\n",
      "2016-12-01.csv\n",
      "2017-01-01.csv\n",
      "2018-04-01.csv\n",
      "2016-11-01.csv\n",
      "2017-09-01.csv\n",
      "2015-08-01.csv\n",
      "2018-03-01.csv\n",
      "2017-06-01.csv\n",
      "2018-02-01.csv\n",
      "2018-01-01.csv\n",
      "2015-05-01.csv\n",
      "2017-03-01.csv\n",
      "2018-05-01.csv\n",
      "2017-02-01.csv\n",
      "2016-10-01.csv\n",
      "2016-01-01.csv\n",
      "2017-12-01.csv\n",
      "2017-04-01.csv\n",
      "2017-07-01.csv\n",
      "2018-06-01.csv\n",
      "2017-05-01.csv\n",
      "2015-10-01.csv\n",
      "2015-02-01.csv\n",
      "2015-03-01.csv\n",
      "2017-10-01.csv\n",
      "2015-06-01.csv\n",
      "2017-08-01.csv\n",
      "2015-01-01.csv\n",
      "2015-04-01.csv\n",
      "2016-07-01.csv\n",
      "2016-06-01.csv\n",
      "2016-08-01.csv\n",
      "2015-12-01.csv\n",
      "2015-07-01.csv\n",
      "dogecoin\n",
      "2017-11-01.csv\n",
      "2015-09-01.csv\n",
      "2016-03-01.csv\n",
      "2015-11-01.csv\n",
      "2016-02-01.csv\n",
      "2016-05-01.csv\n",
      "2016-09-01.csv\n",
      "2016-04-01.csv\n",
      "2016-12-01.csv\n",
      "2017-01-01.csv\n",
      "2018-04-01.csv\n",
      "2016-11-01.csv\n",
      "2017-09-01.csv\n",
      "2015-08-01.csv\n",
      "2018-03-01.csv\n",
      "2017-06-01.csv\n",
      "2018-02-01.csv\n",
      "2018-01-01.csv\n",
      "2015-05-01.csv\n",
      "2017-03-01.csv\n",
      "2018-05-01.csv\n",
      "2017-02-01.csv\n",
      "2016-10-01.csv\n",
      "2016-01-01.csv\n",
      "2017-12-01.csv\n",
      "2017-04-01.csv\n",
      "2017-07-01.csv\n",
      "2018-06-01.csv\n",
      "2017-05-01.csv\n",
      "2015-10-01.csv\n",
      "2015-02-01.csv\n",
      "2015-03-01.csv\n",
      "2017-10-01.csv\n",
      "2015-06-01.csv\n",
      "2017-08-01.csv\n",
      "2015-01-01.csv\n",
      "2015-04-01.csv\n",
      "2016-07-01.csv\n",
      "2016-06-01.csv\n",
      "2016-08-01.csv\n",
      "2015-12-01.csv\n",
      "2015-07-01.csv\n",
      "monero\n",
      "2017-11-01.csv\n",
      "2015-09-01.csv\n",
      "2016-03-01.csv\n",
      "2015-11-01.csv\n",
      "2016-02-01.csv\n",
      "2016-05-01.csv\n",
      "2016-09-01.csv\n",
      "2016-04-01.csv\n",
      "2016-12-01.csv\n",
      "2017-01-01.csv\n",
      "2018-04-01.csv\n",
      "2016-11-01.csv\n",
      "2017-09-01.csv\n",
      "2015-08-01.csv\n",
      "2018-03-01.csv\n",
      "2017-06-01.csv\n",
      "2018-02-01.csv\n",
      "2018-01-01.csv\n",
      "2015-05-01.csv\n",
      "2017-03-01.csv\n",
      "2018-05-01.csv\n",
      "2017-02-01.csv\n",
      "2016-10-01.csv\n",
      "2016-01-01.csv\n",
      "2017-12-01.csv\n",
      "2017-04-01.csv\n",
      "2017-07-01.csv\n",
      "2018-06-01.csv\n",
      "2017-05-01.csv\n",
      "2015-10-01.csv\n",
      "2015-02-01.csv\n",
      "2015-03-01.csv\n",
      "2017-10-01.csv\n",
      "2015-06-01.csv\n",
      "2017-08-01.csv\n",
      "2015-01-01.csv\n",
      "2015-04-01.csv\n",
      "2016-07-01.csv\n",
      "2016-06-01.csv\n",
      "2016-08-01.csv\n",
      "2015-12-01.csv\n",
      "2015-07-01.csv\n",
      "stellar\n",
      "2017-11-01.csv\n",
      "2015-09-01.csv\n",
      "2016-03-01.csv\n",
      "2015-11-01.csv\n",
      "2016-02-01.csv\n",
      "2016-05-01.csv\n",
      "2016-09-01.csv\n",
      "2016-04-01.csv\n",
      "2016-12-01.csv\n",
      "2017-01-01.csv\n",
      "2018-04-01.csv\n",
      "2016-11-01.csv\n",
      "2017-09-01.csv\n",
      "2015-08-01.csv\n",
      "2018-03-01.csv\n",
      "2017-06-01.csv\n",
      "2018-02-01.csv\n",
      "2018-01-01.csv\n",
      "2015-05-01.csv\n",
      "2017-03-01.csv\n",
      "2018-05-01.csv\n",
      "2017-02-01.csv\n",
      "2016-10-01.csv\n",
      "2016-01-01.csv\n",
      "2017-12-01.csv\n",
      "2017-04-01.csv\n",
      "2017-07-01.csv\n",
      "2018-06-01.csv\n",
      "2017-05-01.csv\n",
      "2015-10-01.csv\n",
      "2015-02-01.csv\n",
      "2015-03-01.csv\n",
      "2017-10-01.csv\n",
      "2015-06-01.csv\n",
      "2017-08-01.csv\n",
      "2015-01-01.csv\n",
      "2015-04-01.csv\n",
      "2016-07-01.csv\n",
      "2016-06-01.csv\n",
      "2016-08-01.csv\n",
      "2015-12-01.csv\n",
      "2015-07-01.csv\n",
      "litecoin\n",
      "2017-11-01.csv\n",
      "2015-09-01.csv\n",
      "2016-03-01.csv\n",
      "2015-11-01.csv\n",
      "2016-02-01.csv\n",
      "2016-05-01.csv\n",
      "2016-09-01.csv\n",
      "2016-04-01.csv\n",
      "2016-12-01.csv\n",
      "2017-01-01.csv\n",
      "2018-04-01.csv\n",
      "2016-11-01.csv\n",
      "2017-09-01.csv\n",
      "2015-08-01.csv\n",
      "2018-03-01.csv\n",
      "2017-06-01.csv\n",
      "2018-02-01.csv\n",
      "2018-01-01.csv\n",
      "2015-05-01.csv\n",
      "2017-03-01.csv\n",
      "2018-05-01.csv\n",
      "2017-02-01.csv\n",
      "2016-10-01.csv\n",
      "2016-01-01.csv\n",
      "2017-12-01.csv\n",
      "2017-04-01.csv\n",
      "2017-07-01.csv\n",
      "2018-06-01.csv\n",
      "2017-05-01.csv\n",
      "2015-10-01.csv\n",
      "2015-02-01.csv\n",
      "2015-03-01.csv\n",
      "2017-10-01.csv\n",
      "2015-06-01.csv\n",
      "2017-08-01.csv\n",
      "2015-01-01.csv\n",
      "2015-04-01.csv\n",
      "2016-07-01.csv\n",
      "2016-06-01.csv\n",
      "2016-08-01.csv\n",
      "2015-12-01.csv\n",
      "2015-07-01.csv\n",
      "ethereum\n",
      "2017-11-01.csv\n",
      "2016-03-01.csv\n",
      "2016-02-01.csv\n",
      "2016-05-01.csv\n",
      "2016-09-01.csv\n",
      "2016-04-01.csv\n",
      "2016-12-01.csv\n",
      "2017-01-01.csv\n",
      "2018-04-01.csv\n",
      "2016-11-01.csv\n",
      "2017-09-01.csv\n",
      "2018-03-01.csv\n",
      "2017-06-01.csv\n",
      "2018-02-01.csv\n",
      "2018-01-01.csv\n",
      "2017-03-01.csv\n",
      "2018-05-01.csv\n",
      "2017-02-01.csv\n",
      "2016-10-01.csv\n",
      "2016-01-01.csv\n",
      "2017-12-01.csv\n",
      "2017-04-01.csv\n",
      "2017-07-01.csv\n",
      "2018-06-01.csv\n",
      "2017-05-01.csv\n",
      "2017-10-01.csv\n",
      "2017-08-01.csv\n",
      "2016-07-01.csv\n",
      "2016-06-01.csv\n",
      "2016-08-01.csv\n",
      "2015-12-01.csv\n",
      "dash\n",
      "2017-11-01.csv\n",
      "2015-09-01.csv\n",
      "2016-03-01.csv\n",
      "2015-11-01.csv\n",
      "2016-02-01.csv\n",
      "2016-05-01.csv\n",
      "2016-09-01.csv\n",
      "2016-04-01.csv\n",
      "2016-12-01.csv\n",
      "2017-01-01.csv\n",
      "2018-04-01.csv\n",
      "2016-11-01.csv\n",
      "2017-09-01.csv\n",
      "2015-08-01.csv\n",
      "2018-03-01.csv\n",
      "2017-06-01.csv\n",
      "2018-02-01.csv\n",
      "2018-01-01.csv\n",
      "2015-05-01.csv\n",
      "2017-03-01.csv\n",
      "2018-05-01.csv\n",
      "2017-02-01.csv\n",
      "2016-10-01.csv\n",
      "2016-01-01.csv\n",
      "2017-12-01.csv\n",
      "2017-04-01.csv\n",
      "2017-07-01.csv\n",
      "2018-06-01.csv\n",
      "2017-05-01.csv\n",
      "2015-10-01.csv\n",
      "2017-10-01.csv\n",
      "2015-06-01.csv\n",
      "2017-08-01.csv\n",
      "2016-07-01.csv\n",
      "2016-06-01.csv\n",
      "2016-08-01.csv\n",
      "2015-12-01.csv\n",
      "2015-07-01.csv\n",
      "bitcoin\n",
      "2017-11-01.csv\n",
      "2015-09-01.csv\n",
      "2016-03-01.csv\n",
      "2015-11-01.csv\n",
      "2016-02-01.csv\n",
      "2016-05-01.csv\n",
      "2016-09-01.csv\n",
      "2016-04-01.csv\n",
      "2016-12-01.csv\n",
      "2017-01-01.csv\n",
      "2018-04-01.csv\n",
      "2016-11-01.csv\n",
      "2017-09-01.csv\n",
      "2015-08-01.csv\n",
      "2018-03-01.csv\n",
      "2017-06-01.csv\n",
      "2018-02-01.csv\n",
      "2018-01-01.csv\n",
      "2015-05-01.csv\n",
      "2017-03-01.csv\n",
      "2018-05-01.csv\n",
      "2017-02-01.csv\n",
      "2016-10-01.csv\n",
      "2016-01-01.csv\n",
      "2017-12-01.csv\n",
      "2017-04-01.csv\n",
      "2017-07-01.csv\n",
      "2018-06-01.csv\n",
      "2017-05-01.csv\n",
      "2015-10-01.csv\n",
      "2015-02-01.csv\n",
      "2015-03-01.csv\n",
      "2017-10-01.csv\n",
      "2015-06-01.csv\n",
      "2017-08-01.csv\n",
      "2015-01-01.csv\n",
      "2015-04-01.csv\n",
      "2016-07-01.csv\n",
      "2016-06-01.csv\n",
      "2016-08-01.csv\n",
      "2015-12-01.csv\n",
      "2015-07-01.csv\n"
     ]
    }
   ],
   "source": [
    "merge_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_missing_days(df, freq=24):\n",
    "    df['Time'] = pd.to_datetime(df['Time'])\n",
    "\n",
    "    new = pd.DataFrame(columns=['Time', 'Frequency'])\n",
    "\n",
    "    new['Time'] = df['Time']\n",
    "    new['Frequency'] = 1\n",
    "\n",
    "    new.set_index('Time', inplace = True)\n",
    "    per_24 = new['Frequency'].resample('{}H'.format(freq)).sum().fillna(0)\n",
    "    miss_dates = per_24[per_24 == 0].index\n",
    "    return miss_dates\n",
    "        \n",
    "def fill_missing_days():\n",
    "    for fullPath in get_paths():\n",
    "        coinName = fullPath.split(\"/\")[-2]\n",
    "        print(coinName)\n",
    "        \n",
    "        df = pd.read_csv('{}/combined.csv'.format(fullPath))\n",
    "        miss_dates = get_missing_days(miss_dates)\n",
    "        \n",
    "        tweetDf = pd.DataFrame(columns=['ID', 'Tweet', 'Time', 'User', 'Likes', 'Replies', 'Retweet', 'in_response_to', 'response_type'])\n",
    "        \n",
    "        for dates in miss_dates:\n",
    "            date_from = dates - pd.DateOffset(days=2) #might wanna make it 2\n",
    "            date_to = dates + pd.DateOffset(days=2)\n",
    "\n",
    "            print(\"{} to {}\".format(date_from.date(), date_to.date()))\n",
    "\n",
    "            list_of_tweets = query_tweets(coinName, 10000, begindate=date_from.date(), enddate=date_to.date(), poolsize=4)\n",
    "\n",
    "            for tweet in list_of_tweets:\n",
    "                tweetDf = tweetDf.append({'ID': tweet.id, 'Tweet': tweet.text, 'Time': tweet.timestamp, 'User': tweet.user, 'Likes': tweet.likes, 'Replies': tweet.replies, 'Retweet': tweet.retweets, 'in_response_to': tweet.reply_to_id. 'response_type': tweet.response_type}, ignore_index=True)\n",
    "                \n",
    "        tweetDf.to_csv(\"{}/missing.csv\".format(fullPath), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ripple\n",
      "2015-06-15 to 2015-06-19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Querying ripple since:2015-06-16 until:2015-06-17\n",
      "INFO:root:Querying ripple since:2015-06-18 until:2015-06-19\n",
      "INFO:root:Querying ripple since:2015-06-15 until:2015-06-16\n",
      "INFO:root:Querying ripple since:2015-06-17 until:2015-06-18\n",
      "INFO:root:Got 55 tweets for ripple%20since%3A2015-06-16%20until%3A2015-06-17.\n",
      "INFO:root:Got 55 tweets (55 new).\n",
      "INFO:root:Got 48 tweets for ripple%20since%3A2015-06-18%20until%3A2015-06-19.\n",
      "INFO:root:Got 103 tweets (48 new).\n",
      "INFO:root:Got 60 tweets for ripple%20since%3A2015-06-15%20until%3A2015-06-16.\n",
      "INFO:root:Got 163 tweets (60 new).\n",
      "INFO:root:Got 61 tweets for ripple%20since%3A2015-06-17%20until%3A2015-06-18.\n",
      "INFO:root:Got 224 tweets (61 new).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-01-24 to 2016-01-28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Querying ripple since:2016-01-25 until:2016-01-26\n",
      "INFO:root:Querying ripple since:2016-01-26 until:2016-01-27\n",
      "INFO:root:Querying ripple since:2016-01-24 until:2016-01-25\n",
      "INFO:root:Querying ripple since:2016-01-27 until:2016-01-28\n",
      "INFO:root:Got 45 tweets for ripple%20since%3A2016-01-25%20until%3A2016-01-26.\n",
      "INFO:root:Got 45 tweets (45 new).\n",
      "INFO:root:Got 69 tweets for ripple%20since%3A2016-01-26%20until%3A2016-01-27.\n",
      "INFO:root:Got 114 tweets (69 new).\n",
      "INFO:root:Got 61 tweets for ripple%20since%3A2016-01-27%20until%3A2016-01-28.\n",
      "INFO:root:Got 175 tweets (61 new).\n",
      "INFO:root:Got 60 tweets for ripple%20since%3A2016-01-24%20until%3A2016-01-25.\n",
      "INFO:root:Got 235 tweets (60 new).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-02-04 to 2016-02-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Querying ripple since:2016-02-04 until:2016-02-05\n",
      "INFO:root:Querying ripple since:2016-02-06 until:2016-02-07\n",
      "INFO:root:Querying ripple since:2016-02-07 until:2016-02-08\n",
      "INFO:root:Querying ripple since:2016-02-05 until:2016-02-06\n",
      "INFO:root:Got 40 tweets for ripple%20since%3A2016-02-07%20until%3A2016-02-08.\n",
      "INFO:root:Got 40 tweets (40 new).\n",
      "INFO:root:Got 53 tweets for ripple%20since%3A2016-02-06%20until%3A2016-02-07.\n",
      "INFO:root:Got 93 tweets (53 new).\n",
      "INFO:root:Got 64 tweets for ripple%20since%3A2016-02-05%20until%3A2016-02-06.\n",
      "INFO:root:Got 157 tweets (64 new).\n",
      "ERROR:root:Failed to parse JSON \"Expecting value: line 1 column 1 (char 0)\" while requesting \"https://twitter.com/i/search/timeline?vertical=default&include_available_features=1&include_entities=1&reset_error_state=false&src=typd&max_position=TWEET-695034035781963777-695284988510609409-BD1UO2FFu9QAAAAAAAAVfAAAAAcAAABWAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA==-T-0-2&q=ripple%20since%3A2016-02-04%20until%3A2016-02-05&l=\".\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/shresthanikesh23/jupyter/CryptoTraderRemote/CryptoTrader/data_utils/twitter_data/twitterscraper/query.py\", line 54, in query_single_page\n",
      "    json_resp = json.loads(response.text)\n",
      "  File \"/usr/lib/python3.5/json/__init__.py\", line 319, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/usr/lib/python3.5/json/decoder.py\", line 339, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/usr/lib/python3.5/json/decoder.py\", line 357, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "INFO:root:Retrying... (Attempts left: 10)\n",
      "INFO:root:Got 61 tweets for ripple%20since%3A2016-02-04%20until%3A2016-02-05.\n",
      "INFO:root:Got 218 tweets (61 new).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-02-25 to 2016-02-29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Querying ripple since:2016-02-25 until:2016-02-26\n",
      "INFO:root:Querying ripple since:2016-02-27 until:2016-02-28\n",
      "INFO:root:Querying ripple since:2016-02-26 until:2016-02-27\n",
      "INFO:root:Querying ripple since:2016-02-28 until:2016-02-29\n",
      "INFO:root:Got 57 tweets for ripple%20since%3A2016-02-27%20until%3A2016-02-28.\n",
      "INFO:root:Got 57 tweets (57 new).\n",
      "INFO:root:Got 52 tweets for ripple%20since%3A2016-02-28%20until%3A2016-02-29.\n",
      "INFO:root:Got 109 tweets (52 new).\n",
      "INFO:root:Got 64 tweets for ripple%20since%3A2016-02-25%20until%3A2016-02-26.\n",
      "INFO:root:Got 173 tweets (64 new).\n",
      "INFO:root:Got 66 tweets for ripple%20since%3A2016-02-26%20until%3A2016-02-27.\n",
      "INFO:root:Got 239 tweets (66 new).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-04-06 to 2016-04-10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Querying ripple since:2016-04-06 until:2016-04-07\n",
      "INFO:root:Querying ripple since:2016-04-07 until:2016-04-08\n",
      "INFO:root:Querying ripple since:2016-04-09 until:2016-04-10\n",
      "INFO:root:Querying ripple since:2016-04-08 until:2016-04-09\n",
      "INFO:root:Got 57 tweets for ripple%20since%3A2016-04-06%20until%3A2016-04-07.\n",
      "INFO:root:Got 57 tweets (57 new).\n",
      "INFO:root:Got 63 tweets for ripple%20since%3A2016-04-07%20until%3A2016-04-08.\n",
      "INFO:root:Got 120 tweets (63 new).\n",
      "INFO:root:Got 60 tweets for ripple%20since%3A2016-04-08%20until%3A2016-04-09.\n",
      "INFO:root:Got 180 tweets (60 new).\n",
      "INFO:root:Got 62 tweets for ripple%20since%3A2016-04-09%20until%3A2016-04-10.\n",
      "INFO:root:Got 242 tweets (62 new).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-04-08 to 2017-04-12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Querying ripple since:2017-04-08 until:2017-04-09\n",
      "INFO:root:Querying ripple since:2017-04-10 until:2017-04-11\n",
      "INFO:root:Querying ripple since:2017-04-09 until:2017-04-10\n",
      "INFO:root:Querying ripple since:2017-04-11 until:2017-04-12\n",
      "ERROR:root:Failed to parse JSON \"Expecting value: line 1 column 1 (char 0)\" while requesting \"https://twitter.com/i/search/timeline?vertical=default&include_available_features=1&include_entities=1&reset_error_state=false&src=typd&max_position=TWEET-850506672871100418-850717053493415937-BD1UO2FFu9QAAAAAAAAVfAAAAAcAAABWAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA==-T-0-0&q=ripple%20since%3A2017-04-08%20until%3A2017-04-09&l=\".\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/shresthanikesh23/jupyter/CryptoTraderRemote/CryptoTrader/data_utils/twitter_data/twitterscraper/query.py\", line 54, in query_single_page\n",
      "    json_resp = json.loads(response.text)\n",
      "  File \"/usr/lib/python3.5/json/__init__.py\", line 319, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/usr/lib/python3.5/json/decoder.py\", line 339, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/usr/lib/python3.5/json/decoder.py\", line 357, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "INFO:root:Retrying... (Attempts left: 10)\n",
      "INFO:root:Got 60 tweets for ripple%20since%3A2017-04-11%20until%3A2017-04-12.\n",
      "INFO:root:Got 60 tweets (60 new).\n",
      "INFO:root:Got 45 tweets for ripple%20since%3A2017-04-09%20until%3A2017-04-10.\n",
      "INFO:root:Got 105 tweets (45 new).\n",
      "INFO:root:Got 60 tweets for ripple%20since%3A2017-04-08%20until%3A2017-04-09.\n",
      "INFO:root:Got 165 tweets (60 new).\n",
      "INFO:root:Got 62 tweets for ripple%20since%3A2017-04-10%20until%3A2017-04-11.\n",
      "INFO:root:Got 227 tweets (62 new).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-10-14 to 2017-10-18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Querying ripple since:2017-10-15 until:2017-10-16\n",
      "INFO:root:Querying ripple since:2017-10-16 until:2017-10-17\n",
      "INFO:root:Querying ripple since:2017-10-14 until:2017-10-15\n",
      "INFO:root:Querying ripple since:2017-10-17 until:2017-10-18\n",
      "INFO:root:Got 80 tweets for ripple%20since%3A2017-10-15%20until%3A2017-10-16.\n",
      "INFO:root:Got 80 tweets (80 new).\n",
      "INFO:root:Got 89 tweets for ripple%20since%3A2017-10-14%20until%3A2017-10-15.\n",
      "INFO:root:Got 169 tweets (89 new).\n",
      "INFO:root:Got 120 tweets for ripple%20since%3A2017-10-17%20until%3A2017-10-18.\n",
      "INFO:root:Got 289 tweets (120 new).\n",
      "INFO:root:Got 120 tweets for ripple%20since%3A2017-10-16%20until%3A2017-10-17.\n",
      "INFO:root:Got 409 tweets (120 new).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-01-10 to 2018-01-14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Querying ripple since:2018-01-13 until:2018-01-14\n",
      "INFO:root:Querying ripple since:2018-01-10 until:2018-01-11\n",
      "INFO:root:Querying ripple since:2018-01-11 until:2018-01-12\n",
      "INFO:root:Querying ripple since:2018-01-12 until:2018-01-13\n",
      "INFO:root:Got 177 tweets for ripple%20since%3A2018-01-13%20until%3A2018-01-14.\n",
      "INFO:root:Got 177 tweets (177 new).\n",
      "INFO:root:Got 223 tweets for ripple%20since%3A2018-01-12%20until%3A2018-01-13.\n",
      "INFO:root:Got 400 tweets (223 new).\n",
      "INFO:root:Got 276 tweets for ripple%20since%3A2018-01-10%20until%3A2018-01-11.\n",
      "INFO:root:Got 676 tweets (276 new).\n",
      "INFO:root:Got 375 tweets for ripple%20since%3A2018-01-11%20until%3A2018-01-12.\n",
      "INFO:root:Got 1051 tweets (375 new).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-04-07 to 2018-04-11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Querying ripple since:2018-04-07 until:2018-04-08\n",
      "INFO:root:Querying ripple since:2018-04-10 until:2018-04-11\n",
      "INFO:root:Querying ripple since:2018-04-09 until:2018-04-10\n",
      "INFO:root:Querying ripple since:2018-04-08 until:2018-04-09\n",
      "INFO:root:Got 118 tweets for ripple%20since%3A2018-04-08%20until%3A2018-04-09.\n",
      "INFO:root:Got 118 tweets (118 new).\n",
      "INFO:root:Got 121 tweets for ripple%20since%3A2018-04-07%20until%3A2018-04-08.\n",
      "INFO:root:Got 239 tweets (121 new).\n",
      "INFO:root:Got 120 tweets for ripple%20since%3A2018-04-10%20until%3A2018-04-11.\n",
      "INFO:root:Got 359 tweets (120 new).\n",
      "INFO:root:Got 151 tweets for ripple%20since%3A2018-04-09%20until%3A2018-04-10.\n",
      "INFO:root:Got 510 tweets (151 new).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dogecoin\n",
      "2015-01-07 to 2015-01-11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Querying dogecoin since:2015-01-09 until:2015-01-10\n",
      "INFO:root:Querying dogecoin since:2015-01-10 until:2015-01-11\n",
      "INFO:root:Querying dogecoin since:2015-01-07 until:2015-01-08\n",
      "INFO:root:Querying dogecoin since:2015-01-08 until:2015-01-09\n",
      "INFO:root:Got 0 tweets for dogecoin%20since%3A2015-01-08%20until%3A2015-01-09.\n",
      "INFO:root:Got 0 tweets (0 new).\n",
      "ERROR:root:Failed to parse JSON \"Expecting value: line 1 column 1 (char 0)\" while requesting \"https://twitter.com/i/search/timeline?vertical=default&include_available_features=1&include_entities=1&reset_error_state=false&src=typd&max_position=TWEET-553340635848003584-553562591898120193-BD1UO2FFu9QAAAAAAAAVfAAAAAcAAABWAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA==-T-0-1&q=dogecoin%20since%3A2015-01-09%20until%3A2015-01-10&l=\".\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/shresthanikesh23/jupyter/CryptoTraderRemote/CryptoTrader/data_utils/twitter_data/twitterscraper/query.py\", line 54, in query_single_page\n",
      "    json_resp = json.loads(response.text)\n",
      "  File \"/usr/lib/python3.5/json/__init__.py\", line 319, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/usr/lib/python3.5/json/decoder.py\", line 339, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/usr/lib/python3.5/json/decoder.py\", line 357, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)INFO:root:Retrying... (Attempts left: 10)\n",
      "\n",
      "INFO:root:Got 56 tweets for dogecoin%20since%3A2015-01-07%20until%3A2015-01-08.\n",
      "INFO:root:Got 56 tweets (56 new).\n",
      "INFO:root:Got 49 tweets for dogecoin%20since%3A2015-01-09%20until%3A2015-01-10.\n",
      "INFO:root:Got 105 tweets (49 new).\n",
      "INFO:root:Got 51 tweets for dogecoin%20since%3A2015-01-10%20until%3A2015-01-11.\n",
      "INFO:root:Got 156 tweets (51 new).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015-01-10 to 2015-01-14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Querying dogecoin since:2015-01-11 until:2015-01-12\n",
      "INFO:root:Querying dogecoin since:2015-01-10 until:2015-01-11\n",
      "INFO:root:Querying dogecoin since:2015-01-12 until:2015-01-13\n",
      "INFO:root:Querying dogecoin since:2015-01-13 until:2015-01-14\n",
      "INFO:root:Got 44 tweets for dogecoin%20since%3A2015-01-11%20until%3A2015-01-12.\n",
      "INFO:root:Got 44 tweets (44 new).\n",
      "INFO:root:Got 44 tweets for dogecoin%20since%3A2015-01-13%20until%3A2015-01-14.\n",
      "INFO:root:Got 88 tweets (44 new).\n",
      "INFO:root:Got 51 tweets for dogecoin%20since%3A2015-01-10%20until%3A2015-01-11.\n",
      "INFO:root:Got 139 tweets (51 new).\n",
      "INFO:root:Got 54 tweets for dogecoin%20since%3A2015-01-12%20until%3A2015-01-13.\n",
      "INFO:root:Got 193 tweets (54 new).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015-06-19 to 2015-06-23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Querying dogecoin since:2015-06-20 until:2015-06-21\n",
      "INFO:root:Querying dogecoin since:2015-06-21 until:2015-06-22\n",
      "INFO:root:Querying dogecoin since:2015-06-22 until:2015-06-23\n",
      "INFO:root:Querying dogecoin since:2015-06-19 until:2015-06-20\n",
      "INFO:root:Got 40 tweets for dogecoin%20since%3A2015-06-21%20until%3A2015-06-22.\n",
      "INFO:root:Got 40 tweets (40 new).\n",
      "INFO:root:Got 31 tweets for dogecoin%20since%3A2015-06-22%20until%3A2015-06-23.\n",
      "INFO:root:Got 71 tweets (31 new).\n",
      "INFO:root:Got 49 tweets for dogecoin%20since%3A2015-06-19%20until%3A2015-06-20.\n",
      "INFO:root:Got 120 tweets (49 new).\n",
      "INFO:root:Got 46 tweets for dogecoin%20since%3A2015-06-20%20until%3A2015-06-21.\n",
      "INFO:root:Got 166 tweets (46 new).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-01-09 to 2016-01-13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Querying dogecoin since:2016-01-10 until:2016-01-11\n",
      "INFO:root:Querying dogecoin since:2016-01-11 until:2016-01-12\n",
      "INFO:root:Querying dogecoin since:2016-01-09 until:2016-01-10\n",
      "INFO:root:Querying dogecoin since:2016-01-12 until:2016-01-13\n",
      "INFO:root:Got 28 tweets for dogecoin%20since%3A2016-01-10%20until%3A2016-01-11.\n",
      "INFO:root:Got 28 tweets (28 new).\n",
      "INFO:root:Got 39 tweets for dogecoin%20since%3A2016-01-09%20until%3A2016-01-10.\n",
      "INFO:root:Got 67 tweets (39 new).\n",
      "INFO:root:Got 37 tweets for dogecoin%20since%3A2016-01-12%20until%3A2016-01-13.\n",
      "INFO:root:Got 104 tweets (37 new).\n",
      "INFO:root:Got 41 tweets for dogecoin%20since%3A2016-01-11%20until%3A2016-01-12.\n",
      "INFO:root:Got 145 tweets (41 new).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-12-08 to 2016-12-12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Querying dogecoin since:2016-12-11 until:2016-12-12\n",
      "INFO:root:Querying dogecoin since:2016-12-10 until:2016-12-11\n",
      "INFO:root:Querying dogecoin since:2016-12-08 until:2016-12-09\n",
      "INFO:root:Querying dogecoin since:2016-12-09 until:2016-12-10\n",
      "INFO:root:Got 31 tweets for dogecoin%20since%3A2016-12-08%20until%3A2016-12-09.\n",
      "INFO:root:Got 31 tweets (31 new).\n",
      "INFO:root:Got 35 tweets for dogecoin%20since%3A2016-12-09%20until%3A2016-12-10.\n",
      "INFO:root:Got 66 tweets (35 new).\n",
      "INFO:root:Got 37 tweets for dogecoin%20since%3A2016-12-10%20until%3A2016-12-11.\n",
      "INFO:root:Got 103 tweets (37 new).\n",
      "INFO:root:Got 31 tweets for dogecoin%20since%3A2016-12-11%20until%3A2016-12-12.\n",
      "INFO:root:Got 134 tweets (31 new).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-03-02 to 2017-03-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Querying dogecoin since:2017-03-03 until:2017-03-04\n",
      "INFO:root:Querying dogecoin since:2017-03-04 until:2017-03-05\n",
      "INFO:root:Querying dogecoin since:2017-03-02 until:2017-03-03\n",
      "INFO:root:Querying dogecoin since:2017-03-05 until:2017-03-06\n",
      "INFO:root:Got 33 tweets for dogecoin%20since%3A2017-03-03%20until%3A2017-03-04.\n",
      "INFO:root:Got 33 tweets (33 new).\n",
      "INFO:root:Got 21 tweets for dogecoin%20since%3A2017-03-04%20until%3A2017-03-05.\n",
      "INFO:root:Got 54 tweets (21 new).\n",
      "INFO:root:Got 37 tweets for dogecoin%20since%3A2017-03-02%20until%3A2017-03-03.\n",
      "INFO:root:Got 91 tweets (37 new).\n",
      "INFO:root:Got 35 tweets for dogecoin%20since%3A2017-03-05%20until%3A2017-03-06.\n",
      "INFO:root:Got 126 tweets (35 new).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-03-31 to 2017-04-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Querying dogecoin since:2017-03-31 until:2017-04-01\n",
      "INFO:root:Querying dogecoin since:2017-04-03 until:2017-04-04\n",
      "INFO:root:Querying dogecoin since:2017-04-02 until:2017-04-03\n",
      "INFO:root:Querying dogecoin since:2017-04-01 until:2017-04-02\n",
      "INFO:root:Got 26 tweets for dogecoin%20since%3A2017-04-03%20until%3A2017-04-04.\n",
      "INFO:root:Got 26 tweets (26 new).\n",
      "INFO:root:Got 23 tweets for dogecoin%20since%3A2017-03-31%20until%3A2017-04-01.\n",
      "INFO:root:Got 49 tweets (23 new).\n",
      "INFO:root:Got 31 tweets for dogecoin%20since%3A2017-04-01%20until%3A2017-04-02.\n",
      "INFO:root:Got 80 tweets (31 new).\n",
      "INFO:root:Got 45 tweets for dogecoin%20since%3A2017-04-02%20until%3A2017-04-03.\n",
      "INFO:root:Got 125 tweets (45 new).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-07-16 to 2017-07-20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Querying dogecoin since:2017-07-16 until:2017-07-17\n",
      "INFO:root:Querying dogecoin since:2017-07-17 until:2017-07-18\n",
      "INFO:root:Querying dogecoin since:2017-07-18 until:2017-07-19\n",
      "INFO:root:Querying dogecoin since:2017-07-19 until:2017-07-20\n",
      "INFO:root:Got 33 tweets for dogecoin%20since%3A2017-07-18%20until%3A2017-07-19.\n",
      "INFO:root:Got 33 tweets (33 new).\n",
      "ERROR:root:Failed to parse JSON \"Expecting value: line 1 column 1 (char 0)\" while requesting \"https://twitter.com/i/search/timeline?vertical=default&include_available_features=1&include_entities=1&reset_error_state=false&src=typd&max_position=TWEET-887462251464085504-887818573971955712-BD1UO2FFu9QAAAAAAAAVfAAAAAcAAABWAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA==-T-0-1&q=dogecoin%20since%3A2017-07-19%20until%3A2017-07-20&l=\".\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/shresthanikesh23/jupyter/CryptoTraderRemote/CryptoTrader/data_utils/twitter_data/twitterscraper/query.py\", line 54, in query_single_page\n",
      "    json_resp = json.loads(response.text)\n",
      "  File \"/usr/lib/python3.5/json/__init__.py\", line 319, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/usr/lib/python3.5/json/decoder.py\", line 339, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/usr/lib/python3.5/json/decoder.py\", line 357, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "INFO:root:Retrying... (Attempts left: 10)\n",
      "INFO:root:Got 34 tweets for dogecoin%20since%3A2017-07-16%20until%3A2017-07-17.\n",
      "INFO:root:Got 67 tweets (34 new).\n",
      "INFO:root:Got 30 tweets for dogecoin%20since%3A2017-07-19%20until%3A2017-07-20.\n",
      "INFO:root:Got 97 tweets (30 new).\n",
      "INFO:root:Got 40 tweets for dogecoin%20since%3A2017-07-17%20until%3A2017-07-18.\n",
      "INFO:root:Got 137 tweets (40 new).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-09-27 to 2017-10-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Querying dogecoin since:2017-09-29 until:2017-09-30\n",
      "INFO:root:Querying dogecoin since:2017-09-28 until:2017-09-29\n",
      "INFO:root:Querying dogecoin since:2017-09-27 until:2017-09-28\n",
      "INFO:root:Querying dogecoin since:2017-09-30 until:2017-10-01\n",
      "INFO:root:Got 31 tweets for dogecoin%20since%3A2017-09-28%20until%3A2017-09-29.\n",
      "INFO:root:Got 31 tweets (31 new).\n",
      "INFO:root:Got 32 tweets for dogecoin%20since%3A2017-09-29%20until%3A2017-09-30.\n",
      "INFO:root:Got 63 tweets (32 new).\n",
      "INFO:root:Got 42 tweets for dogecoin%20since%3A2017-09-27%20until%3A2017-09-28.\n",
      "INFO:root:Got 105 tweets (42 new).\n",
      "INFO:root:Got 47 tweets for dogecoin%20since%3A2017-09-30%20until%3A2017-10-01.\n",
      "INFO:root:Got 152 tweets (47 new).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-01-15 to 2018-01-19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Querying dogecoin since:2018-01-16 until:2018-01-17\n",
      "INFO:root:Querying dogecoin since:2018-01-17 until:2018-01-18\n",
      "INFO:root:Querying dogecoin since:2018-01-15 until:2018-01-16\n",
      "INFO:root:Querying dogecoin since:2018-01-18 until:2018-01-19\n",
      "INFO:root:Got 58 tweets for dogecoin%20since%3A2018-01-17%20until%3A2018-01-18.\n",
      "INFO:root:Got 58 tweets (58 new).\n",
      "INFO:root:Got 58 tweets for dogecoin%20since%3A2018-01-16%20until%3A2018-01-17.\n",
      "INFO:root:Got 116 tweets (58 new).\n",
      "INFO:root:Got 61 tweets for dogecoin%20since%3A2018-01-15%20until%3A2018-01-16.\n",
      "INFO:root:Got 177 tweets (61 new).\n",
      "INFO:root:Got 58 tweets for dogecoin%20since%3A2018-01-18%20until%3A2018-01-19.\n",
      "INFO:root:Got 235 tweets (58 new).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-02-15 to 2018-02-19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Querying dogecoin since:2018-02-16 until:2018-02-17\n",
      "INFO:root:Querying dogecoin since:2018-02-15 until:2018-02-16\n",
      "INFO:root:Querying dogecoin since:2018-02-17 until:2018-02-18\n",
      "INFO:root:Querying dogecoin since:2018-02-18 until:2018-02-19\n",
      "ERROR:root:Failed to parse JSON \"Expecting value: line 1 column 1 (char 0)\" while requesting \"https://twitter.com/i/search/timeline?vertical=default&include_available_features=1&include_entities=1&reset_error_state=false&src=typd&max_position=TWEET-965256847035858946-965104973850660864&q=dogecoin%20since%3A2018-02-18%20until%3A2018-02-19&l=\".\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/shresthanikesh23/jupyter/CryptoTraderRemote/CryptoTrader/data_utils/twitter_data/twitterscraper/query.py\", line 54, in query_single_page\n",
      "    json_resp = json.loads(response.text)\n",
      "  File \"/usr/lib/python3.5/json/__init__.py\", line 319, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/usr/lib/python3.5/json/decoder.py\", line 339, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/usr/lib/python3.5/json/decoder.py\", line 357, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "INFO:root:Retrying... (Attempts left: 10)\n",
      "INFO:root:Got 51 tweets for dogecoin%20since%3A2018-02-17%20until%3A2018-02-18.\n",
      "INFO:root:Got 51 tweets (51 new).\n",
      "INFO:root:Got 40 tweets for dogecoin%20since%3A2018-02-18%20until%3A2018-02-19.\n",
      "INFO:root:Got 91 tweets (40 new).\n",
      "INFO:root:Got 64 tweets for dogecoin%20since%3A2018-02-16%20until%3A2018-02-17.\n",
      "INFO:root:Got 155 tweets (64 new).\n",
      "INFO:root:Got 62 tweets for dogecoin%20since%3A2018-02-15%20until%3A2018-02-16.\n",
      "INFO:root:Got 217 tweets (62 new).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-04-11 to 2018-04-15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Querying dogecoin since:2018-04-12 until:2018-04-13\n",
      "INFO:root:Querying dogecoin since:2018-04-13 until:2018-04-14\n",
      "INFO:root:Querying dogecoin since:2018-04-11 until:2018-04-12\n",
      "INFO:root:Querying dogecoin since:2018-04-14 until:2018-04-15\n",
      "INFO:root:Got 47 tweets for dogecoin%20since%3A2018-04-11%20until%3A2018-04-12.\n",
      "INFO:root:Got 47 tweets (47 new).\n",
      "INFO:root:Got 48 tweets for dogecoin%20since%3A2018-04-13%20until%3A2018-04-14.\n",
      "INFO:root:Got 95 tweets (48 new).\n",
      "INFO:root:Got 43 tweets for dogecoin%20since%3A2018-04-12%20until%3A2018-04-13.\n",
      "INFO:root:Got 138 tweets (43 new).\n",
      "INFO:root:Got 48 tweets for dogecoin%20since%3A2018-04-14%20until%3A2018-04-15.\n",
      "INFO:root:Got 186 tweets (48 new).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-25 to 2018-05-29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Querying dogecoin since:2018-05-26 until:2018-05-27\n",
      "INFO:root:Querying dogecoin since:2018-05-25 until:2018-05-26\n",
      "INFO:root:Querying dogecoin since:2018-05-27 until:2018-05-28\n",
      "INFO:root:Querying dogecoin since:2018-05-28 until:2018-05-29\n",
      "INFO:root:Got 0 tweets for dogecoin%20since%3A2018-05-28%20until%3A2018-05-29.\n",
      "INFO:root:Got 0 tweets (0 new).\n",
      "INFO:root:Got 42 tweets for dogecoin%20since%3A2018-05-25%20until%3A2018-05-26.\n",
      "INFO:root:Got 42 tweets (42 new).\n",
      "INFO:root:Got 53 tweets for dogecoin%20since%3A2018-05-26%20until%3A2018-05-27.\n",
      "INFO:root:Got 95 tweets (53 new).\n",
      "INFO:root:Got 48 tweets for dogecoin%20since%3A2018-05-27%20until%3A2018-05-28.\n",
      "INFO:root:Got 143 tweets (48 new).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "monero\n",
      "2015-04-27 to 2015-05-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Querying monero since:2015-04-29 until:2015-04-30\n",
      "INFO:root:Querying monero since:2015-04-27 until:2015-04-28\n",
      "INFO:root:Querying monero since:2015-04-28 until:2015-04-29\n",
      "INFO:root:Querying monero since:2015-04-30 until:2015-05-01\n",
      "INFO:root:Got 19 tweets for monero%20since%3A2015-04-28%20until%3A2015-04-29.\n",
      "INFO:root:Got 19 tweets (19 new).\n",
      "INFO:root:Got 24 tweets for monero%20since%3A2015-04-29%20until%3A2015-04-30.\n",
      "INFO:root:Got 43 tweets (24 new).\n",
      "INFO:root:Got 40 tweets for monero%20since%3A2015-04-30%20until%3A2015-05-01.\n",
      "INFO:root:Got 83 tweets (40 new).\n",
      "INFO:root:Got 25 tweets for monero%20since%3A2015-04-27%20until%3A2015-04-28.\n",
      "INFO:root:Got 108 tweets (25 new).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-07-12 to 2016-07-16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Querying monero since:2016-07-13 until:2016-07-14\n",
      "INFO:root:Querying monero since:2016-07-14 until:2016-07-15\n",
      "INFO:root:Querying monero since:2016-07-12 until:2016-07-13\n",
      "INFO:root:Querying monero since:2016-07-15 until:2016-07-16\n",
      "INFO:root:Got 16 tweets for monero%20since%3A2016-07-15%20until%3A2016-07-16.\n",
      "INFO:root:Got 16 tweets (16 new).\n",
      "INFO:root:Got 15 tweets for monero%20since%3A2016-07-14%20until%3A2016-07-15.\n",
      "INFO:root:Got 31 tweets (15 new).\n",
      "INFO:root:Got 24 tweets for monero%20since%3A2016-07-13%20until%3A2016-07-14.\n",
      "INFO:root:Got 55 tweets (24 new).\n",
      "INFO:root:Got 25 tweets for monero%20since%3A2016-07-12%20until%3A2016-07-13.\n",
      "INFO:root:Got 80 tweets (25 new).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-07-31 to 2016-08-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Querying monero since:2016-08-01 until:2016-08-02\n",
      "INFO:root:Querying monero since:2016-07-31 until:2016-08-01\n",
      "INFO:root:Querying monero since:2016-08-02 until:2016-08-03\n",
      "INFO:root:Querying monero since:2016-08-03 until:2016-08-04\n",
      "INFO:root:Got 20 tweets for monero%20since%3A2016-07-31%20until%3A2016-08-01.\n",
      "INFO:root:Got 20 tweets (20 new).\n",
      "INFO:root:Got 16 tweets for monero%20since%3A2016-08-01%20until%3A2016-08-02.\n",
      "INFO:root:Got 36 tweets (16 new).\n",
      "INFO:root:Got 23 tweets for monero%20since%3A2016-08-02%20until%3A2016-08-03.\n",
      "INFO:root:Got 59 tweets (23 new).\n",
      "INFO:root:Got 30 tweets for monero%20since%3A2016-08-03%20until%3A2016-08-04.\n",
      "INFO:root:Got 89 tweets (30 new).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-08-03 to 2016-08-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Querying monero since:2016-08-03 until:2016-08-04\n",
      "INFO:root:Querying monero since:2016-08-05 until:2016-08-06\n",
      "INFO:root:Querying monero since:2016-08-06 until:2016-08-07\n",
      "INFO:root:Querying monero since:2016-08-04 until:2016-08-05\n",
      "INFO:root:Got 16 tweets for monero%20since%3A2016-08-04%20until%3A2016-08-05.\n",
      "INFO:root:Got 16 tweets (16 new).\n",
      "INFO:root:Got 30 tweets for monero%20since%3A2016-08-03%20until%3A2016-08-04.\n",
      "INFO:root:Got 46 tweets (30 new).\n",
      "INFO:root:Got 21 tweets for monero%20since%3A2016-08-06%20until%3A2016-08-07.\n",
      "INFO:root:Got 67 tweets (21 new).\n",
      "INFO:root:Got 18 tweets for monero%20since%3A2016-08-05%20until%3A2016-08-06.\n",
      "INFO:root:Got 85 tweets (18 new).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-01-27 to 2017-01-31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Querying monero since:2017-01-27 until:2017-01-28\n",
      "INFO:root:Querying monero since:2017-01-28 until:2017-01-29\n",
      "INFO:root:Querying monero since:2017-01-29 until:2017-01-30\n",
      "INFO:root:Querying monero since:2017-01-30 until:2017-01-31\n",
      "INFO:root:Got 24 tweets for monero%20since%3A2017-01-27%20until%3A2017-01-28.\n",
      "INFO:root:Got 24 tweets (24 new).\n",
      "INFO:root:Got 24 tweets for monero%20since%3A2017-01-29%20until%3A2017-01-30.\n",
      "INFO:root:Got 48 tweets (24 new).\n",
      "INFO:root:Got 27 tweets for monero%20since%3A2017-01-30%20until%3A2017-01-31.\n",
      "INFO:root:Got 75 tweets (27 new).\n",
      "INFO:root:Got 35 tweets for monero%20since%3A2017-01-28%20until%3A2017-01-29.\n",
      "INFO:root:Got 110 tweets (35 new).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-02-11 to 2017-02-15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Querying monero since:2017-02-11 until:2017-02-12\n",
      "INFO:root:Querying monero since:2017-02-12 until:2017-02-13\n",
      "INFO:root:Querying monero since:2017-02-13 until:2017-02-14\n",
      "INFO:root:Querying monero since:2017-02-14 until:2017-02-15\n",
      "INFO:root:Got 5 tweets for monero%20since%3A2017-02-13%20until%3A2017-02-14.\n",
      "INFO:root:Got 5 tweets (5 new).\n",
      "INFO:root:Got 13 tweets for monero%20since%3A2017-02-14%20until%3A2017-02-15.\n",
      "INFO:root:Got 18 tweets (13 new).\n",
      "INFO:root:Got 17 tweets for monero%20since%3A2017-02-12%20until%3A2017-02-13.\n",
      "INFO:root:Got 35 tweets (17 new).\n",
      "INFO:root:Got 21 tweets for monero%20since%3A2017-02-11%20until%3A2017-02-12.\n",
      "INFO:root:Got 56 tweets (21 new).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-02-19 to 2017-02-23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Querying monero since:2017-02-21 until:2017-02-22\n",
      "INFO:root:Querying monero since:2017-02-19 until:2017-02-20\n",
      "INFO:root:Querying monero since:2017-02-20 until:2017-02-21\n",
      "INFO:root:Querying monero since:2017-02-22 until:2017-02-23\n",
      "INFO:root:Got 10 tweets for monero%20since%3A2017-02-21%20until%3A2017-02-22.\n",
      "INFO:root:Got 10 tweets (10 new).\n",
      "INFO:root:Got 24 tweets for monero%20since%3A2017-02-22%20until%3A2017-02-23.\n",
      "INFO:root:Got 34 tweets (24 new).\n",
      "INFO:root:Got 23 tweets for monero%20since%3A2017-02-20%20until%3A2017-02-21.\n",
      "INFO:root:Got 57 tweets (23 new).\n",
      "INFO:root:Got 22 tweets for monero%20since%3A2017-02-19%20until%3A2017-02-20.\n",
      "INFO:root:Got 79 tweets (22 new).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-03-25 to 2017-03-29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Querying monero since:2017-03-25 until:2017-03-26\n",
      "INFO:root:Querying monero since:2017-03-26 until:2017-03-27\n",
      "INFO:root:Querying monero since:2017-03-27 until:2017-03-28\n",
      "INFO:root:Querying monero since:2017-03-28 until:2017-03-29\n",
      "INFO:root:Got 24 tweets for monero%20since%3A2017-03-28%20until%3A2017-03-29.\n",
      "INFO:root:Got 24 tweets (24 new).\n",
      "INFO:root:Got 29 tweets for monero%20since%3A2017-03-25%20until%3A2017-03-26.\n",
      "INFO:root:Got 53 tweets (29 new).\n",
      "INFO:root:Got 31 tweets for monero%20since%3A2017-03-27%20until%3A2017-03-28.\n",
      "INFO:root:Got 84 tweets (31 new).\n",
      "INFO:root:Got 40 tweets for monero%20since%3A2017-03-26%20until%3A2017-03-27.\n",
      "INFO:root:Got 124 tweets (40 new).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-04-16 to 2017-04-20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Querying monero since:2017-04-16 until:2017-04-17\n",
      "INFO:root:Querying monero since:2017-04-18 until:2017-04-19\n",
      "INFO:root:Querying monero since:2017-04-19 until:2017-04-20\n",
      "INFO:root:Querying monero since:2017-04-17 until:2017-04-18\n",
      "INFO:root:Got 35 tweets for monero%20since%3A2017-04-17%20until%3A2017-04-18.\n",
      "INFO:root:Got 35 tweets (35 new).\n",
      "INFO:root:Got 40 tweets for monero%20since%3A2017-04-19%20until%3A2017-04-20.\n",
      "INFO:root:Got 75 tweets (40 new).\n",
      "INFO:root:Got 40 tweets for monero%20since%3A2017-04-16%20until%3A2017-04-17.\n",
      "INFO:root:Got 115 tweets (40 new).\n",
      "INFO:root:Got 37 tweets for monero%20since%3A2017-04-18%20until%3A2017-04-19.\n",
      "INFO:root:Got 152 tweets (37 new).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-11-26 to 2017-11-30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Querying monero since:2017-11-27 until:2017-11-28\n",
      "INFO:root:Querying monero since:2017-11-28 until:2017-11-29\n",
      "INFO:root:Querying monero since:2017-11-29 until:2017-11-30\n",
      "INFO:root:Querying monero since:2017-11-26 until:2017-11-27\n",
      "INFO:root:Got 47 tweets for monero%20since%3A2017-11-27%20until%3A2017-11-28.\n",
      "INFO:root:Got 47 tweets (47 new).\n",
      "INFO:root:Got 54 tweets for monero%20since%3A2017-11-26%20until%3A2017-11-27.\n",
      "INFO:root:Got 101 tweets (54 new).\n",
      "INFO:root:Got 61 tweets for monero%20since%3A2017-11-29%20until%3A2017-11-30.\n",
      "INFO:root:Got 162 tweets (61 new).\n",
      "INFO:root:Got 58 tweets for monero%20since%3A2017-11-28%20until%3A2017-11-29.\n",
      "INFO:root:Got 220 tweets (58 new).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-12-21 to 2017-12-25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Querying monero since:2017-12-21 until:2017-12-22\n",
      "INFO:root:Querying monero since:2017-12-22 until:2017-12-23\n",
      "INFO:root:Querying monero since:2017-12-23 until:2017-12-24\n",
      "INFO:root:Querying monero since:2017-12-24 until:2017-12-25\n",
      "INFO:root:Got 64 tweets for monero%20since%3A2017-12-21%20until%3A2017-12-22.\n",
      "INFO:root:Got 64 tweets (64 new).\n",
      "INFO:root:Got 59 tweets for monero%20since%3A2017-12-24%20until%3A2017-12-25.\n",
      "INFO:root:Got 123 tweets (59 new).\n",
      "INFO:root:Got 59 tweets for monero%20since%3A2017-12-22%20until%3A2017-12-23.\n",
      "INFO:root:Got 182 tweets (59 new).\n",
      "INFO:root:Got 78 tweets for monero%20since%3A2017-12-23%20until%3A2017-12-24.\n",
      "INFO:root:Got 260 tweets (78 new).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-16 to 2018-05-20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Querying monero since:2018-05-18 until:2018-05-19\n",
      "INFO:root:Querying monero since:2018-05-16 until:2018-05-17\n",
      "INFO:root:Querying monero since:2018-05-17 until:2018-05-18\n",
      "INFO:root:Querying monero since:2018-05-19 until:2018-05-20\n",
      "INFO:root:Got 47 tweets for monero%20since%3A2018-05-18%20until%3A2018-05-19.\n",
      "INFO:root:Got 47 tweets (47 new).\n",
      "INFO:root:Got 55 tweets for monero%20since%3A2018-05-17%20until%3A2018-05-18.\n",
      "INFO:root:Got 102 tweets (55 new).\n",
      "INFO:root:Got 54 tweets for monero%20since%3A2018-05-19%20until%3A2018-05-20.\n",
      "INFO:root:Got 156 tweets (54 new).\n",
      "INFO:root:Got 70 tweets for monero%20since%3A2018-05-16%20until%3A2018-05-17.\n",
      "INFO:root:Got 226 tweets (70 new).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stellar\n",
      "2014-12-01 to 2014-12-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Querying stellar since:2014-12-04 until:2014-12-05\n",
      "INFO:root:Querying stellar since:2014-12-03 until:2014-12-04\n",
      "INFO:root:Querying stellar since:2014-12-01 until:2014-12-02\n",
      "INFO:root:Querying stellar since:2014-12-02 until:2014-12-03\n",
      "ERROR:root:Failed to parse JSON \"Expecting value: line 1 column 1 (char 0)\" while requesting \"https://twitter.com/i/search/timeline?vertical=default&include_available_features=1&include_entities=1&reset_error_state=false&src=typd&max_position=TWEET-539207281561174016-539501920319447040-BD1UO2FFu9QAAAAAAAAVfAAAAAcAAABWAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA==-T-0-1&q=stellar%20since%3A2014-12-01%20until%3A2014-12-02&l=\".\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/shresthanikesh23/jupyter/CryptoTraderRemote/CryptoTrader/data_utils/twitter_data/twitterscraper/query.py\", line 54, in query_single_page\n",
      "    json_resp = json.loads(response.text)\n",
      "  File \"/usr/lib/python3.5/json/__init__.py\", line 319, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/usr/lib/python3.5/json/decoder.py\", line 339, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/usr/lib/python3.5/json/decoder.py\", line 357, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "INFO:root:Retrying... (Attempts left: 10)\n",
      "INFO:root:Got 59 tweets for stellar%20since%3A2014-12-01%20until%3A2014-12-02.\n",
      "INFO:root:Got 59 tweets (59 new).\n",
      "INFO:root:Got 62 tweets for stellar%20since%3A2014-12-03%20until%3A2014-12-04.\n",
      "INFO:root:Got 121 tweets (62 new).\n",
      "INFO:root:Got 62 tweets for stellar%20since%3A2014-12-02%20until%3A2014-12-03.\n",
      "INFO:root:Got 183 tweets (62 new).\n",
      "INFO:root:Got 83 tweets for stellar%20since%3A2014-12-04%20until%3A2014-12-05.\n",
      "INFO:root:Got 266 tweets (83 new).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015-07-21 to 2015-07-25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Querying stellar since:2015-07-21 until:2015-07-22\n",
      "INFO:root:Querying stellar since:2015-07-22 until:2015-07-23\n",
      "INFO:root:Querying stellar since:2015-07-23 until:2015-07-24\n",
      "INFO:root:Querying stellar since:2015-07-24 until:2015-07-25\n",
      "INFO:root:Got 0 tweets for stellar%20since%3A2015-07-22%20until%3A2015-07-23.\n",
      "INFO:root:Got 0 tweets (0 new).\n",
      "INFO:root:Got 81 tweets for stellar%20since%3A2015-07-24%20until%3A2015-07-25.\n",
      "INFO:root:Got 81 tweets (81 new).\n",
      "INFO:root:Got 99 tweets for stellar%20since%3A2015-07-23%20until%3A2015-07-24.\n",
      "INFO:root:Got 180 tweets (99 new).\n",
      "INFO:root:Got 106 tweets for stellar%20since%3A2015-07-21%20until%3A2015-07-22.\n",
      "INFO:root:Got 286 tweets (106 new).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-02-28 to 2016-03-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Querying stellar since:2016-03-01 until:2016-03-02\n",
      "INFO:root:Querying stellar since:2016-02-28 until:2016-02-29\n",
      "INFO:root:Querying stellar since:2016-03-02 until:2016-03-03\n",
      "INFO:root:Querying stellar since:2016-02-29 until:2016-03-01\n",
      "INFO:root:Got 80 tweets for stellar%20since%3A2016-03-01%20until%3A2016-03-02.\n",
      "INFO:root:Got 80 tweets (80 new).\n",
      "INFO:root:Got 68 tweets for stellar%20since%3A2016-02-29%20until%3A2016-03-01.\n",
      "INFO:root:Got 148 tweets (68 new).\n",
      "INFO:root:Got 80 tweets for stellar%20since%3A2016-02-28%20until%3A2016-02-29.\n",
      "INFO:root:Got 228 tweets (80 new).\n",
      "INFO:root:Got 80 tweets for stellar%20since%3A2016-03-02%20until%3A2016-03-03.\n",
      "INFO:root:Got 308 tweets (80 new).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-03-12 to 2017-03-16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Querying stellar since:2017-03-12 until:2017-03-13\n",
      "INFO:root:Querying stellar since:2017-03-14 until:2017-03-15\n",
      "INFO:root:Querying stellar since:2017-03-15 until:2017-03-16\n",
      "INFO:root:Querying stellar since:2017-03-13 until:2017-03-14\n",
      "INFO:root:Got 80 tweets for stellar%20since%3A2017-03-14%20until%3A2017-03-15.\n",
      "INFO:root:Got 80 tweets (80 new).\n",
      "INFO:root:Got 80 tweets for stellar%20since%3A2017-03-13%20until%3A2017-03-14.\n",
      "INFO:root:Got 160 tweets (80 new).\n",
      "INFO:root:Got 83 tweets for stellar%20since%3A2017-03-15%20until%3A2017-03-16.\n",
      "INFO:root:Got 243 tweets (83 new).\n",
      "INFO:root:Got 81 tweets for stellar%20since%3A2017-03-12%20until%3A2017-03-13.\n",
      "INFO:root:Got 324 tweets (81 new).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-04-15 to 2017-04-19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Querying stellar since:2017-04-15 until:2017-04-16\n",
      "INFO:root:Querying stellar since:2017-04-18 until:2017-04-19\n",
      "INFO:root:Querying stellar since:2017-04-17 until:2017-04-18\n",
      "INFO:root:Querying stellar since:2017-04-16 until:2017-04-17\n",
      "INFO:root:Got 77 tweets for stellar%20since%3A2017-04-18%20until%3A2017-04-19.\n",
      "INFO:root:Got 77 tweets (77 new).\n",
      "INFO:root:Got 64 tweets for stellar%20since%3A2017-04-17%20until%3A2017-04-18.\n",
      "INFO:root:Got 141 tweets (64 new).\n",
      "INFO:root:Got 81 tweets for stellar%20since%3A2017-04-15%20until%3A2017-04-16.\n",
      "INFO:root:Got 222 tweets (81 new).\n",
      "INFO:root:Got 91 tweets for stellar%20since%3A2017-04-16%20until%3A2017-04-17.\n",
      "INFO:root:Got 313 tweets (91 new).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-04-20 to 2017-04-24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Querying stellar since:2017-04-21 until:2017-04-22\n",
      "INFO:root:Querying stellar since:2017-04-22 until:2017-04-23\n",
      "INFO:root:Querying stellar since:2017-04-23 until:2017-04-24\n",
      "INFO:root:Querying stellar since:2017-04-20 until:2017-04-21\n",
      "ERROR:root:Failed to parse JSON \"Expecting value: line 1 column 1 (char 0)\" while requesting \"https://twitter.com/i/search/timeline?vertical=default&include_available_features=1&include_entities=1&reset_error_state=false&src=typd&max_position=TWEET-855213781269585921-855556943120871429-BD1UO2FFu9QAAAAAAAAVfAAAAAcAAABWAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA==-T-0-1&q=stellar%20since%3A2017-04-21%20until%3A2017-04-22&l=\".\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/shresthanikesh23/jupyter/CryptoTraderRemote/CryptoTrader/data_utils/twitter_data/twitterscraper/query.py\", line 54, in query_single_page\n",
      "    json_resp = json.loads(response.text)\n",
      "  File \"/usr/lib/python3.5/json/__init__.py\", line 319, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/usr/lib/python3.5/json/decoder.py\", line 339, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/usr/lib/python3.5/json/decoder.py\", line 357, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "INFO:root:Retrying... (Attempts left: 10)\n",
      "INFO:root:Got 80 tweets for stellar%20since%3A2017-04-22%20until%3A2017-04-23.\n",
      "INFO:root:Got 80 tweets (80 new).\n",
      "INFO:root:Got 67 tweets for stellar%20since%3A2017-04-23%20until%3A2017-04-24.\n",
      "INFO:root:Got 147 tweets (67 new).\n",
      "INFO:root:Got 79 tweets for stellar%20since%3A2017-04-21%20until%3A2017-04-22.\n",
      "INFO:root:Got 226 tweets (79 new).\n",
      "INFO:root:Got 80 tweets for stellar%20since%3A2017-04-20%20until%3A2017-04-21.\n",
      "INFO:root:Got 306 tweets (80 new).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-11 to 2017-05-15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Querying stellar since:2017-05-12 until:2017-05-13\n",
      "INFO:root:Querying stellar since:2017-05-13 until:2017-05-14\n",
      "INFO:root:Querying stellar since:2017-05-11 until:2017-05-12\n",
      "INFO:root:Querying stellar since:2017-05-14 until:2017-05-15\n",
      "INFO:root:Got 80 tweets for stellar%20since%3A2017-05-13%20until%3A2017-05-14.\n",
      "INFO:root:Got 80 tweets (80 new).\n",
      "INFO:root:Got 79 tweets for stellar%20since%3A2017-05-14%20until%3A2017-05-15.\n",
      "INFO:root:Got 159 tweets (79 new).\n",
      "INFO:root:Got 89 tweets for stellar%20since%3A2017-05-11%20until%3A2017-05-12.\n",
      "INFO:root:Got 248 tweets (89 new).\n",
      "INFO:root:Got 91 tweets for stellar%20since%3A2017-05-12%20until%3A2017-05-13.\n",
      "INFO:root:Got 339 tweets (91 new).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-06-22 to 2017-06-26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Querying stellar since:2017-06-24 until:2017-06-25\n",
      "INFO:root:Querying stellar since:2017-06-23 until:2017-06-24\n",
      "INFO:root:Querying stellar since:2017-06-22 until:2017-06-23\n",
      "INFO:root:Querying stellar since:2017-06-25 until:2017-06-26\n",
      "INFO:root:Got 74 tweets for stellar%20since%3A2017-06-23%20until%3A2017-06-24.\n",
      "INFO:root:Got 74 tweets (74 new).\n",
      "INFO:root:Got 79 tweets for stellar%20since%3A2017-06-25%20until%3A2017-06-26.\n",
      "INFO:root:Got 153 tweets (79 new).\n",
      "INFO:root:Got 84 tweets for stellar%20since%3A2017-06-22%20until%3A2017-06-23.\n",
      "INFO:root:Got 237 tweets (84 new).\n",
      "INFO:root:Got 82 tweets for stellar%20since%3A2017-06-24%20until%3A2017-06-25.\n",
      "INFO:root:Got 319 tweets (82 new).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-08-04 to 2017-08-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Querying stellar since:2017-08-05 until:2017-08-06\n",
      "INFO:root:Querying stellar since:2017-08-04 until:2017-08-05\n",
      "INFO:root:Querying stellar since:2017-08-06 until:2017-08-07\n",
      "INFO:root:Querying stellar since:2017-08-07 until:2017-08-08\n",
      "INFO:root:Got 79 tweets for stellar%20since%3A2017-08-04%20until%3A2017-08-05.\n",
      "INFO:root:Got 79 tweets (79 new).\n",
      "INFO:root:Got 72 tweets for stellar%20since%3A2017-08-07%20until%3A2017-08-08.\n",
      "INFO:root:Got 151 tweets (72 new).\n",
      "INFO:root:Got 69 tweets for stellar%20since%3A2017-08-05%20until%3A2017-08-06.\n",
      "INFO:root:Got 220 tweets (69 new).\n",
      "INFO:root:Got 80 tweets for stellar%20since%3A2017-08-06%20until%3A2017-08-07.\n",
      "INFO:root:Got 300 tweets (80 new).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-11-16 to 2017-11-20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Querying stellar since:2017-11-17 until:2017-11-18\n",
      "INFO:root:Querying stellar since:2017-11-16 until:2017-11-17\n",
      "INFO:root:Querying stellar since:2017-11-18 until:2017-11-19\n",
      "INFO:root:Querying stellar since:2017-11-19 until:2017-11-20\n",
      "INFO:root:Got 75 tweets for stellar%20since%3A2017-11-19%20until%3A2017-11-20.\n",
      "INFO:root:Got 75 tweets (75 new).\n",
      "INFO:root:Got 80 tweets for stellar%20since%3A2017-11-16%20until%3A2017-11-17.\n",
      "INFO:root:Got 155 tweets (80 new).\n",
      "INFO:root:Got 80 tweets for stellar%20since%3A2017-11-18%20until%3A2017-11-19.\n",
      "INFO:root:Got 235 tweets (80 new).\n",
      "INFO:root:Got 83 tweets for stellar%20since%3A2017-11-17%20until%3A2017-11-18.\n",
      "INFO:root:Got 318 tweets (83 new).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04 to 2018-05-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Querying stellar since:2018-05-07 until:2018-05-08\n",
      "INFO:root:Querying stellar since:2018-05-04 until:2018-05-05\n",
      "INFO:root:Querying stellar since:2018-05-05 until:2018-05-06\n",
      "INFO:root:Querying stellar since:2018-05-06 until:2018-05-07\n",
      "INFO:root:Got 84 tweets for stellar%20since%3A2018-05-04%20until%3A2018-05-05.\n",
      "INFO:root:Got 84 tweets (84 new).\n",
      "INFO:root:Got 100 tweets for stellar%20since%3A2018-05-07%20until%3A2018-05-08.\n",
      "INFO:root:Got 184 tweets (100 new).\n",
      "INFO:root:Got 108 tweets for stellar%20since%3A2018-05-06%20until%3A2018-05-07.\n",
      "INFO:root:Got 292 tweets (108 new).\n",
      "INFO:root:Got 102 tweets for stellar%20since%3A2018-05-05%20until%3A2018-05-06.\n",
      "INFO:root:Got 394 tweets (102 new).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-10 to 2018-05-14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Querying stellar since:2018-05-10 until:2018-05-11\n",
      "INFO:root:Querying stellar since:2018-05-12 until:2018-05-13\n",
      "INFO:root:Querying stellar since:2018-05-11 until:2018-05-12\n",
      "INFO:root:Querying stellar since:2018-05-13 until:2018-05-14\n",
      "INFO:root:Got 78 tweets for stellar%20since%3A2018-05-13%20until%3A2018-05-14.\n",
      "INFO:root:Got 78 tweets (78 new).\n",
      "INFO:root:Got 92 tweets for stellar%20since%3A2018-05-12%20until%3A2018-05-13.\n",
      "INFO:root:Got 170 tweets (92 new).\n",
      "INFO:root:Got 100 tweets for stellar%20since%3A2018-05-11%20until%3A2018-05-12.\n",
      "INFO:root:Got 270 tweets (100 new).\n",
      "INFO:root:Got 112 tweets for stellar%20since%3A2018-05-10%20until%3A2018-05-11.\n",
      "INFO:root:Got 382 tweets (112 new).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "litecoin\n",
      "2015-01-03 to 2015-01-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Querying litecoin since:2015-01-06 until:2015-01-07\n",
      "INFO:root:Querying litecoin since:2015-01-04 until:2015-01-05\n",
      "INFO:root:Querying litecoin since:2015-01-03 until:2015-01-04\n",
      "INFO:root:Querying litecoin since:2015-01-05 until:2015-01-06\n",
      "ERROR:root:Failed to parse JSON \"Expecting value: line 1 column 1 (char 0)\" while requesting \"https://twitter.com/i/search/timeline?vertical=default&include_available_features=1&include_entities=1&reset_error_state=false&src=typd&max_position=TWEET-551318318129610755-551417292722950146&q=litecoin%20since%3A2015-01-03%20until%3A2015-01-04&l=\".\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/shresthanikesh23/jupyter/CryptoTraderRemote/CryptoTrader/data_utils/twitter_data/twitterscraper/query.py\", line 54, in query_single_page\n",
      "    json_resp = json.loads(response.text)\n",
      "  File \"/usr/lib/python3.5/json/__init__.py\", line 319, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/usr/lib/python3.5/json/decoder.py\", line 339, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/usr/lib/python3.5/json/decoder.py\", line 357, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "INFO:root:Retrying... (Attempts left: 10)\n",
      "ERROR:root:Failed to parse JSON \"Expecting value: line 1 column 1 (char 0)\" while requesting \"https://twitter.com/i/search/timeline?vertical=default&include_available_features=1&include_entities=1&reset_error_state=false&src=typd&max_position=TWEET-551987170932572161-552182305213923328&q=litecoin%20since%3A2015-01-05%20until%3A2015-01-06&l=\".\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/shresthanikesh23/jupyter/CryptoTraderRemote/CryptoTrader/data_utils/twitter_data/twitterscraper/query.py\", line 54, in query_single_page\n",
      "    json_resp = json.loads(response.text)\n",
      "  File \"/usr/lib/python3.5/json/__init__.py\", line 319, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/usr/lib/python3.5/json/decoder.py\", line 339, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/usr/lib/python3.5/json/decoder.py\", line 357, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "INFO:root:Retrying... (Attempts left: 10)\n",
      "INFO:root:Got 40 tweets for litecoin%20since%3A2015-01-06%20until%3A2015-01-07.\n",
      "INFO:root:Got 40 tweets (40 new).\n",
      "INFO:root:Got 46 tweets for litecoin%20since%3A2015-01-04%20until%3A2015-01-05.\n",
      "INFO:root:Got 86 tweets (46 new).\n",
      "INFO:root:Got 44 tweets for litecoin%20since%3A2015-01-05%20until%3A2015-01-06.\n",
      "INFO:root:Got 130 tweets (44 new).\n",
      "INFO:root:Got 56 tweets for litecoin%20since%3A2015-01-03%20until%3A2015-01-04.\n",
      "INFO:root:Got 186 tweets (56 new).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015-04-04 to 2015-04-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Querying litecoin since:2015-04-05 until:2015-04-06\n",
      "INFO:root:Querying litecoin since:2015-04-06 until:2015-04-07\n",
      "INFO:root:Querying litecoin since:2015-04-04 until:2015-04-05\n",
      "INFO:root:Querying litecoin since:2015-04-07 until:2015-04-08\n",
      "INFO:root:Got 22 tweets for litecoin%20since%3A2015-04-04%20until%3A2015-04-05.\n",
      "INFO:root:Got 22 tweets (22 new).\n",
      "INFO:root:Got 38 tweets for litecoin%20since%3A2015-04-05%20until%3A2015-04-06.\n",
      "INFO:root:Got 60 tweets (38 new).\n",
      "INFO:root:Got 27 tweets for litecoin%20since%3A2015-04-07%20until%3A2015-04-08.\n",
      "INFO:root:Got 87 tweets (27 new).\n",
      "INFO:root:Got 37 tweets for litecoin%20since%3A2015-04-06%20until%3A2015-04-07.\n",
      "INFO:root:Got 124 tweets (37 new).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015-06-25 to 2015-06-29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Querying litecoin since:2015-06-27 until:2015-06-28\n",
      "INFO:root:Querying litecoin since:2015-06-25 until:2015-06-26\n",
      "INFO:root:Querying litecoin since:2015-06-26 until:2015-06-27\n",
      "INFO:root:Querying litecoin since:2015-06-28 until:2015-06-29\n",
      "INFO:root:Got 27 tweets for litecoin%20since%3A2015-06-28%20until%3A2015-06-29.\n",
      "INFO:root:Got 27 tweets (27 new).\n",
      "INFO:root:Got 23 tweets for litecoin%20since%3A2015-06-26%20until%3A2015-06-27.\n",
      "INFO:root:Got 50 tweets (23 new).\n",
      "INFO:root:Got 17 tweets for litecoin%20since%3A2015-06-27%20until%3A2015-06-28.\n",
      "INFO:root:Got 67 tweets (17 new).\n",
      "INFO:root:Got 36 tweets for litecoin%20since%3A2015-06-25%20until%3A2015-06-26.\n",
      "INFO:root:Got 103 tweets (36 new).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015-09-24 to 2015-09-28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Querying litecoin since:2015-09-24 until:2015-09-25\n",
      "INFO:root:Querying litecoin since:2015-09-25 until:2015-09-26\n",
      "INFO:root:Querying litecoin since:2015-09-26 until:2015-09-27\n",
      "INFO:root:Querying litecoin since:2015-09-27 until:2015-09-28\n",
      "INFO:root:Got 35 tweets for litecoin%20since%3A2015-09-26%20until%3A2015-09-27.\n",
      "INFO:root:Got 35 tweets (35 new).\n",
      "INFO:root:Got 33 tweets for litecoin%20since%3A2015-09-27%20until%3A2015-09-28.\n",
      "INFO:root:Got 68 tweets (33 new).\n",
      "INFO:root:Got 28 tweets for litecoin%20since%3A2015-09-24%20until%3A2015-09-25.\n",
      "INFO:root:Got 96 tweets (28 new).\n",
      "INFO:root:Got 37 tweets for litecoin%20since%3A2015-09-25%20until%3A2015-09-26.\n",
      "INFO:root:Got 133 tweets (37 new).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015-12-30 to 2016-01-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Querying litecoin since:2015-12-31 until:2016-01-01\n",
      "INFO:root:Querying litecoin since:2015-12-30 until:2015-12-31\n",
      "INFO:root:Querying litecoin since:2016-01-01 until:2016-01-02\n",
      "INFO:root:Querying litecoin since:2016-01-02 until:2016-01-03\n",
      "INFO:root:Got 30 tweets for litecoin%20since%3A2015-12-31%20until%3A2016-01-01.\n",
      "INFO:root:Got 30 tweets (30 new).\n",
      "INFO:root:Got 29 tweets for litecoin%20since%3A2016-01-02%20until%3A2016-01-03.\n",
      "INFO:root:Got 59 tweets (29 new).\n",
      "INFO:root:Got 40 tweets for litecoin%20since%3A2016-01-01%20until%3A2016-01-02.\n",
      "INFO:root:Got 99 tweets (40 new).\n",
      "INFO:root:Got 37 tweets for litecoin%20since%3A2015-12-30%20until%3A2015-12-31.\n",
      "INFO:root:Got 136 tweets (37 new).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-07-30 to 2016-08-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Querying litecoin since:2016-08-01 until:2016-08-02\n",
      "INFO:root:Querying litecoin since:2016-07-31 until:2016-08-01\n",
      "INFO:root:Querying litecoin since:2016-07-30 until:2016-07-31\n",
      "INFO:root:Querying litecoin since:2016-08-02 until:2016-08-03\n",
      "INFO:root:Got 21 tweets for litecoin%20since%3A2016-08-01%20until%3A2016-08-02.\n",
      "INFO:root:Got 21 tweets (21 new).\n",
      "INFO:root:Got 28 tweets for litecoin%20since%3A2016-08-02%20until%3A2016-08-03.\n",
      "INFO:root:Got 49 tweets (28 new).\n",
      "INFO:root:Got 34 tweets for litecoin%20since%3A2016-07-31%20until%3A2016-08-01.\n",
      "INFO:root:Got 83 tweets (34 new).\n",
      "INFO:root:Got 35 tweets for litecoin%20since%3A2016-07-30%20until%3A2016-07-31.\n",
      "INFO:root:Got 118 tweets (35 new).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-08-30 to 2016-09-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Querying litecoin since:2016-08-30 until:2016-08-31\n",
      "INFO:root:Querying litecoin since:2016-09-02 until:2016-09-03\n",
      "INFO:root:Querying litecoin since:2016-08-31 until:2016-09-01\n",
      "INFO:root:Querying litecoin since:2016-09-01 until:2016-09-02\n",
      "INFO:root:Got 35 tweets for litecoin%20since%3A2016-09-01%20until%3A2016-09-02.\n",
      "INFO:root:Got 35 tweets (35 new).\n",
      "INFO:root:Got 36 tweets for litecoin%20since%3A2016-08-30%20until%3A2016-08-31.\n",
      "INFO:root:Got 71 tweets (36 new).\n",
      "INFO:root:Got 40 tweets for litecoin%20since%3A2016-08-31%20until%3A2016-09-01.\n",
      "INFO:root:Got 111 tweets (40 new).\n",
      "INFO:root:Got 36 tweets for litecoin%20since%3A2016-09-02%20until%3A2016-09-03.\n",
      "INFO:root:Got 147 tweets (36 new).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-01-21 to 2017-01-25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Querying litecoin since:2017-01-23 until:2017-01-24\n",
      "INFO:root:Querying litecoin since:2017-01-21 until:2017-01-22\n",
      "INFO:root:Querying litecoin since:2017-01-24 until:2017-01-25\n",
      "INFO:root:Querying litecoin since:2017-01-22 until:2017-01-23\n",
      "INFO:root:Got 23 tweets for litecoin%20since%3A2017-01-24%20until%3A2017-01-25.\n",
      "INFO:root:Got 23 tweets (23 new).\n",
      "INFO:root:Got 21 tweets for litecoin%20since%3A2017-01-22%20until%3A2017-01-23.\n",
      "INFO:root:Got 44 tweets (21 new).\n",
      "INFO:root:Got 34 tweets for litecoin%20since%3A2017-01-23%20until%3A2017-01-24.\n",
      "INFO:root:Got 78 tweets (34 new).\n",
      "INFO:root:Got 37 tweets for litecoin%20since%3A2017-01-21%20until%3A2017-01-22.\n",
      "INFO:root:Got 115 tweets (37 new).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-09-26 to 2017-09-30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Querying litecoin since:2017-09-26 until:2017-09-27\n",
      "INFO:root:Querying litecoin since:2017-09-27 until:2017-09-28\n",
      "INFO:root:Querying litecoin since:2017-09-29 until:2017-09-30\n",
      "INFO:root:Querying litecoin since:2017-09-28 until:2017-09-29\n",
      "INFO:root:Got 46 tweets for litecoin%20since%3A2017-09-28%20until%3A2017-09-29.\n",
      "INFO:root:Got 46 tweets (46 new).\n",
      "INFO:root:Got 55 tweets for litecoin%20since%3A2017-09-29%20until%3A2017-09-30.\n",
      "INFO:root:Got 101 tweets (55 new).\n",
      "INFO:root:Got 70 tweets for litecoin%20since%3A2017-09-27%20until%3A2017-09-28.\n",
      "INFO:root:Got 171 tweets (70 new).\n",
      "INFO:root:Got 73 tweets for litecoin%20since%3A2017-09-26%20until%3A2017-09-27.\n",
      "INFO:root:Got 244 tweets (73 new).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ethereum\n",
      "2015-11-10 to 2015-11-14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shresthanikesh23/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2909: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n",
      "INFO:root:Querying ethereum since:2015-11-11 until:2015-11-12\n",
      "INFO:root:Querying ethereum since:2015-11-12 until:2015-11-13\n",
      "INFO:root:Querying ethereum since:2015-11-13 until:2015-11-14\n",
      "INFO:root:Querying ethereum since:2015-11-10 until:2015-11-11\n",
      "INFO:root:Got 41 tweets for ethereum%20since%3A2015-11-10%20until%3A2015-11-11.\n",
      "INFO:root:Got 41 tweets (41 new).\n",
      "INFO:root:Got 56 tweets for ethereum%20since%3A2015-11-11%20until%3A2015-11-12.\n",
      "INFO:root:Got 97 tweets (56 new).\n",
      "INFO:root:Got 58 tweets for ethereum%20since%3A2015-11-13%20until%3A2015-11-14.\n",
      "INFO:root:Got 155 tweets (58 new).\n",
      "INFO:root:Got 49 tweets for ethereum%20since%3A2015-11-12%20until%3A2015-11-13.\n",
      "INFO:root:Got 204 tweets (49 new).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015-12-22 to 2015-12-26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Querying ethereum since:2015-12-23 until:2015-12-24\n",
      "INFO:root:Querying ethereum since:2015-12-24 until:2015-12-25\n",
      "INFO:root:Querying ethereum since:2015-12-22 until:2015-12-23\n",
      "INFO:root:Querying ethereum since:2015-12-25 until:2015-12-26\n",
      "INFO:root:Got 0 tweets for ethereum%20since%3A2015-12-25%20until%3A2015-12-26.\n",
      "INFO:root:Got 0 tweets (0 new).\n",
      "INFO:root:Got 22 tweets (22 new).\n",
      "INFO:root:Got 22 tweets for ethereum%20since%3A2015-12-24%20until%3A2015-12-25.\n",
      "INFO:root:Got 22 tweets for ethereum%20since%3A2015-12-22%20until%3A2015-12-23.\n",
      "INFO:root:Got 44 tweets (22 new).\n",
      "INFO:root:Got 37 tweets for ethereum%20since%3A2015-12-23%20until%3A2015-12-24.\n",
      "INFO:root:Got 81 tweets (37 new).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-04-06 to 2016-04-10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Querying ethereum since:2016-04-08 until:2016-04-09\n",
      "INFO:root:Querying ethereum since:2016-04-06 until:2016-04-07\n",
      "INFO:root:Querying ethereum since:2016-04-07 until:2016-04-08\n",
      "INFO:root:Querying ethereum since:2016-04-09 until:2016-04-10\n",
      "INFO:root:Got 43 tweets for ethereum%20since%3A2016-04-06%20until%3A2016-04-07.\n",
      "INFO:root:Got 43 tweets (43 new).\n",
      "INFO:root:Got 60 tweets for ethereum%20since%3A2016-04-07%20until%3A2016-04-08.\n",
      "INFO:root:Got 103 tweets (60 new).\n",
      "INFO:root:Got 54 tweets for ethereum%20since%3A2016-04-08%20until%3A2016-04-09.\n",
      "INFO:root:Got 157 tweets (54 new).\n",
      "INFO:root:Got 59 tweets for ethereum%20since%3A2016-04-09%20until%3A2016-04-10.\n",
      "INFO:root:Got 216 tweets (59 new).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-04-14 to 2016-04-18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Querying ethereum since:2016-04-17 until:2016-04-18\n",
      "INFO:root:Querying ethereum since:2016-04-15 until:2016-04-16\n",
      "INFO:root:Querying ethereum since:2016-04-16 until:2016-04-17\n",
      "INFO:root:Querying ethereum since:2016-04-14 until:2016-04-15\n",
      "INFO:root:Got 32 tweets for ethereum%20since%3A2016-04-17%20until%3A2016-04-18.\n",
      "INFO:root:Got 32 tweets (32 new).\n",
      "INFO:root:Got 42 tweets for ethereum%20since%3A2016-04-16%20until%3A2016-04-17.\n",
      "INFO:root:Got 74 tweets (42 new).\n",
      "INFO:root:Got 47 tweets for ethereum%20since%3A2016-04-14%20until%3A2016-04-15.\n",
      "INFO:root:Got 121 tweets (47 new).\n",
      "INFO:root:Got 49 tweets for ethereum%20since%3A2016-04-15%20until%3A2016-04-16.\n",
      "INFO:root:Got 170 tweets (49 new).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-10-23 to 2016-10-27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Querying ethereum since:2016-10-23 until:2016-10-24\n",
      "INFO:root:Querying ethereum since:2016-10-24 until:2016-10-25\n",
      "INFO:root:Querying ethereum since:2016-10-26 until:2016-10-27\n",
      "INFO:root:Querying ethereum since:2016-10-25 until:2016-10-26\n",
      "ERROR:root:Failed to parse JSON \"Expecting value: line 1 column 1 (char 0)\" while requesting \"https://twitter.com/i/search/timeline?vertical=default&include_available_features=1&include_entities=1&reset_error_state=false&src=typd&max_position=TWEET-791066830223794177-791374883460681728-BD1UO2FFu9QAAAAAAAAVfAAAAAcAAABWAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA==-T-0-1&q=ethereum%20since%3A2016-10-26%20until%3A2016-10-27&l=\".\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/shresthanikesh23/jupyter/CryptoTraderRemote/CryptoTrader/data_utils/twitter_data/twitterscraper/query.py\", line 54, in query_single_page\n",
      "    json_resp = json.loads(response.text)\n",
      "  File \"/usr/lib/python3.5/json/__init__.py\", line 319, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/usr/lib/python3.5/json/decoder.py\", line 339, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/usr/lib/python3.5/json/decoder.py\", line 357, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "INFO:root:Retrying... (Attempts left: 10)\n",
      "INFO:root:Got 42 tweets for ethereum%20since%3A2016-10-26%20until%3A2016-10-27.\n",
      "INFO:root:Got 42 tweets (42 new).\n",
      "INFO:root:Got 41 tweets for ethereum%20since%3A2016-10-24%20until%3A2016-10-25.\n",
      "INFO:root:Got 83 tweets (41 new).\n",
      "INFO:root:Got 52 tweets for ethereum%20since%3A2016-10-25%20until%3A2016-10-26.\n",
      "INFO:root:Got 135 tweets (52 new).\n",
      "INFO:root:Got 54 tweets for ethereum%20since%3A2016-10-23%20until%3A2016-10-24.\n",
      "INFO:root:Got 189 tweets (54 new).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-11-15 to 2016-11-19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Querying ethereum since:2016-11-17 until:2016-11-18\n",
      "INFO:root:Querying ethereum since:2016-11-15 until:2016-11-16\n",
      "INFO:root:Querying ethereum since:2016-11-16 until:2016-11-17\n",
      "INFO:root:Querying ethereum since:2016-11-18 until:2016-11-19\n",
      "INFO:root:Got 57 tweets for ethereum%20since%3A2016-11-15%20until%3A2016-11-16.\n",
      "INFO:root:Got 57 tweets (57 new).\n",
      "INFO:root:Got 45 tweets for ethereum%20since%3A2016-11-16%20until%3A2016-11-17.\n",
      "INFO:root:Got 102 tweets (45 new).\n",
      "INFO:root:Got 59 tweets for ethereum%20since%3A2016-11-17%20until%3A2016-11-18.\n",
      "INFO:root:Got 161 tweets (59 new).\n",
      "INFO:root:Got 58 tweets for ethereum%20since%3A2016-11-18%20until%3A2016-11-19.\n",
      "INFO:root:Got 219 tweets (58 new).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-04-01 to 2017-04-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Querying ethereum since:2017-04-03 until:2017-04-04\n",
      "INFO:root:Querying ethereum since:2017-04-02 until:2017-04-03\n",
      "INFO:root:Querying ethereum since:2017-04-01 until:2017-04-02\n",
      "INFO:root:Querying ethereum since:2017-04-04 until:2017-04-05\n",
      "INFO:root:Got 55 tweets for ethereum%20since%3A2017-04-02%20until%3A2017-04-03.\n",
      "INFO:root:Got 55 tweets (55 new).\n",
      "INFO:root:Got 57 tweets for ethereum%20since%3A2017-04-03%20until%3A2017-04-04.\n",
      "INFO:root:Got 112 tweets (57 new).\n",
      "INFO:root:Got 60 tweets for ethereum%20since%3A2017-04-01%20until%3A2017-04-02.\n",
      "INFO:root:Got 172 tweets (60 new).\n",
      "INFO:root:Got 62 tweets for ethereum%20since%3A2017-04-04%20until%3A2017-04-05.\n",
      "INFO:root:Got 234 tweets (62 new).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-02-17 to 2018-02-21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Querying ethereum since:2018-02-19 until:2018-02-20\n",
      "INFO:root:Querying ethereum since:2018-02-18 until:2018-02-19\n",
      "INFO:root:Querying ethereum since:2018-02-17 until:2018-02-18\n",
      "INFO:root:Querying ethereum since:2018-02-20 until:2018-02-21\n",
      "INFO:root:Got 224 tweets for ethereum%20since%3A2018-02-18%20until%3A2018-02-19.\n",
      "INFO:root:Got 224 tweets (224 new).\n",
      "INFO:root:Got 271 tweets for ethereum%20since%3A2018-02-17%20until%3A2018-02-18.\n",
      "INFO:root:Got 495 tweets (271 new).\n",
      "INFO:root:Got 305 tweets for ethereum%20since%3A2018-02-20%20until%3A2018-02-21.\n",
      "INFO:root:Got 800 tweets (305 new).\n",
      "INFO:root:Got 311 tweets for ethereum%20since%3A2018-02-19%20until%3A2018-02-20.\n",
      "INFO:root:Got 1111 tweets (311 new).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04 to 2018-05-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Querying ethereum since:2018-05-05 until:2018-05-06\n",
      "INFO:root:Querying ethereum since:2018-05-04 until:2018-05-05\n",
      "INFO:root:Querying ethereum since:2018-05-07 until:2018-05-08\n",
      "INFO:root:Querying ethereum since:2018-05-06 until:2018-05-07\n",
      "INFO:root:Got 0 tweets for ethereum%20since%3A2018-05-06%20until%3A2018-05-07.\n",
      "INFO:root:Got 0 tweets (0 new).\n",
      "INFO:root:Got 284 tweets for ethereum%20since%3A2018-05-05%20until%3A2018-05-06.\n",
      "INFO:root:Got 284 tweets (284 new).\n",
      "INFO:root:Got 329 tweets for ethereum%20since%3A2018-05-04%20until%3A2018-05-05.\n",
      "INFO:root:Got 613 tweets (329 new).\n",
      "INFO:root:Got 329 tweets for ethereum%20since%3A2018-05-07%20until%3A2018-05-08.\n",
      "INFO:root:Got 942 tweets (329 new).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dash\n",
      "2015-09-02 to 2015-09-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Querying dash since:2015-09-03 until:2015-09-04\n",
      "INFO:root:Querying dash since:2015-09-02 until:2015-09-03\n",
      "INFO:root:Querying dash since:2015-09-05 until:2015-09-06\n",
      "INFO:root:Querying dash since:2015-09-04 until:2015-09-05\n",
      "ERROR:root:Failed to parse JSON \"Expecting value: line 1 column 1 (char 0)\" while requesting \"https://twitter.com/i/search/timeline?vertical=default&include_available_features=1&include_entities=1&reset_error_state=false&src=typd&max_position=TWEET-639634101989953536-639935238647492608-BD1UO2FFu9QAAAAAAAAVfAAAAAcAAABWAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA==-T-0-5&q=dash%20since%3A2015-09-04%20until%3A2015-09-05&l=\".\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/shresthanikesh23/jupyter/CryptoTraderRemote/CryptoTrader/data_utils/twitter_data/twitterscraper/query.py\", line 54, in query_single_page\n",
      "    json_resp = json.loads(response.text)\n",
      "  File \"/usr/lib/python3.5/json/__init__.py\", line 319, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/usr/lib/python3.5/json/decoder.py\", line 339, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/usr/lib/python3.5/json/decoder.py\", line 357, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "INFO:root:Retrying... (Attempts left: 10)\n",
      "ERROR:root:Failed to parse JSON \"Expecting value: line 1 column 1 (char 0)\" while requesting \"https://twitter.com/i/search/timeline?vertical=default&include_available_features=1&include_entities=1&reset_error_state=false&src=typd&max_position=TWEET-639634101989953536-639935238647492608-BD1UO2FFu9QAAAAAAAAVfAAAAAcAAABWAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA==-T-0-5&q=dash%20since%3A2015-09-04%20until%3A2015-09-05&l=\".\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/shresthanikesh23/jupyter/CryptoTraderRemote/CryptoTrader/data_utils/twitter_data/twitterscraper/query.py\", line 54, in query_single_page\n",
      "    json_resp = json.loads(response.text)\n",
      "  File \"/usr/lib/python3.5/json/__init__.py\", line 319, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/usr/lib/python3.5/json/decoder.py\", line 339, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/usr/lib/python3.5/json/decoder.py\", line 357, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "INFO:root:Retrying... (Attempts left: 9)\n",
      "INFO:root:Got 176 tweets for dash%20since%3A2015-09-05%20until%3A2015-09-06.\n",
      "INFO:root:Got 176 tweets (176 new).\n",
      "INFO:root:Got 207 tweets for dash%20since%3A2015-09-03%20until%3A2015-09-04.\n",
      "INFO:root:Got 383 tweets (207 new).\n",
      "INFO:root:Got 198 tweets for dash%20since%3A2015-09-04%20until%3A2015-09-05.\n",
      "INFO:root:Got 581 tweets (198 new).\n",
      "INFO:root:Got 258 tweets for dash%20since%3A2015-09-02%20until%3A2015-09-03.\n",
      "INFO:root:Got 839 tweets (258 new).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-01-04 to 2016-01-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Querying dash since:2016-01-04 until:2016-01-05\n",
      "INFO:root:Querying dash since:2016-01-07 until:2016-01-08\n",
      "INFO:root:Querying dash since:2016-01-06 until:2016-01-07\n",
      "INFO:root:Querying dash since:2016-01-05 until:2016-01-06\n",
      "INFO:root:Got 160 tweets for dash%20since%3A2016-01-07%20until%3A2016-01-08.\n",
      "INFO:root:Got 160 tweets (160 new).\n",
      "INFO:root:Got 195 tweets for dash%20since%3A2016-01-06%20until%3A2016-01-07.\n",
      "INFO:root:Got 355 tweets (195 new).\n",
      "INFO:root:Got 191 tweets for dash%20since%3A2016-01-05%20until%3A2016-01-06.\n",
      "INFO:root:Got 546 tweets (191 new).\n",
      "INFO:root:Got 203 tweets for dash%20since%3A2016-01-04%20until%3A2016-01-05.\n",
      "INFO:root:Got 749 tweets (203 new).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-07-24 to 2016-07-28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Querying dash since:2016-07-25 until:2016-07-26\n",
      "INFO:root:Querying dash since:2016-07-26 until:2016-07-27\n",
      "INFO:root:Querying dash since:2016-07-24 until:2016-07-25\n",
      "INFO:root:Querying dash since:2016-07-27 until:2016-07-28\n",
      "ERROR:root:Failed to parse JSON \"Expecting value: line 1 column 1 (char 0)\" while requesting \"https://twitter.com/i/search/timeline?vertical=default&include_available_features=1&include_entities=1&reset_error_state=false&src=typd&max_position=TWEET-757334232352100355-757343244464160773&q=dash%20since%3A2016-07-24%20until%3A2016-07-25&l=\".\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/shresthanikesh23/jupyter/CryptoTraderRemote/CryptoTrader/data_utils/twitter_data/twitterscraper/query.py\", line 54, in query_single_page\n",
      "    json_resp = json.loads(response.text)\n",
      "  File \"/usr/lib/python3.5/json/__init__.py\", line 319, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/usr/lib/python3.5/json/decoder.py\", line 339, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/usr/lib/python3.5/json/decoder.py\", line 357, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "INFO:root:Retrying... (Attempts left: 10)\n",
      "INFO:root:Got 142 tweets for dash%20since%3A2016-07-27%20until%3A2016-07-28.\n",
      "INFO:root:Got 142 tweets (142 new).\n",
      "ERROR:root:Failed to parse JSON \"Expecting value: line 1 column 1 (char 0)\" while requesting \"https://twitter.com/i/search/timeline?vertical=default&include_available_features=1&include_entities=1&reset_error_state=false&src=typd&max_position=TWEET-757364857620619264-757710306650890241-BD1UO2FFu9QAAAAAAAAVfAAAAAcAAABWAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA==-T-0-5&q=dash%20since%3A2016-07-25%20until%3A2016-07-26&l=\".\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/shresthanikesh23/jupyter/CryptoTraderRemote/CryptoTrader/data_utils/twitter_data/twitterscraper/query.py\", line 54, in query_single_page\n",
      "    json_resp = json.loads(response.text)\n",
      "  File \"/usr/lib/python3.5/json/__init__.py\", line 319, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/usr/lib/python3.5/json/decoder.py\", line 339, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/usr/lib/python3.5/json/decoder.py\", line 357, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "INFO:root:Retrying... (Attempts left: 10)\n",
      "INFO:root:Got 142 tweets for dash%20since%3A2016-07-25%20until%3A2016-07-26.\n",
      "INFO:root:Got 284 tweets (142 new).\n",
      "INFO:root:Got 159 tweets for dash%20since%3A2016-07-26%20until%3A2016-07-27.\n",
      "INFO:root:Got 443 tweets (159 new).\n",
      "INFO:root:Got 210 tweets for dash%20since%3A2016-07-24%20until%3A2016-07-25.\n",
      "INFO:root:Got 653 tweets (210 new).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-11-30 to 2016-12-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Querying dash since:2016-12-02 until:2016-12-03\n",
      "INFO:root:Querying dash since:2016-11-30 until:2016-12-01\n",
      "INFO:root:Querying dash since:2016-12-01 until:2016-12-02\n",
      "INFO:root:Querying dash since:2016-12-03 until:2016-12-04\n",
      "ERROR:root:Failed to parse JSON \"Expecting value: line 1 column 1 (char 0)\" while requesting \"https://twitter.com/i/search/timeline?vertical=default&include_available_features=1&include_entities=1&reset_error_state=false&src=typd&max_position=TWEET-805030184818774017-805180886253584384-BD1UO2FFu9QAAAAAAAAVfAAAAAcAAABWAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA==-T-0-2&q=dash%20since%3A2016-12-03%20until%3A2016-12-04&l=\".\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/shresthanikesh23/jupyter/CryptoTraderRemote/CryptoTrader/data_utils/twitter_data/twitterscraper/query.py\", line 54, in query_single_page\n",
      "    json_resp = json.loads(response.text)\n",
      "  File \"/usr/lib/python3.5/json/__init__.py\", line 319, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/usr/lib/python3.5/json/decoder.py\", line 339, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/usr/lib/python3.5/json/decoder.py\", line 357, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "INFO:root:Retrying... (Attempts left: 10)\n",
      "INFO:root:Got 160 tweets for dash%20since%3A2016-11-30%20until%3A2016-12-01.\n",
      "INFO:root:Got 160 tweets (160 new).\n",
      "INFO:root:Got 179 tweets for dash%20since%3A2016-12-02%20until%3A2016-12-03.\n",
      "INFO:root:Got 339 tweets (179 new).\n",
      "INFO:root:Got 160 tweets for dash%20since%3A2016-12-03%20until%3A2016-12-04.\n",
      "INFO:root:Got 499 tweets (160 new).\n",
      "INFO:root:Got 180 tweets for dash%20since%3A2016-12-01%20until%3A2016-12-02.\n",
      "INFO:root:Got 679 tweets (180 new).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-03-09 to 2017-03-13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Querying dash since:2017-03-10 until:2017-03-11\n",
      "INFO:root:Querying dash since:2017-03-12 until:2017-03-13\n",
      "INFO:root:Querying dash since:2017-03-11 until:2017-03-12\n",
      "INFO:root:Querying dash since:2017-03-09 until:2017-03-10\n",
      "INFO:root:Got 159 tweets for dash%20since%3A2017-03-10%20until%3A2017-03-11.\n",
      "INFO:root:Got 159 tweets (159 new).\n",
      "INFO:root:Got 168 tweets for dash%20since%3A2017-03-09%20until%3A2017-03-10.\n",
      "INFO:root:Got 327 tweets (168 new).\n",
      "INFO:root:Got 198 tweets for dash%20since%3A2017-03-11%20until%3A2017-03-12.\n",
      "INFO:root:Got 525 tweets (198 new).\n",
      "INFO:root:Got 254 tweets for dash%20since%3A2017-03-12%20until%3A2017-03-13.\n",
      "INFO:root:Got 779 tweets (254 new).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-06-21 to 2017-06-25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Querying dash since:2017-06-21 until:2017-06-22\n",
      "INFO:root:Querying dash since:2017-06-23 until:2017-06-24\n",
      "INFO:root:Querying dash since:2017-06-24 until:2017-06-25\n",
      "INFO:root:Querying dash since:2017-06-22 until:2017-06-23\n",
      "INFO:root:Got 165 tweets for dash%20since%3A2017-06-24%20until%3A2017-06-25.\n",
      "INFO:root:Got 165 tweets (165 new).\n",
      "INFO:root:Got 163 tweets for dash%20since%3A2017-06-22%20until%3A2017-06-23.\n",
      "INFO:root:Got 328 tweets (163 new).\n",
      "INFO:root:Got 154 tweets for dash%20since%3A2017-06-23%20until%3A2017-06-24.\n",
      "INFO:root:Got 482 tweets (154 new).\n",
      "INFO:root:Got 183 tweets for dash%20since%3A2017-06-21%20until%3A2017-06-22.\n",
      "INFO:root:Got 665 tweets (183 new).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-01 to 2018-05-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Querying dash since:2018-05-04 until:2018-05-05\n",
      "INFO:root:Querying dash since:2018-05-01 until:2018-05-02\n",
      "INFO:root:Querying dash since:2018-05-02 until:2018-05-03\n",
      "INFO:root:Querying dash since:2018-05-03 until:2018-05-04\n",
      "INFO:root:Got 196 tweets for dash%20since%3A2018-05-04%20until%3A2018-05-05.\n",
      "INFO:root:Got 196 tweets (196 new).\n",
      "INFO:root:Got 232 tweets for dash%20since%3A2018-05-03%20until%3A2018-05-04.\n",
      "INFO:root:Got 428 tweets (232 new).\n",
      "INFO:root:Got 218 tweets for dash%20since%3A2018-05-01%20until%3A2018-05-02.\n",
      "INFO:root:Got 646 tweets (218 new).\n",
      "INFO:root:Got 284 tweets for dash%20since%3A2018-05-02%20until%3A2018-05-03.\n",
      "INFO:root:Got 930 tweets (284 new).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-13 to 2018-05-17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Querying dash since:2018-05-14 until:2018-05-15\n",
      "INFO:root:Querying dash since:2018-05-16 until:2018-05-17\n",
      "INFO:root:Querying dash since:2018-05-15 until:2018-05-16\n",
      "INFO:root:Querying dash since:2018-05-13 until:2018-05-14\n",
      "INFO:root:Got 217 tweets for dash%20since%3A2018-05-16%20until%3A2018-05-17.\n",
      "INFO:root:Got 217 tweets (217 new).\n",
      "INFO:root:Got 240 tweets for dash%20since%3A2018-05-15%20until%3A2018-05-16.\n",
      "INFO:root:Got 457 tweets (240 new).\n",
      "INFO:root:Got 247 tweets for dash%20since%3A2018-05-14%20until%3A2018-05-15.\n",
      "INFO:root:Got 704 tweets (247 new).\n",
      "ERROR:root:Failed to parse JSON \"Expecting value: line 1 column 1 (char 0)\" while requesting \"https://twitter.com/i/search/timeline?vertical=default&include_available_features=1&include_entities=1&reset_error_state=false&src=typd&max_position=TWEET-995604234581303298-995802569158086656-BD1UO2FFu9QAAAAAAAAVfAAAAAcAAABWAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA==-T-0-35&q=dash%20since%3A2018-05-13%20until%3A2018-05-14&l=\".\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/shresthanikesh23/jupyter/CryptoTraderRemote/CryptoTrader/data_utils/twitter_data/twitterscraper/query.py\", line 54, in query_single_page\n",
      "    json_resp = json.loads(response.text)\n",
      "  File \"/usr/lib/python3.5/json/__init__.py\", line 319, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/usr/lib/python3.5/json/decoder.py\", line 339, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/usr/lib/python3.5/json/decoder.py\", line 357, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "INFO:root:Retrying... (Attempts left: 10)\n",
      "INFO:root:Got 819 tweets for dash%20since%3A2018-05-13%20until%3A2018-05-14.\n",
      "INFO:root:Got 1523 tweets (819 new).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bitcoin\n",
      "2014-12-18 to 2014-12-22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Querying bitcoin since:2014-12-18 until:2014-12-19\n",
      "INFO:root:Querying bitcoin since:2014-12-20 until:2014-12-21\n",
      "INFO:root:Querying bitcoin since:2014-12-19 until:2014-12-20\n",
      "INFO:root:Querying bitcoin since:2014-12-21 until:2014-12-22\n",
      "INFO:root:Got 144 tweets for bitcoin%20since%3A2014-12-20%20until%3A2014-12-21.\n",
      "INFO:root:Got 144 tweets (144 new).\n",
      "INFO:root:Got 150 tweets for bitcoin%20since%3A2014-12-21%20until%3A2014-12-22.\n",
      "INFO:root:Got 294 tweets (150 new).\n",
      "INFO:root:Got 176 tweets for bitcoin%20since%3A2014-12-19%20until%3A2014-12-20.\n",
      "INFO:root:Got 470 tweets (176 new).\n",
      "INFO:root:Got 177 tweets for bitcoin%20since%3A2014-12-18%20until%3A2014-12-19.\n",
      "INFO:root:Got 647 tweets (177 new).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015-07-02 to 2015-07-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Querying bitcoin since:2015-07-02 until:2015-07-03\n",
      "INFO:root:Querying bitcoin since:2015-07-05 until:2015-07-06\n",
      "INFO:root:Querying bitcoin since:2015-07-04 until:2015-07-05\n",
      "INFO:root:Querying bitcoin since:2015-07-03 until:2015-07-04\n",
      "INFO:root:Got 218 tweets for bitcoin%20since%3A2015-07-05%20until%3A2015-07-06.\n",
      "INFO:root:Got 218 tweets (218 new).\n",
      "INFO:root:Got 218 tweets for bitcoin%20since%3A2015-07-04%20until%3A2015-07-05.\n",
      "INFO:root:Got 436 tweets (218 new).\n",
      "INFO:root:Got 226 tweets for bitcoin%20since%3A2015-07-03%20until%3A2015-07-04.\n",
      "INFO:root:Got 662 tweets (226 new).\n",
      "INFO:root:Got 239 tweets for bitcoin%20since%3A2015-07-02%20until%3A2015-07-03.\n",
      "INFO:root:Got 901 tweets (239 new).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015-07-07 to 2015-07-11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Querying bitcoin since:2015-07-07 until:2015-07-08\n",
      "INFO:root:Querying bitcoin since:2015-07-10 until:2015-07-11\n",
      "INFO:root:Querying bitcoin since:2015-07-08 until:2015-07-09\n",
      "INFO:root:Querying bitcoin since:2015-07-09 until:2015-07-10\n",
      "INFO:root:Got 257 tweets for bitcoin%20since%3A2015-07-08%20until%3A2015-07-09.\n",
      "INFO:root:Got 257 tweets (257 new).\n",
      "INFO:root:Got 262 tweets for bitcoin%20since%3A2015-07-09%20until%3A2015-07-10.\n",
      "INFO:root:Got 519 tweets (262 new).\n",
      "INFO:root:Got 271 tweets for bitcoin%20since%3A2015-07-07%20until%3A2015-07-08.\n",
      "INFO:root:Got 790 tweets (271 new).\n",
      "INFO:root:Got 287 tweets for bitcoin%20since%3A2015-07-10%20until%3A2015-07-11.\n",
      "INFO:root:Got 1077 tweets (287 new).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-02-25 to 2016-02-29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Querying bitcoin since:2016-02-25 until:2016-02-26\n",
      "INFO:root:Querying bitcoin since:2016-02-26 until:2016-02-27\n",
      "INFO:root:Querying bitcoin since:2016-02-27 until:2016-02-28\n",
      "INFO:root:Querying bitcoin since:2016-02-28 until:2016-02-29\n",
      "INFO:root:Got 253 tweets for bitcoin%20since%3A2016-02-27%20until%3A2016-02-28.\n",
      "INFO:root:Got 253 tweets (253 new).\n",
      "INFO:root:Got 252 tweets for bitcoin%20since%3A2016-02-28%20until%3A2016-02-29.\n",
      "INFO:root:Got 505 tweets (252 new).\n",
      "INFO:root:Got 299 tweets for bitcoin%20since%3A2016-02-26%20until%3A2016-02-27.\n",
      "INFO:root:Got 804 tweets (299 new).\n",
      "INFO:root:Got 308 tweets for bitcoin%20since%3A2016-02-25%20until%3A2016-02-26.\n",
      "INFO:root:Got 1112 tweets (308 new).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-08-24 to 2016-08-28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Querying bitcoin since:2016-08-24 until:2016-08-25\n",
      "INFO:root:Querying bitcoin since:2016-08-25 until:2016-08-26\n",
      "INFO:root:Querying bitcoin since:2016-08-26 until:2016-08-27\n",
      "INFO:root:Querying bitcoin since:2016-08-27 until:2016-08-28\n",
      "INFO:root:Got 165 tweets for bitcoin%20since%3A2016-08-27%20until%3A2016-08-28.\n",
      "INFO:root:Got 165 tweets (165 new).\n",
      "INFO:root:Got 185 tweets for bitcoin%20since%3A2016-08-26%20until%3A2016-08-27.\n",
      "INFO:root:Got 350 tweets (185 new).\n",
      "INFO:root:Got 216 tweets for bitcoin%20since%3A2016-08-24%20until%3A2016-08-25.\n",
      "INFO:root:Got 566 tweets (216 new).\n",
      "INFO:root:Got 226 tweets for bitcoin%20since%3A2016-08-25%20until%3A2016-08-26.\n",
      "INFO:root:Got 792 tweets (226 new).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-02-01 to 2017-02-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Querying bitcoin since:2017-02-01 until:2017-02-02\n",
      "INFO:root:Querying bitcoin since:2017-02-03 until:2017-02-04\n",
      "INFO:root:Querying bitcoin since:2017-02-02 until:2017-02-03\n",
      "INFO:root:Querying bitcoin since:2017-02-04 until:2017-02-05\n",
      "ERROR:root:Failed to parse JSON \"Expecting value: line 1 column 1 (char 0)\" while requesting \"https://twitter.com/i/search/timeline?vertical=default&include_available_features=1&include_entities=1&reset_error_state=false&src=typd&max_position=TWEET-828013083117416448-828015121217814530&q=bitcoin%20since%3A2017-02-04%20until%3A2017-02-05&l=\".\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/shresthanikesh23/jupyter/CryptoTraderRemote/CryptoTrader/data_utils/twitter_data/twitterscraper/query.py\", line 54, in query_single_page\n",
      "    json_resp = json.loads(response.text)\n",
      "  File \"/usr/lib/python3.5/json/__init__.py\", line 319, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/usr/lib/python3.5/json/decoder.py\", line 339, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/usr/lib/python3.5/json/decoder.py\", line 357, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "INFO:root:Retrying... (Attempts left: 10)\n",
      "ERROR:root:Failed to parse JSON \"Expecting value: line 1 column 1 (char 0)\" while requesting \"https://twitter.com/i/search/timeline?vertical=default&include_available_features=1&include_entities=1&reset_error_state=false&src=typd&max_position=TWEET-827527928028209153-827646913159655425-BD1UO2FFu9QAAAAAAAAVfAAAAAcAAABWAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA==-T-0-3&q=bitcoin%20since%3A2017-02-03%20until%3A2017-02-04&l=\".\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/shresthanikesh23/jupyter/CryptoTraderRemote/CryptoTrader/data_utils/twitter_data/twitterscraper/query.py\", line 54, in query_single_page\n",
      "    json_resp = json.loads(response.text)\n",
      "  File \"/usr/lib/python3.5/json/__init__.py\", line 319, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/usr/lib/python3.5/json/decoder.py\", line 339, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/usr/lib/python3.5/json/decoder.py\", line 357, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "INFO:root:Retrying... (Attempts left: 10)\n",
      "INFO:root:Got 232 tweets for bitcoin%20since%3A2017-02-02%20until%3A2017-02-03.\n",
      "INFO:root:Got 232 tweets (232 new).\n",
      "INFO:root:Got 214 tweets for bitcoin%20since%3A2017-02-01%20until%3A2017-02-02.\n",
      "INFO:root:Got 446 tweets (214 new).\n",
      "INFO:root:Got 231 tweets for bitcoin%20since%3A2017-02-04%20until%3A2017-02-05.\n",
      "INFO:root:Got 677 tweets (231 new).\n",
      "INFO:root:Got 233 tweets for bitcoin%20since%3A2017-02-03%20until%3A2017-02-04.\n",
      "INFO:root:Got 910 tweets (233 new).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-04-02 to 2017-04-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Querying bitcoin since:2017-04-03 until:2017-04-04\n",
      "INFO:root:Querying bitcoin since:2017-04-04 until:2017-04-05\n",
      "INFO:root:Querying bitcoin since:2017-04-05 until:2017-04-06\n",
      "INFO:root:Querying bitcoin since:2017-04-02 until:2017-04-03\n",
      "INFO:root:Got 196 tweets for bitcoin%20since%3A2017-04-02%20until%3A2017-04-03.\n",
      "INFO:root:Got 196 tweets (196 new).\n",
      "INFO:root:Got 231 tweets for bitcoin%20since%3A2017-04-05%20until%3A2017-04-06.\n",
      "INFO:root:Got 427 tweets (231 new).\n",
      "INFO:root:Got 202 tweets for bitcoin%20since%3A2017-04-04%20until%3A2017-04-05.\n",
      "INFO:root:Got 629 tweets (202 new).\n",
      "INFO:root:Got 222 tweets for bitcoin%20since%3A2017-04-03%20until%3A2017-04-04.\n",
      "INFO:root:Got 851 tweets (222 new).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-06-23 to 2017-06-27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Querying bitcoin since:2017-06-24 until:2017-06-25\n",
      "INFO:root:Querying bitcoin since:2017-06-25 until:2017-06-26\n",
      "INFO:root:Querying bitcoin since:2017-06-23 until:2017-06-24\n",
      "INFO:root:Querying bitcoin since:2017-06-26 until:2017-06-27\n",
      "INFO:root:Got 261 tweets for bitcoin%20since%3A2017-06-24%20until%3A2017-06-25.\n",
      "INFO:root:Got 261 tweets (261 new).\n",
      "INFO:root:Got 255 tweets for bitcoin%20since%3A2017-06-25%20until%3A2017-06-26.\n",
      "INFO:root:Got 516 tweets (255 new).\n",
      "INFO:root:Got 316 tweets for bitcoin%20since%3A2017-06-23%20until%3A2017-06-24.\n",
      "INFO:root:Got 832 tweets (316 new).\n",
      "INFO:root:Got 343 tweets for bitcoin%20since%3A2017-06-26%20until%3A2017-06-27.\n",
      "INFO:root:Got 1175 tweets (343 new).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-06-24 to 2017-06-28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Querying bitcoin since:2017-06-24 until:2017-06-25\n",
      "INFO:root:Querying bitcoin since:2017-06-26 until:2017-06-27\n",
      "INFO:root:Querying bitcoin since:2017-06-27 until:2017-06-28\n",
      "INFO:root:Querying bitcoin since:2017-06-25 until:2017-06-26\n",
      "INFO:root:Got 0 tweets for bitcoin%20since%3A2017-06-25%20until%3A2017-06-26.\n",
      "INFO:root:Got 0 tweets (0 new).\n",
      "INFO:root:Got 261 tweets for bitcoin%20since%3A2017-06-24%20until%3A2017-06-25.\n",
      "INFO:root:Got 261 tweets (261 new).\n",
      "INFO:root:Got 343 tweets for bitcoin%20since%3A2017-06-26%20until%3A2017-06-27.\n",
      "INFO:root:Got 604 tweets (343 new).\n",
      "INFO:root:Got 352 tweets for bitcoin%20since%3A2017-06-27%20until%3A2017-06-28.\n",
      "INFO:root:Got 956 tweets (352 new).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-07-19 to 2017-07-23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Querying bitcoin since:2017-07-20 until:2017-07-21\n",
      "INFO:root:Querying bitcoin since:2017-07-19 until:2017-07-20\n",
      "INFO:root:Querying bitcoin since:2017-07-21 until:2017-07-22\n",
      "INFO:root:Querying bitcoin since:2017-07-22 until:2017-07-23\n",
      "ERROR:root:Failed to parse JSON \"Expecting value: line 1 column 1 (char 0)\" while requesting \"https://twitter.com/i/search/timeline?vertical=default&include_available_features=1&include_entities=1&reset_error_state=false&src=typd&max_position=TWEET-888399320982183936-888532542567071744-BD1UO2FFu9QAAAAAAAAVfAAAAAcAAABWAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA==-T-0-6&q=bitcoin%20since%3A2017-07-21%20until%3A2017-07-22&l=\".\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/shresthanikesh23/jupyter/CryptoTraderRemote/CryptoTrader/data_utils/twitter_data/twitterscraper/query.py\", line 54, in query_single_page\n",
      "    json_resp = json.loads(response.text)\n",
      "  File \"/usr/lib/python3.5/json/__init__.py\", line 319, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/usr/lib/python3.5/json/decoder.py\", line 339, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/usr/lib/python3.5/json/decoder.py\", line 357, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "INFO:root:Retrying... (Attempts left: 10)\n",
      "ERROR:root:Failed to parse JSON \"Expecting value: line 1 column 1 (char 0)\" while requesting \"https://twitter.com/i/search/timeline?vertical=default&include_available_features=1&include_entities=1&reset_error_state=false&src=typd&max_position=TWEET-888010066540068868-888180203670966273-BD1UO2FFu9QAAAAAAAAVfAAAAAcAAABWAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA==-T-0-9&q=bitcoin%20since%3A2017-07-20%20until%3A2017-07-21&l=\".\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/shresthanikesh23/jupyter/CryptoTraderRemote/CryptoTrader/data_utils/twitter_data/twitterscraper/query.py\", line 54, in query_single_page\n",
      "    json_resp = json.loads(response.text)\n",
      "  File \"/usr/lib/python3.5/json/__init__.py\", line 319, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/usr/lib/python3.5/json/decoder.py\", line 339, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/usr/lib/python3.5/json/decoder.py\", line 357, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "INFO:root:Retrying... (Attempts left: 10)\n",
      "INFO:root:Got 297 tweets for bitcoin%20since%3A2017-07-22%20until%3A2017-07-23.\n",
      "INFO:root:Got 297 tweets (297 new).\n",
      "INFO:root:Got 375 tweets for bitcoin%20since%3A2017-07-20%20until%3A2017-07-21.\n",
      "INFO:root:Got 672 tweets (375 new).\n",
      "INFO:root:Got 359 tweets for bitcoin%20since%3A2017-07-21%20until%3A2017-07-22.\n",
      "INFO:root:Got 1031 tweets (359 new).\n",
      "INFO:root:Got 353 tweets for bitcoin%20since%3A2017-07-19%20until%3A2017-07-20.\n",
      "INFO:root:Got 1384 tweets (353 new).\n"
     ]
    }
   ],
   "source": [
    "fill_missing_days()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_missing():\n",
    "    for fullPath in get_paths():\n",
    "        coinName = fullPath.split(\"/\")[-2]\n",
    "        \n",
    "        df = pd.read_csv('{}/combined.csv'.format(fullPath), engine='python')\n",
    "        missing = pd.read_csv('{}/missing.csv'.format(fullPath), engine='python')[['ID', 'Tweet', 'Time', 'User', 'Likes', 'Replies', 'Retweet', 'in_response_to', 'response_type']]\n",
    "        \n",
    "        combined = pd.concat([df,missing])\n",
    "        newDf = clean_data(combined)\n",
    "        \n",
    "        newDf.to_csv('{}/combined.csv'.format(fullPath), index=False)\n",
    "        print(\"New Data Written to combined.csv\")\n",
    "        os.remove('{}/missing.csv'.format(fullPath))\n",
    "        print(\"missing.csv removed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Data Written to combined.csv\n",
      "missing.csv removed\n",
      "New Data Written to combined.csv\n",
      "missing.csv removed\n",
      "New Data Written to combined.csv\n",
      "missing.csv removed\n",
      "New Data Written to combined.csv\n",
      "missing.csv removed\n",
      "New Data Written to combined.csv\n",
      "missing.csv removed\n",
      "New Data Written to combined.csv\n",
      "missing.csv removed\n",
      "New Data Written to combined.csv\n",
      "missing.csv removed\n",
      "New Data Written to combined.csv\n",
      "missing.csv removed\n"
     ]
    }
   ],
   "source": [
    "merge_missing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_missing(freq=24):\n",
    "    for fullPath in get_paths():\n",
    "        coinName = fullPath.split(\"/\")[-2]\n",
    "        \n",
    "        df = pd.read_csv('{}/combined.csv'.format(fullPath), engine='python')\n",
    "        coinName = fullPath.split(\"/\")[-2]\n",
    "        \n",
    "        print(coinName)\n",
    "        print(get_missing_days(df, freq=freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ripple\n",
      "DatetimeIndex(['2015-01-01', '2016-02-02', '2016-02-29'], dtype='datetime64[ns]', name='Time', freq=None)\n",
      "dogecoin\n",
      "DatetimeIndex([], dtype='datetime64[ns]', name='Time', freq='12H')\n",
      "monero\n",
      "DatetimeIndex(['2017-02-13'], dtype='datetime64[ns]', name='Time', freq='12H')\n",
      "stellar\n",
      "DatetimeIndex([], dtype='datetime64[ns]', name='Time', freq='12H')\n",
      "litecoin\n",
      "DatetimeIndex([], dtype='datetime64[ns]', name='Time', freq='12H')\n",
      "ethereum\n",
      "DatetimeIndex(['2018-05-06 00:00:00', '2018-05-06 12:00:00'], dtype='datetime64[ns]', name='Time', freq='12H')\n",
      "dash\n",
      "DatetimeIndex([], dtype='datetime64[ns]', name='Time', freq='12H')\n",
      "bitcoin\n",
      "DatetimeIndex([], dtype='datetime64[ns]', name='Time', freq='12H')\n"
     ]
    }
   ],
   "source": [
    "print_missing(freq=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
